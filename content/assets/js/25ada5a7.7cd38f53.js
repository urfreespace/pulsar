"use strict";(self.webpackChunkwebsite_next=self.webpackChunkwebsite_next||[]).push([[76306],{3905:function(e,r,a){a.d(r,{Zo:function(){return p},kt:function(){return m}});var n=a(67294);function t(e,r,a){return r in e?Object.defineProperty(e,r,{value:a,enumerable:!0,configurable:!0,writable:!0}):e[r]=a,e}function o(e,r){var a=Object.keys(e);if(Object.getOwnPropertySymbols){var n=Object.getOwnPropertySymbols(e);r&&(n=n.filter((function(r){return Object.getOwnPropertyDescriptor(e,r).enumerable}))),a.push.apply(a,n)}return a}function i(e){for(var r=1;r<arguments.length;r++){var a=null!=arguments[r]?arguments[r]:{};r%2?o(Object(a),!0).forEach((function(r){t(e,r,a[r])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(a)):o(Object(a)).forEach((function(r){Object.defineProperty(e,r,Object.getOwnPropertyDescriptor(a,r))}))}return e}function s(e,r){if(null==e)return{};var a,n,t=function(e,r){if(null==e)return{};var a,n,t={},o=Object.keys(e);for(n=0;n<o.length;n++)a=o[n],r.indexOf(a)>=0||(t[a]=e[a]);return t}(e,r);if(Object.getOwnPropertySymbols){var o=Object.getOwnPropertySymbols(e);for(n=0;n<o.length;n++)a=o[n],r.indexOf(a)>=0||Object.prototype.propertyIsEnumerable.call(e,a)&&(t[a]=e[a])}return t}var l=n.createContext({}),u=function(e){var r=n.useContext(l),a=r;return e&&(a="function"==typeof e?e(r):i(i({},r),e)),a},p=function(e){var r=u(e.components);return n.createElement(l.Provider,{value:r},e.children)},c={inlineCode:"code",wrapper:function(e){var r=e.children;return n.createElement(n.Fragment,{},r)}},d=n.forwardRef((function(e,r){var a=e.components,t=e.mdxType,o=e.originalType,l=e.parentName,p=s(e,["components","mdxType","originalType","parentName"]),d=u(a),m=t,v=d["".concat(l,".").concat(m)]||d[m]||c[m]||o;return a?n.createElement(v,i(i({ref:r},p),{},{components:a})):n.createElement(v,i({ref:r},p))}));function m(e,r){var a=arguments,t=r&&r.mdxType;if("string"==typeof e||t){var o=a.length,i=new Array(o);i[0]=d;var s={};for(var l in r)hasOwnProperty.call(r,l)&&(s[l]=r[l]);s.originalType=e,s.mdxType="string"==typeof e?e:t,i[1]=s;for(var u=2;u<o;u++)i[u]=a[u];return n.createElement.apply(null,i)}return n.createElement.apply(null,a)}d.displayName="MDXCreateElement"},58215:function(e,r,a){var n=a(67294);r.Z=function(e){var r=e.children,a=e.hidden,t=e.className;return n.createElement("div",{role:"tabpanel",hidden:a,className:t},r)}},26396:function(e,r,a){a.d(r,{Z:function(){return d}});var n=a(87462),t=a(67294),o=a(72389),i=a(79443);var s=function(){var e=(0,t.useContext)(i.Z);if(null==e)throw new Error('"useUserPreferencesContext" is used outside of "Layout" component.');return e},l=a(89521),u=a(86010),p="tabItem_vU9c";function c(e){var r,a,n,o=e.lazy,i=e.block,c=e.defaultValue,d=e.values,m=e.groupId,v=e.className,f=t.Children.map(e.children,(function(e){if((0,t.isValidElement)(e)&&void 0!==e.props.value)return e;throw new Error("Docusaurus error: Bad <Tabs> child <"+("string"==typeof e.type?e.type:e.type.name)+'>: all children of the <Tabs> component should be <TabItem>, and every <TabItem> should have a unique "value" prop.')})),h=null!=d?d:f.map((function(e){var r=e.props;return{value:r.value,label:r.label}})),g=(0,l.lx)(h,(function(e,r){return e.value===r.value}));if(g.length>0)throw new Error('Docusaurus error: Duplicate values "'+g.map((function(e){return e.value})).join(", ")+'" found in <Tabs>. Every value needs to be unique.');var k=null===c?c:null!=(r=null!=c?c:null==(a=f.find((function(e){return e.props.default})))?void 0:a.props.value)?r:null==(n=f[0])?void 0:n.props.value;if(null!==k&&!h.some((function(e){return e.value===k})))throw new Error('Docusaurus error: The <Tabs> has a defaultValue "'+k+'" but none of its children has the corresponding value. Available values are: '+h.map((function(e){return e.value})).join(", ")+". If you intend to show no default tab, use defaultValue={null} instead.");var b=s(),y=b.tabGroupChoices,S=b.setTabGroupChoices,w=(0,t.useState)(k),x=w[0],C=w[1],P=[],N=(0,l.o5)().blockElementScrollPositionUntilNextRender;if(null!=m){var O=y[m];null!=O&&O!==x&&h.some((function(e){return e.value===O}))&&C(O)}var E=function(e){var r=e.currentTarget,a=P.indexOf(r),n=h[a].value;n!==x&&(N(r),C(n),null!=m&&S(m,n))},D=function(e){var r,a=null;switch(e.key){case"ArrowRight":var n=P.indexOf(e.currentTarget)+1;a=P[n]||P[0];break;case"ArrowLeft":var t=P.indexOf(e.currentTarget)-1;a=P[t]||P[P.length-1]}null==(r=a)||r.focus()};return t.createElement("div",{className:"tabs-container"},t.createElement("ul",{role:"tablist","aria-orientation":"horizontal",className:(0,u.Z)("tabs",{"tabs--block":i},v)},h.map((function(e){var r=e.value,a=e.label;return t.createElement("li",{role:"tab",tabIndex:x===r?0:-1,"aria-selected":x===r,className:(0,u.Z)("tabs__item",p,{"tabs__item--active":x===r}),key:r,ref:function(e){return P.push(e)},onKeyDown:D,onFocus:E,onClick:E},null!=a?a:r)}))),o?(0,t.cloneElement)(f.filter((function(e){return e.props.value===x}))[0],{className:"margin-vert--md"}):t.createElement("div",{className:"margin-vert--md"},f.map((function(e,r){return(0,t.cloneElement)(e,{key:r,hidden:e.props.value!==x})}))))}function d(e){var r=(0,o.Z)();return t.createElement(c,(0,n.Z)({key:String(r)},e))}},79443:function(e,r,a){var n=(0,a(67294).createContext)(void 0);r.Z=n},22462:function(e,r,a){a.r(r),a.d(r,{frontMatter:function(){return s},contentTitle:function(){return l},metadata:function(){return u},toc:function(){return p},default:function(){return d}});var n=a(87462),t=a(63366),o=(a(67294),a(3905)),i=(a(26396),a(58215),["components"]),s={id:"adaptors-spark",title:"Pulsar adaptor for Apache Spark",sidebar_label:"Apache Spark",original_id:"adaptors-spark"},l=void 0,u={unversionedId:"adaptors-spark",id:"version-2.7.0/adaptors-spark",isDocsHomePage:!1,title:"Pulsar adaptor for Apache Spark",description:"The Spark Streaming receiver for Pulsar is a custom receiver that enables Apache Spark Streaming to receive raw data from Pulsar.",source:"@site/versioned_docs/version-2.7.0/adaptors-spark.md",sourceDirName:".",slug:"/adaptors-spark",permalink:"/docs/2.7.0/adaptors-spark",editUrl:"https://github.com/apache/pulsar/edit/master/site2/website-next/versioned_docs/version-2.7.0/adaptors-spark.md",tags:[],version:"2.7.0",frontMatter:{id:"adaptors-spark",title:"Pulsar adaptor for Apache Spark",sidebar_label:"Apache Spark",original_id:"adaptors-spark"},sidebar:"version-2.7.0/docsSidebar",previous:{title:"Kafka client wrapper",permalink:"/docs/2.7.0/adaptors-kafka"},next:{title:"Apache Storm",permalink:"/docs/2.7.0/adaptors-storm"}},p=[{value:"Prerequisites",id:"prerequisites",children:[{value:"Maven",id:"maven",children:[],level:3},{value:"Gradle",id:"gradle",children:[],level:3}],level:2},{value:"Usage",id:"usage",children:[],level:2}],c={toc:p};function d(e){var r=e.components,a=(0,t.Z)(e,i);return(0,o.kt)("wrapper",(0,n.Z)({},c,a,{components:r,mdxType:"MDXLayout"}),(0,o.kt)("p",null,"The Spark Streaming receiver for Pulsar is a custom receiver that enables Apache ",(0,o.kt)("a",{parentName:"p",href:"https://spark.apache.org/streaming/"},"Spark Streaming")," to receive raw data from Pulsar."),(0,o.kt)("p",null,"An application can receive data in ",(0,o.kt)("a",{parentName:"p",href:"https://spark.apache.org/docs/latest/programming-guide.html#resilient-distributed-datasets-rdds"},"Resilient Distributed Dataset")," (RDD) format via the Spark Streaming receiver and can process it in a variety of ways."),(0,o.kt)("h2",{id:"prerequisites"},"Prerequisites"),(0,o.kt)("p",null,"To use the receiver, include a dependency for the ",(0,o.kt)("inlineCode",{parentName:"p"},"pulsar-spark")," library in your Java configuration."),(0,o.kt)("h3",{id:"maven"},"Maven"),(0,o.kt)("p",null,"If you're using Maven, add this to your ",(0,o.kt)("inlineCode",{parentName:"p"},"pom.xml"),":"),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-xml"},"\n\x3c!-- in your <properties> block --\x3e\n<pulsar.version>2.7.0</pulsar.version>\n\n\x3c!-- in your <dependencies> block --\x3e\n<dependency>\n  <groupId>org.apache.pulsar</groupId>\n  <artifactId>pulsar-spark</artifactId>\n  <version>${pulsar.version}</version>\n</dependency>\n\n")),(0,o.kt)("h3",{id:"gradle"},"Gradle"),(0,o.kt)("p",null,"If you're using Gradle, add this to your ",(0,o.kt)("inlineCode",{parentName:"p"},"build.gradle")," file:"),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-groovy"},"\ndef pulsarVersion = \"2.7.0\"\n\ndependencies {\n    compile group: 'org.apache.pulsar', name: 'pulsar-spark', version: pulsarVersion\n}\n\n")),(0,o.kt)("h2",{id:"usage"},"Usage"),(0,o.kt)("p",null,"Pass an instance of ",(0,o.kt)("inlineCode",{parentName:"p"},"SparkStreamingPulsarReceiver")," to the ",(0,o.kt)("inlineCode",{parentName:"p"},"receiverStream")," method in ",(0,o.kt)("inlineCode",{parentName:"p"},"JavaStreamingContext"),":"),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-java"},'\n    String serviceUrl = "pulsar://localhost:6650/";\n    String topic = "persistent://public/default/test_src";\n    String subs = "test_sub";\n\n    SparkConf sparkConf = new SparkConf().setMaster("local[*]").setAppName("Pulsar Spark Example");\n\n    JavaStreamingContext jsc = new JavaStreamingContext(sparkConf, Durations.seconds(60));\n\n    ConsumerConfigurationData<byte[]> pulsarConf = new ConsumerConfigurationData();\n\n    Set<String> set = new HashSet();\n    set.add(topic);\n    pulsarConf.setTopicNames(set);\n    pulsarConf.setSubscriptionName(subs);\n\n    SparkStreamingPulsarReceiver pulsarReceiver = new SparkStreamingPulsarReceiver(\n        serviceUrl,\n        pulsarConf,\n        new AuthenticationDisabled());\n\n    JavaReceiverInputDStream<byte[]> lineDStream = jsc.receiverStream(pulsarReceiver);\n\n')),(0,o.kt)("p",null,"For a complete example, click ",(0,o.kt)("a",{parentName:"p",href:"https://github.com/apache/pulsar-adapters/blob/master/examples/spark/src/main/java/org/apache/spark/streaming/receiver/example/SparkStreamingPulsarReceiverExample.java"},"here"),'. In this example, the number of messages that contain the string "Pulsar" in received messages is counted.'))}d.isMDXComponent=!0}}]);