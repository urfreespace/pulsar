"use strict";(self.webpackChunkwebsite_next=self.webpackChunkwebsite_next||[]).push([[1477],{30010:function(e){e.exports=JSON.parse('{"blogPosts":[{"id":"/2021/12/14/Apache-Pulsar-2-7-4","metadata":{"permalink":"/blog/2021/12/14/Apache-Pulsar-2-7-4","editUrl":"https://github.com/apache/pulsar/edit/master/site2/website-next/blog/2021-12-14-Apache-Pulsar-2-7-4.md","source":"@site/blog/2021-12-14-Apache-Pulsar-2-7-4.md","title":"What\u2019s New in Apache Pulsar 2.7.4","description":"The Apache Pulsar community releases version 2.7.4! 32 contributors provided improvements and bug fixes that delivered 98 commits.","date":"2021-12-14T00:00:00.000Z","formattedDate":"December 14, 2021","tags":[],"readingTime":4.385,"truncated":false,"authors":[{"name":"Technoboy-, Anonymitaet"}],"nextItem":{"title":"Log4j2 Zero Day vulnerability (CVE-2021-44228)","permalink":"/blog/2021/12/11/Log4j-CVE"}},"content":"The Apache Pulsar community releases version 2.7.4! 32 contributors provided improvements and bug fixes that delivered 98 commits.\\n\\nHighlights of this release are as below:\\n\\n- Upgrade Log4j to 2.17.0 - [CVE-2021-45105](https://pulsar.apache.org/blog/2021/12/11/Log4j-CVE/). [PR-13392](https://github.com/apache/pulsar/pull/13392)\\n  \\n- `ManagedLedger` can be referenced correctly when `OpAddEntry` is recycled. [PR-12103](https://github.com/apache/pulsar/pull/12103)\\n\\n- NPE does not occur on `OpAddEntry` while ManagedLedger is closing. [PR-12364](https://github.com/apache/pulsar/pull/12364)\\n\\nThis blog walks through the most noteworthy changes grouped by the affected functionalities. For the complete list including all enhancements and bug fixes, check out the [Pulsar 2.7.4 Release Notes](https://pulsar.apache.org/en/release-notes/#274).\\n\\n# Notable bug fixes and enhancements\\n\\n### Upgrade Log4j to 2.17.0 - [CVE-2021-45105](https://pulsar.apache.org/blog/2021/12/11/Log4j-CVE/). [PR-13392](https://github.com/apache/pulsar/pull/13392)\\n\\n- **Issue**\\n\\n  A serious vulnerability was reported regarding Log4j that can allow remote execution for attackers. The vulnerability issue is described and tracked under [CVE-2021-44228](https://nvd.nist.gov/vuln/detail/CVE-2021-44228).\\n\\n- **Resolution**\\n  \\n  Pulsar 2.7.4 upgraded Log4j to 2.17.0.\\n\\n### `ManagedLedger` can be referenced correctly when `OpAddEntry` is recycled. [PR-12103](https://github.com/apache/pulsar/pull/12103)\\n\\n- **Issue**\\n  \\n  Previously, after a write failure, a task was scheduled in the background to force close the ledger and trigger the creation of  a new ledger. If the `OpAddEntry` instance was already recycled, that could lead to either an NPE or undefined behavior.\\n\\n- **Resolution**\\n  \\n  The `ManagedLedgerImpl` object reference is copied to a final variable so the background task will not be dependent on the lifecycle of the `OpAddEntry` instance.\\n\\n### No potential race condition in the `BlobStoreBackedReadHandler`. [PR-12123](https://github.com/apache/pulsar/pull/12123)\\n\\n- **Issue**\\n\\n  Previously, `BlobStoreBackedReadHandler` entered an infinite loop when reading an offload ledger. There was a race condition between the operation of reading entries and closing BlobStoreBackedReadHandler.\\n\\n- **Resolution**\\n  \\n  Added a state check before reading entries and made the `BlobStoreBackedReadHandler` exit loop when the `entryID` is bigger than the `lastEntryID`.\\n\\n### NPE does not occur on `OpAddEntry` while ManagedLedger is closing. [PR-12364](https://github.com/apache/pulsar/pull/12364)\\n\\n- **Issue** \\n\\n  Previously, the test `ManagedLedgerBkTest#managedLedgerClosed` closed ManagedLedger object on some `asyncAddEntry` operations and failed with NPE.\\n\\t\\n- **Resolution**\\n\\n  Closed `OpAddEntry`  when ` ManagedLedger` signaled  `OpAddEntry` to fail. In this way, the `OpAddEntry` object was correctly recycled and the failed callback was correctly triggered.\\n\\n### Set a topic policy through the topic name of a partition correctly. [PR-11294](https://github.com/apache/pulsar/pull/11294)\\n\\n- **Issue**\\n\\n  Previously, the topic name of a partition could not be used to set a topic policy.\\n\\n- **Resolution**\\n\\n  Allowed setting a topic policy through a topic name of a partition by converting the topic name of a partition in `SystemTopicBasedTopicPoliciesService`.\\n\\n### Dispatch rate limiter takes effect for consumers. [PR-8611](https://github.com/apache/pulsar/pull/8611)\\n\\n- **Issue**\\n\\n  Previously, dispatch rate limiter did not take effect in cases where all consumers started reading in the next second since `acquiredPermits` was reset to 0 every second.\\n\\n- **Resolution**\\n  \\n  Changed the behaviour of `DispatchRateLimiter` by minus `permits` every second instead of reset `acquiredPermits` to 0. Consumers stopped reading entries temporarily until `acquiredPermits` returned to a value less than `permits` .\\n\\n### NPE does not occur when executing unload bundles operations. [PR-11310](https://github.com/apache/pulsar/pull/11310)\\n\\n- **Issue**\\n  \\n  When performing pressure tests on persistent partitioned topics, NPE occurred when executing unload bundles operations. Concurrently, producers did not write messages.\\n\\n- **Resolution**\\n  \\n  Added more safety checks to fix this issue.\\n\\n### Fix inconsistent behavior for Namespace bundles cache. [PR-11346](https://github.com/apache/pulsar/pull/11346)\\n\\n- **Issue**\\n  \\n  Previously, namespace bundle cache was not invalidated after a namespace was deleted.\\n\\n- **Resolution**\\n\\n  Invalidated namespace policy cache when bundle cache was invalidated.\\n\\n### Close the replicator and replication client after a cluster is deleted. [PR-11342](https://github.com/apache/pulsar/pull/11342)\\n\\n- **Issue**\\n  \\n  Previously, the replicator and the replication client were not closed after a cluster was deleted. The producer of the replicator would then try to reconnect to the deleted cluster continuously.\\n\\n- **Resolution**\\n  \\n  Closed the relative replicator and replication client.\\n\\n### Publish rate limiter takes effect as expected. [PR-10384](https://github.com/apache/pulsar/pull/10384)\\n\\n- **Issue**\\n  \\n  Previously, there were various issues if `preciseTopicPublishRateLimiterEnable`  was set to `true` for rate limiting:\\n\\n  - Updating the limits did not set a boundary when changing the limits from a bounded limit to an unbounded limit.\\n  \\n  - Each topic created a scheduler thread for each limiter instance.\\n  \\n  - Topics did not release the scheduler thread when the topic was unloaded or the operation closed.\\n  \\n  - Updating the limits did not close the scheduler thread related to the replaced limiter instance\\n\\n- **Resolution**\\n  \\n  - Cleaned up the previous limiter instances before creating new limiter instances.\\n\\n  - Used `brokerService.pulsar().getExecutor()` as the scheduler for the rate limiter instances.\\n\\n  - Added resource cleanup hooks for topic closing (unload).\\n\\n### Clean up newly created  ledgers if fails to update ZNode list. [PR-12015](https://github.com/apache/pulsar/pull/12015)\\n\\n- **Issue**\\n  \\n  When updating a ZNode list, ZooKeeper threw an exception and did not clean up the created ledger. Newly created ledgers were not  indexed to a topic `managedLedger` list and could not be cleared up as topic retention. Also, ZNode numbers increased in ZooKeeper if the ZNode version mismatch exception was thrown out.\\n\\n- **Resolution**\\n  \\n  Deleted the created ledger from broker cache and BookKeeper regardless of exception type when the ZNode list failed to update.\\n\\n# What\u2019s Next?\\n\\nIf you are interested in learning more about Pulsar 2.7.4, you can [download](https://pulsar.apache.org/en/versions/) and try it out now! \\n\\nPulsar Summit Asia 2021 will take place on January 15-16, 2022. [Register now](https://pulsar-summit.org/) and help us make it an even bigger success by spreading the word on social media!\\n\\nFor more information about the Apache Pulsar project and current  progress, visit\\nthe [Pulsar website](https://pulsar.apache.org), follow the project on Twitter [@apache_pulsar](https://twitter.com/apache_pulsar), and join [Pulsar Slack](https://apache-pulsar.herokuapp.com/)!"},{"id":"/2021/12/11/Log4j-CVE","metadata":{"permalink":"/blog/2021/12/11/Log4j-CVE","editUrl":"https://github.com/apache/pulsar/edit/master/site2/website-next/blog/2021-12-11-Log4j-CVE.md","source":"@site/blog/2021-12-11-Log4j-CVE.md","title":"Log4j2 Zero Day vulnerability (CVE-2021-44228)","description":"Yesterday, a new serious vulnerability was reported regarding Log4j that can","date":"2021-12-11T00:00:00.000Z","formattedDate":"December 11, 2021","tags":[],"readingTime":1.15,"truncated":false,"authors":[{"name":"Matteo Merli"}],"prevItem":{"title":"What\u2019s New in Apache Pulsar 2.7.4","permalink":"/blog/2021/12/14/Apache-Pulsar-2-7-4"},"nextItem":{"title":"Apache Pulsar 2.8.1","permalink":"/blog/2021/09/23/Apache-Pulsar-2-8-1"}},"content":"Yesterday, a new serious vulnerability was reported regarding Log4j that can\\nallow remote execution for attackers.\\n\\nThe vulnerability issue is described and tracked under [CVE-2021-44228](https://nvd.nist.gov/vuln/detail/CVE-2021-44228).\\n\\nCurrent releases of Apache Pulsar are bundling Log4j2 versions that are affected by this vulnerability.\\nDefault configuration, combined with JVM version and other factors, can render it exploitable.\\nWe strongly recommend to follow the advisory of the Apache Log4j community and patch your systems \\nas soon as possible, as well as looking for unexpected behavior in your Pulsar logs.\\n\\nThere are 2 workarounds to patch a Pulsar deployments. You can set either of:\\n\\n 1. Java property: `-Dlog4j2.formatMsgNoLookups=true`\\n 2. Environment variable: `LOG4J_FORMAT_MSG_NO_LOOKUPS=true`\\n\\nBoth approaches are effective in mitigating the vulnerability for Pulsar\\nservices.\\n\\nAdditionally, when running Pulsar Functions with Kubernetes runtime, you should update\\nyour Docker images, following the example described [here](https://github.com/lhotari/pulsar-docker-images-patch-CVE-2021-44228).\\n\\nIf you are using the Pulsar Helm Chart for deploying in Kubernetes, a [new\\nversion of the chart](https://github.com/apache/pulsar-helm-chart/releases/tag/pulsar-2.7.6) is already available and it applies the above mentioned workaround.\\nIf upgrading is not an option, you may also mitigate by adding `-Dlog4j2.formatMsgNoLookups=true` to the `PULSAR_EXTRA_OPTS` in the `configData` section for proxy, broker, bookkeeper, zookeeper, auto-recovery, and relative components in the helm values file.\\n\\nWe are already preparing new patch releases, 2.7.4, 2.8.2 and 2.9.1. These\\nreleases will be ready in the next few days and will bundle the Log4j2 2.15.0,\\nwhich contains the vulnerability fix."},{"id":"/2021/09/23/Apache-Pulsar-2-8-1","metadata":{"permalink":"/blog/2021/09/23/Apache-Pulsar-2-8-1","editUrl":"https://github.com/apache/pulsar/edit/master/site2/website-next/blog/2021-09-23-Apache-Pulsar-2-8-1.md","source":"@site/blog/2021-09-23-Apache-Pulsar-2-8-1.md","title":"Apache Pulsar 2.8.1","description":"The Apache Pulsar community releases version 2.8.1! 49 contributors provided improvements and bug fixes that delivered 213 commits.","date":"2021-09-23T00:00:00.000Z","formattedDate":"September 23, 2021","tags":[],"readingTime":5.645,"truncated":false,"authors":[{"name":"Hang Chen, Anonymitaet"}],"prevItem":{"title":"Log4j2 Zero Day vulnerability (CVE-2021-44228)","permalink":"/blog/2021/12/11/Log4j-CVE"},"nextItem":{"title":"Announcing Pulsar Summit Asia 2021: CFP Is Open!","permalink":"/blog/2021/08/18/asia-cfp"}},"content":"The Apache Pulsar community releases version 2.8.1! 49 contributors provided improvements and bug fixes that delivered 213 commits.\\n\\nHighlights of this release are as below:\\n\\n- Key-shared subscriptions no longer stop dispatching to consumers when repeatedly opening and closing consumers. [PR-10920](https://github.com/apache/pulsar/pull/10920)\\n\\n- System topic no longer has potential data loss when not configured for compaction. [PR-11003](https://github.com/apache/pulsar/pull/11003)\\n\\n- Consumers are not allowed to read data on topics to which they are not subscribed. [PR-11912](https://github.com/apache/pulsar/pull/11912)\\n\\nThis blog walks through the most noteworthy changes grouped by component. For the complete list including all features, enhancements, and bug fixes, check out the [Pulsar 2.8.1 Release Notes](https://pulsar.apache.org/release-notes/#281-mdash-2021-09-10-a-id281a).\\n\\n# Notable bug fixes and enhancements\\n\\n## Broker\\n\\n### Precise publish rate limit takes effect as expected. [PR-11446](https://github.com/apache/pulsar/pull/11446)\\n\\n**Issue**: Previously, when setting precise publish rate limits on topics, it did not work.\\n\\n**Resolution**: Implemented a new `RateLimiter` using the `LeakingBucket` and `FixedWindow` algorithms.\\n\\n### Messages with the same keys are delivered to the correct consumers on Key-Shared subscriptions. [PR-10762](https://github.com/apache/pulsar/pull/10762)\\n\\n**Issue**: Messages with the same keys were out of order when message redelivery occurred on a Key-Shared subscription.\\n\\n**Resolution**: When sending a message to `messagesToRedeliver`, the broker saved the hash value of the key. If the dispatcher attempted to send newer messages to the consumer that had a key corresponding to any one of the saved hash values, they were added to `messagesToRedeliver` instead of being sent. This prevented messages with the same key from being out of order.\\n\\n### Active producers with the same name are no longer removed from the topic map. [PR-11804](https://github.com/apache/pulsar/pull/11804)\\n\\n**Issue**: Previously, when there were producers with the same name, an error would be triggered and the old producer would be removed even though it was still writing to a topic.\\n\\n**Resolution**: Validated producers based on a connection ID (local & remote addresses and unique ID) and a producer ID within that connection rather than a producer name.\\n\\n### Topics in a fenced state can recover when producers continue to reconnect to brokers. [PR-11737](https://github.com/apache/pulsar/pull/11737)\\n\\n**Issue**: Previously, when a producer continued to reconnect to a broker, the fenced state of the topic was always set to true, which caused the topic to be unable to recover.\\n\\n**Resolution**: Add an entry to `ManagedLedgerException` when the polled operation is not equal to the current operation.\\n\\n### Topic properly initializes the cursor to prevent data loss. [PR-11547](https://github.com/apache/pulsar/pull/11547)\\n\\n**Issue**: Previously, when subscribing to a topic with the earliest position, data would be lost because `ManagedLedger` used a wrong position to initialize a cursor.\\n\\n**Resolution**: Added a test to check a cursor\'s position when subscribing to a topic with the earliest position.\\n\\n### Deadlock no longer occurs when using `hasMessageAvailableAsync` and `readNextAsync`. [PR-11183](https://github.com/apache/pulsar/pull/11183)\\n\\n**Issue**: Previously, when messages were added to an incoming queue, a deadlock might occur. The deadlock might happen in two possible scenarios. First, if the message was added to the queue before the message was read. Second, if `readNextAsync` was completed before `future.whenComplete` was called.\\n\\n**Resolution**: Used an internal thread to process the callback of `hasMessageAvailableAsync`.\\n\\n### Memory leak does not occur when calling getLastMessageId API. [PR-10977](https://github.com/apache/pulsar/pull/10977)\\n\\n**Issue**: Previously, the broker ran out of memory when calling the `getLastMessageId` API.\\n\\n**Resolution**: Added the `entry.release()` call to the `PersistentTopic.getLastMessageId`.\\n\\n### Compaction is triggered for system topics. [PR-10941](https://github.com/apache/pulsar/pull/10941)\\n\\n**Issue**: Previously, when a topic had only non-durable subscriptions, the compaction was not triggered because it had 0 estimated backlog size. \\n\\n**Resolution**: Used the total backlog size to trigger the compaction. Changed the behavior in the case of no durable subscriptions to use the total backlog size\\n\\n### Key-shared subscriptions no longer stop dispatching to consumers when repeatedly opening and closing consumers. [PR-10920](https://github.com/apache/pulsar/pull/10920)\\n\\n**Issue**: Repeatedly opening and closing consumers with a Key-Shared subscription might occasionally stop dispatching messages to all consumers.\\n\\n**Resolution**: Moved the mark-delete position and removed the consumer from the selector before calling `removeConsumer()`.\\n\\n### Consumers are not allowed to read data on topics to which they are not subscribed. [PR-11912](https://github.com/apache/pulsar/pull/11912)\\n\\n**Issue**: Previously, the request ledger was not checked whether it belonged to a consumer\u2019s connected topic, which allowed the consumer to read data that does not belong to the connected topic.\\n\\n**Resolution**: Added a check on the `ManagedLedger` level before executing read operations. \\n\\n## Topic Policy\\n\\n### Retention policy works as expected. [PR-11021](https://github.com/apache/pulsar/pull/11021)\\n\\n**Issue**: Previously, the retention policy did not work because it was not set in the `managedLedger` configuration.\\n\\n**Resolution**: Set the retention policy in the `managedLedger` configuration to the `onUpdate` listener method.\\n\\n### System topic no longer has potential data loss when not configured for compaction. [PR-11003](https://github.com/apache/pulsar/pull/11003) \\n\\n**Issue**: Previously, data might be lost if there were no durable subscriptions on topics.\\n\\n**Resolution**: Leveraged the topic compaction cursor to retain data.\\n\\n## Proxy\\n\\n### Pulsar proxy correctly shuts down outbound connections. [PR-11848](https://github.com/apache/pulsar/pull/11848)\\n\\n**Issue**: Previously, there was a memory leak of outgoing TCP connections in the Pulsar proxy because the `ProxyConnectionPool` instances were created outside the `PulsarClientImpl` instance and not closed when the client was closed.\\n\\n**Resolution**: Shut down the `ConnectionPool` correctly.\\n\\n## Function\\n\\n### Pulsar Functions support Protobuf schema. [PR-11709](https://github.com/apache/pulsar/pull/11709)\\n\\n**Issue**: Previously, the exception `GeneratedMessageV3 is not assignable` was thrown when using a Protobuf schema.\\n\\n**Resolution**: Added the relevant dependencies to the Pulsar instance.\\n\\n## Client\\n\\n### Partitioned-topic consumers clean up resources after a failure. [PR-11754](https://github.com/apache/pulsar/pull/11754)\\n\\n**Issue**: Previously, partitioned-topic consumers did not clean up the resources when failing to create consumers. If this failure occurred with non-recoverable errors, it triggered a memory leak, which made applications unstable.\\n\\n**Resolution**: Closed and cleaned timer task references.\\n\\n### Race conditions do not occur on multi-topic consumers. [PR-11764](https://github.com/apache/pulsar/pull/11764)\\n\\n**Issue**: Previously, there was a race condition between 2 threads when one of the individual consumers was in a \\"paused\\" state and the shared queue was full. \\n\\n**Resolution**: Validated the state of the shared queue after marking the consumer as \\"paused\\". The consumer is not blocked if the other thread has emptied the queue in the meantime. \\n\\n### Consumers are not blocked on `batchReceive`. [PR-11691](https://github.com/apache/pulsar/pull/11691)\\n\\n**Issue**: Previously, consumers were blocked when `Consumer.batchReceive()` was called concurrently by different threads due to a race condition in `ConsumerBase.java`.\\n\\n**Resolution**: Put `pinnedInternalExecutor` in `ConsumerBase` to allow batch timer, `ConsumerImpl`, and `MultiTopicsConsumerImpl` to submit work in a single thread.\\n\\n### Python client correctly enables custom logging. [PR-11882](https://github.com/apache/pulsar/pull/11882)\\n\\n**Issue**: Previously, deadlock might happen when custom logging was enabled in the Python client.\\n\\n**Resolution**: Detached the worker thread and reduced log level.\\n\\n# What is Next?\\n\\nIf you are interested in learning more about Pulsar 2.8.1, you can [download](https://pulsar.apache.org/en/download/) and try it out now! \\n\\nThe first-ever Pulsar Virtual Summit Europe 2021 will take place in October. [Register now](https://hopin.com/events/pulsar-summit-europe-2021) and help us make it an even bigger success by spreading the word on social media!\\n\\nFor more information about the Apache Pulsar project and the progress, visit\\nthe [Pulsar website](https://pulsar.apache.org), follow the project on Twitter [@apache_pulsar](https://twitter.com/apache_pulsar), and join [Pulsar Slack](https://apache-pulsar.herokuapp.com/)!"},{"id":"/2021/08/18/asia-cfp","metadata":{"permalink":"/blog/2021/08/18/asia-cfp","editUrl":"https://github.com/apache/pulsar/edit/master/site2/website-next/blog/2021-08-18-asia-cfp.md","source":"@site/blog/2021-08-18-asia-cfp.md","title":"Announcing Pulsar Summit Asia 2021: CFP Is Open!","description":"We\u2019re proud to announce the Pulsar Summit Asia 2021!","date":"2021-08-18T00:00:00.000Z","formattedDate":"August 18, 2021","tags":[],"readingTime":2.845,"truncated":false,"authors":[{"name":"Dianjin"}],"prevItem":{"title":"Apache Pulsar 2.8.1","permalink":"/blog/2021/09/23/Apache-Pulsar-2-8-1"},"nextItem":{"title":"Apache Pulsar 2.7.3","permalink":"/blog/2021/08/11/Apache-Pulsar-2-7-3"}},"content":"We\u2019re proud to announce the Pulsar Summit Asia 2021!\\n\\n2021 has been a remarkable year for the Apache Pulsar community. [Both the technology and community are growing rapidly this year](https://streamnative.io/en/blog/community/2021-06-14-pulsar-hits-its-400th-contributor-and-passes-kafka-in-monthly-active-contributors), and [Pulsar Virtual Summit North America 2021](https://www.na2021.pulsar-summit.org) was a big success with 33 break-out sessions and more than 550 registrations.\\n\\nLast year, [Pulsar Summit Asia](https://pulsar-summit.org/en/event/asia-2020) featured more than 40 interactive sessions by tech leads, open-source developers, software engineers, and software architects from Tencent Group, BIGO, Kingsoft Cloud, Splunk, Yahoo! JAPAN, Nutanix, Dada Group, TIBCO, Huawei Cloud, and more. The conference garnered nearly 1,000 attendees around the globe mostly from Asia, including attendees from top tech, fintech and media companies.\\n\\nCumulatively, the Pulsar Summits drew more than 100 speakers, thousands of attendees, and hundreds of companies from diverse industries. It is a unique opportunity to network and learn about Pulsar project updates, ecosystem developments, best practices, and adoption stories.\\n\\n**This year, the Pulsar Summit Asia will be hosted on November 20-21, 2021 by StreamNative. You can join us offline in Beijing for one day of Pulsar Training and one day of keynotes and breakout sessions. All the talks will be streamed live online.**\\n# CFP Details\\nJoin us and speak at the Pulsar Summit Asia 2021!\\nWe are looking for Pulsar stories that are innovative, informative, or thought-provoking. Here are some suggestions:\\n- Your Pulsar use case / success story\\n- A technical deep dive\\n- Pulsar best practices\\n- Pulsar ecosystem updates\\n\\nTo speak at the summit, please [submit an abstract](https://sessionize.com/pulsar-summit-asia-2021/) about your presentation. Remember to keep your proposal short, relevant and engaging.\\n# First-time Speakers Welcomed! \\nFirst time submitting? Don\'t feel intimidated. We strongly encourage first-time speakers to submit talks for the Pulsar Summit Asia 2021. If your submission is similar to a previous talk in the past Pulsar Summits, please include information on how this version will be different. We hope to see some exciting updates on the topic.\\n\\nWe welcome submissions from around the globe. Our hybrid conference model has taken time differences into consideration. After your talk is accepted, we will schedule the sessions and send you the presentation options. \\n\\n# Speaker Benefits\\nAs a speaker, you will receive: \\n- The chance to demonstrate your experience and deep knowledge in the rapidly growing event streaming space.\\n- Your name, title, company, and bio will be featured on the Pulsar Summit Asia 2021 website.\\n- Your session will be added to the Pulsar Summit YouTube Channel and promoted on Twitter,  LinkedIn, and WeChat.\\n- A professionally produced video of your presentation.\\nExclusive Pulsar swag only available to the speakers.\\n\\n# Important Dates\\n- CFP opens: August 18th, 2021 \\n- CFP closes: September 8th, 2021 \\n- Speaker notifications: September 22th, 2021\\n- Schedule announcement: October 13th, 2021 \\n\\nSubmissions are open until September 8th. If you want some advice or feedback on your proposal, or have any questions about the summit, please do not hesitate to contact us at organizers@pulsar-summit.org. We are happy to help!\\n\\n# Sponsor Pulsar Summit Asia\\nPulsar Summit is a conference for the community and sponsorship is needed. Sponsoring this event provides a great opportunity for your organization to further engage with the Apache Pulsar community. Contact us at organizers@pulsar-summit.org to learn more.\\n\\nHelp us make Pulsar Summit Asia 2021 a big success by spreading the word and submitting your proposal! Follow Pulsar Summit on [Twitter](https://twitter.com/PulsarSummit) to receive the latest updates of the conference."},{"id":"/2021/08/11/Apache-Pulsar-2-7-3","metadata":{"permalink":"/blog/2021/08/11/Apache-Pulsar-2-7-3","editUrl":"https://github.com/apache/pulsar/edit/master/site2/website-next/blog/2021-08-11-Apache-Pulsar-2-7-3.md","source":"@site/blog/2021-08-11-Apache-Pulsar-2-7-3.md","title":"Apache Pulsar 2.7.3","description":"The Apache Pulsar community releases version 2.7.3! 34 contributors provided improvements and bug fixes that delivered 79 commits.","date":"2021-08-11T00:00:00.000Z","formattedDate":"August 11, 2021","tags":[],"readingTime":5.715,"truncated":false,"authors":[{"name":"Bo Cong, Anonymitaet"}],"prevItem":{"title":"Announcing Pulsar Summit Asia 2021: CFP Is Open!","permalink":"/blog/2021/08/18/asia-cfp"},"nextItem":{"title":"Apache Pulsar 2.8.0","permalink":"/blog/2021/06/12/Apache-Pulsar-2-8-0"}},"content":"The Apache Pulsar community releases version 2.7.3! 34 contributors provided improvements and bug fixes that delivered 79 commits.\\n\\n## Highlights\\n\\n- Cursor reads adhere to the dispatch byte rate limiter setting and no longer cause unexpected results. [PR-11249](https://github.com/apache/pulsar/pull/11249)\\n\\n- The ledger rollover scheduled task runs as expected. [PR-11226](https://github.com/apache/pulsar/pull/11226)\\n\\nThis blog walks through the most noteworthy changes. For the complete list including all enhancements and bug fixes, check out the [Pulsar 2.7.3 Release Notes](https://pulsar.apache.org/release-notes/#273-mdash-2021-07-27-a-id273a).\\n\\n# Notable bug fixes and enhancements\\n\\n## Broker\\n\\n### Cursor reads adhere to the dispatch byte rate limiter setting. [PR-9826](https://github.com/apache/pulsar/pull/9826)\\n\\n- **Issue**: When using byte rates, the dispatch rates were not respected (regardless\\nof being a namespace or topic policy). \\n\\n- **Resolution**: Fixed behavior of dispatch byte rate limiter setting. Cursor reads adhere to the setting and no longer cause unexpected results. \\n\\n### The ledger rollover scheduled task runs as expected. [PR-11226](https://github.com/apache/pulsar/pull/11226)\\n\\n- **Issue**: Previously, the ledger rollover scheduled task was executed before reaching the ledger maximum rollover time, which caused the ledger not to roll over in time. \\n\\n- **Resolution**: Fixed the timing of the ledger rollover schedule, so the task runs only after the ledger is created successfully. \\n  \\n### The topic-level retention policy works correctly when restarting a broker. [PR-11136](https://github.com/apache/pulsar/pull/11136)\\n\\n- **Issue**: Previously, when setting a topic-level retention policy for a topic and then restarting the broker, the topic-level retention policy did not work.\\n\\n- **Resolution**: Fixed behavior of the policy so it replays all policy messages after initiating `policyCacheInitMap` and added a retention policy check test when restarting the broker.\\n\\n### The lastMessageId API call no longer causes a memory leak. [PR-10977](https://github.com/apache/pulsar/pull/10977)\\n\\n- **Issue**: Previously, there was a memory leak when calling the `lastMessageId` API, which caused the broker process to be stopped by Kubernetes. \\n\\n- **Resolution**: Added the missing entry.release() call to PersistentTopic.getLastMessageId to ensure the broker does not run out of memory. \\n\\n### ZooKeeper reads are cached by brokers. [PR-10594](https://github.com/apache/pulsar/pull/10594)\\n\\n- **Issue**: When performing the admin operation to get the namespace of a tenant, ZooKeeper reads were issued on the ZooKeeper client and not getting cached by the brokers.\\n\\n- **Resolution**: Fixed ZooKeeper caching when fetching a list of namespaces for a tenant.\\n\\n### Monitoring threads that call `LeaderService.isLeader()` are no longer blocked. [PR-10512](https://github.com/apache/pulsar/pull/10512)\\n\\n- **Issue**:  When `LeaderService` changed leadership status, it was locked with a `synchronized` block, which also blocked other threads calling `LeaderService.isLeader()`. \\n  \\n- **Resolution**: Fixed the deadlock condition on the monitoring thread so it is not blocked by `LeaderService.isLeader() by modifying `ClusterServiceCoordinator` and `WorkerStatsManager` to check if it is a leader from `MembershipManager`. \\n\\n### `hasMessageAvailable` can read messages successfully. [PR-10414](https://github.com/apache/pulsar/pull/10414)\\n\\n- **Issue**: When `hasMessageAvailableAsync` returned `true`, it could not read messages because messages were filtered by `acknowledgmentsGroupingTracker`. \\n\\n- **Resolution**: Fixed the race conditions by modifying `acknowledgmentsGroupingTracker` to filter duplicate messages, and then cleanup the messages when the connection is open.\\n  \\n## Proxy\\n\\n### Proxy supports creating partitioned topics automatically. [PR-8048](https://github.com/apache/pulsar/pull/8048)\\n\\n- **Issue**: Proxies were not creating partitions because they were using the current ZooKeeper metadata.\\n\\n- **Resolution**: Changed the proxy to handle `PartitionMetadataRequest` by selecting and fetching from an available broker instead of using current ZooKeeper metadata.\\n  \\n## Pulsar admin\\n\\n### Flag added to indicate whether or not to create a metadata path on replicated clusters. [PR-11140](https://github.com/apache/pulsar/pull/11140)\\n\\n- **Issue**: When creating a partitioned topic in a replicated namespace, it did not\\ncreate a metadata path `/managed-ledgers` on replicated clusters.\\n\\n- **Resolution**: Added a flag (createLocalTopicOnly) to indicate whether or not to create a metadata path for a partitioned topic in replicated clusters.\\n\\n### A topic policy can no longer be set for a non-existent topic. [PR-11131](https://github.com/apache/pulsar/pull/11131)\\n\\n- **Issue**: Due to a redirect loop in a topic policy, you can set a policy for a non-existing topic or a partition of a partitioned topic. \\n\\n- **Resolution**: The fix added an authoritative flag for a topic policy to avoid a redirect loop. You can not set a topic policy for a non-existent topic or a partition of a partitioned topic. If you set a topic policy for a partition of a 0-partition topic, it redirects to the broker. \\n\\n### Discovery service no longer hard codes the topic domain as persistent. [PR-10806](https://github.com/apache/pulsar/pull/10806)\\n\\n- **Issue**: When using the lookup discovery service for a partitioned non-persistent topic, it returned zero rather than the number of partitions. The Pulsar client tried to connect to the topic as if it were a normal topic.\\n\\n- **Resolution**: Implemented `topicName.getDomain().value()` rather than hard coding `persistent.` Now you can use the discovery service for a partitioned, non-persistent topic successfully.\\n\\n### Other connectors can now use the Kinesis `Backoff` class. [PR-10744](https://github.com/apache/pulsar/pull/10744)\\n\\n- **Issue**: The Kinesis sink connector `Backoff` class in the Pulsar client implementation project in combination  with the dependency `org.apache.pulsar:pulsar-client-original` increased the connector size. \\n\\n- **Resolution**: Added a new class `Backoff` in the function io-core project so that the Kinesis sink connector and other connectors can use the class.\\n\\n## Client\\n\\n### A `FLOW` request with zero permits can not be sent. [PR-10506](https://github.com/apache/pulsar/pull/10506)\\n\\n- **Issue**: When a broker received a `FLOW` request with zero permits, an exception was thrown and then the connection was closed. This triggered frequent reconnections and caused duplicate or out-of-order messages. \\n  \\n- **Resolution**: Added a validation that verifies the permits of a `FLOW` request before sending it. If the permit is zero, the `FLOW` request can not be sent.\\n\\n## Function and connector\\n\\n### The Kinesis sink connector acknowledges successful messages. [PR-10769](https://github.com/apache/pulsar/pull/10769)\\n\\n- **Issue**: The Kinesis sink connector did not acknowledge messages after they were sent successfully. \\n  \\n- **Resolution**: Added acknowledgement for the Kinesis sink connector once a message is sent successfully. \\n \\n## Docker\\n\\n### Function name length cannot exceed 52 characters when using Kubernetes runtime. [PR-10531](https://github.com/apache/pulsar/pull/10531)\\n\\n- **Issue**: When using Kubernetes runtime, if a function was submitted with a valid length (less than 55 characters), a StatefulSet was created but it was unable to spawn pods. \\n  \\n- **Resolution**: Changed the maximum length of a function name from 55 to 53 characters for Kubernetes runtime. With this fix, the length of a function name can not exceed 52 characters. \\n\\n## Dependency \\n\\n### `pulsar-admin` connection to proxy is stable when TLS is enabled. [PR-10907](https://github.com/apache/pulsar/pull/10907)\\n\\n- **Issue**: `pulsar-admin` was unstable over the TLS connection because of the Jetty bug in SSL buffering introduced in Jetty 9.4.39. It caused large function jar uploads to fail frequently.\\n  \\n- **Resolution**: Upgraded Jetty to 9.4.42.v20210604, so that `pulsar-admin` connection to proxy is stable when TLS is enabled.\\n\\n# What is Next?\\n\\nIf you are interested in learning more about Pulsar 2.7.3, you can [download 2.7.3](https://pulsar.apache.org/en/versions/) and try it out now! \\n\\nThe first-ever Pulsar Virtual Summit Europe 2021 will take place in October. [Register now](https://hopin.com/events/pulsar-summit-europe-2021) and help us make it an even bigger success by spreading the word on social!\\n\\nFor more information about the Apache Pulsar project and the progress, visit\\nthe [Pulsar website](https://pulsar.apache.org), follow the project on Twitter [@apache_pulsar](https://twitter.com/apache_pulsar), and join [Pulsar Slack](https://apache-pulsar.herokuapp.com/)!"},{"id":"/2021/06/12/Apache-Pulsar-2-8-0","metadata":{"permalink":"/blog/2021/06/12/Apache-Pulsar-2-8-0","editUrl":"https://github.com/apache/pulsar/edit/master/site2/website-next/blog/2021-06-12-Apache-Pulsar-2-8-0.md","source":"@site/blog/2021-06-12-Apache-Pulsar-2-8-0.md","title":"Apache Pulsar 2.8.0","description":"We are very glad to see the Apache Pulsar community has successfully released the 2.8.0 version, which includes a number of exciting upgrades and enhancements. This blog provides a deep dive into the updates from the 2.8.0 release as well as a detailed look at the major Pulsar developments that have helped it evolve into the unified messaging and streaming platform it is today.","date":"2021-06-12T00:00:00.000Z","formattedDate":"June 12, 2021","tags":[],"readingTime":13.465,"truncated":false,"authors":[{"name":"Matteo Merli, Sijie Guo"}],"prevItem":{"title":"Apache Pulsar 2.7.3","permalink":"/blog/2021/08/11/Apache-Pulsar-2-7-3"},"nextItem":{"title":"Apache Pulsar 2.7.2","permalink":"/blog/2021/05/13/Apache-Pulsar-2-7-2"}},"content":"We are very glad to see the Apache Pulsar community has successfully released the 2.8.0 version, which includes a number of exciting upgrades and enhancements. This blog provides a deep dive into the updates from the 2.8.0 release as well as a detailed look at the major Pulsar developments that have helped it evolve into the unified messaging and streaming platform it is today.\\n\\nNote: The Pulsar community typically releases a major release every 3 months, but it has been 6 months since the release of 2.7.0. We spent more time on 2.8.0 in order to make the transaction API generally available to the Pulsar community. \\n\\n# Release 2.8 Overview\\n\\nThe key features and updates in this release are:\\n- Exclusive Producer\\n- Package Management API\\n- Simplified Client Memory Limit Settings\\n- Broker Entry Metadata\\n- New Protobuf Code Generator\\n- Transactions\\n\\n## Exclusive Producer\\n\\nBy default, the Pulsar producer API provides a \u201cmulti-writer\u201d semantic to append messages to a topic. However, there are several use cases that require exclusive access for a single writer, such as ensuring a linear non-interleaved history of messages or providing a mechanism for leader election.\\n\\nThis new feature allows applications to require exclusive producer access in order to achieve a \u201csingle-writer\u201d situation. It guarantees that there should be 1 single writer in any combination of errors. If the producer loses its exclusive access, no more messages from it can be published on the topic.\\n\\nOne use case for this feature is the metadata controller in Pulsar Functions. In order to write a single linear history of all the functions metadata updates, the metadata controller requires to elect one leader and that all the \u201cdecisions\u201d made by this leader be written on the metadata topic. By leveraging the exclusive producer feature, Pulsar guarantees that the metadata topic contains different segments of updates, one per each successive leader, and there is no interleaving across different leaders. See \u201c[PIP-68: Exclusive Producer](https://github.com/apache/pulsar/wiki/PIP-68%3A-Exclusive-Producer)\u201d for more details.\\n\\n## Package Management API\\n\\nSince its introduction in version 2.0, the Functions API has become hugely popular among Pulsar users. While it offers many benefits, there are a number of ways to improve the user experience. For example, today, if a function is deployed multiple times, the function package ends up being uploaded multiple times. Also, there is no version management in Pulsar for Functions and IO connectors. The newly introduced package management API provides an easier way to manage the packages for Functions and IO connectors and significantly simplifies the upgrade and rollback processes. Read \u201c[Package Management API](http://pulsar.apache.org/docs/en/admin-api-packages/)\u201d for more details.\\n\\n## Simplified Client Memory Limit Settings\\n\\nPrior to 2.8, there are multiple settings in producers and consumers that allow controlling the sizes of the internal message queues. These settings ultimately control the amount of memory the Pulsar client uses. However, there are few issues with this approach that make it complicated to select an overall configuration that controls the total usage of memory. \\n\\nFor example, the settings are based on the \u201cnumber of messages\u201d, so the expected message size must be adjusted per producer or consumer. If an application has a large (or unknown) number of producers or consumers, it\u2019s very difficult to select an appropriate value for queue sizes. The same is true for topics that have many partitions.\\n\\nIn 2.8, we introduced a new API to set the memory limit. This single `memoryLimit` setting specifies a maximum amount of memory on a given Pulsar client. The producers and consumers compete for the memory assigned. It ensures the memory used by the Pulsar client will not go beyond the set limit. Read \u201c[PIP-74: Pulsar client memory limits](https://github.com/apache/pulsar/wiki/PIP-74%3A-Pulsar-client-memory-limits)\u201d for more details.\\n\\n## Broker Entry Metadata\\n\\nPulsar messages define a very comprehensive set of metadata properties. However, to add a new property, the `MessageMetadata` definition in Pulsar protocol must change to inform both broker and client of the newly introduced property. \\n\\nBut in certain cases, this metadata property might need to be added from the broker side, or need to be retrieved by the broker at a very low cost. To prevent deserializing these properties from the message metadata, we introduced \u201cBroker Entry Metadata\u201d in 2.8.0 to provide a lightweight approach to add additional metadata properties without serializing and deserializing the protobuf-encoded `MessageMetadata`. \\n\\nThis feature unblocks a new set of capabilities for Pulsar. For example, we can leverage broker entry metadata to generate broker publish time for the messages appended to the Pulsar topic. The other example is to generate a monotonically increasing sequence-id for messages produced to a Pulsar topic. We use this feature in Kafka-on-Pulsar to implement Kafka offset.\\n\\n## New Protobuf Code Generator\\n\\nPulsar uses Google Protobuf in order to perform serialization and deserialization of the commands that are exchanged between clients and brokers. Because of the overhead involved with the regular Protobuf implementation, we have been using a modified version of Protobuf 2.4.1. The modifications were done to ensure a more efficient serialization code that used thread local cache for the objects used in the process.\\n\\nThis approach introduced a few issues. For example, the patch to the Protobuf code generator is only based on Protobuf version 2.4.1 and cannot be upgraded to the newer Protobuf versions. In 2.8, we switched the patched Protobuf 2.4.1 to Splunk LightProto as the code generator. The new code generator generates the fastest possible Java code for Protobuf SerDe, is 100% compatible with proto2 definition and wire protocol, and provides zero-copy deserialization using Netty ByteBuf.\\n\\n## Transactions\\n\\nPrior to Pulsar 2.8, Pulsar only supported exactly-once semantics on single topic through Idempotent Producer. While powerful, Idempotent producer only solves a narrow scope of challenges for exactly-once semantics. For example, there is no `atomicity` when a producer attempts to produce messages to multiple topics. A publish error can occur when the broker serving one of the topics crashes. If the producer doesn\u2019t retry publishing the message again, it results in some messages being persisted once and others being lost. If the producer retries, it results in some messages being persisted multiple times.\\n\\nIn order to address the remaining challenges described above, we\u2019ve strengthened the Pulsar\u2019s delivery semantics by introducing a Pulsar Transaction API to support atomic writes and acknowledgements across multiple topics. The addition of the Transaction API to Apache Pulsar completes our vision of making Pulsar a complete unified messaging and streaming platform.\\n\\nPulsar PMC member, Penghui Li, goes over this functionality in great detail in his recent blog, Exactly-once Semantics with Transactions in Pulsar. You can read it to learn more about the [exactly-once semantics support in Pulsar](https://streamnative.io/en/blog/release/2021-06-14-exactly-once-semantics-with-transactions-in-pulsar).\\n\\n# Building a Unified Messaging and Streaming Platform with Apache Pulsar\\n\\n## The Evolution of Apache Pulsar\\n\\nApache Pulsar is widely adopted by hundreds of companies across the globe, including Splunk, Tencent, Verizon, and Yahoo! JAPAN, just to name a few. Born as a cloud-native distributed messaging system, Apache Pulsar has evolved into a complete messaging and streaming platform for publishing and subscribing, storing, and processing streams of data at scale and in real-time. \\n\\nBack in 2012 the Yahoo! team was looking for a global, geo-replicated infrastructure that could manage all of Yahoo!\u2019s messaging data. After vetting the messaging and streaming landscape it became clear that existing technologies were not able to serve the need for an event-driven organization. As a result, the team at Yahoo! set out to build its own.\\n\\nAt the time, there were generally two types of systems to handle in-motion data: message queues that handled mission-critical business events in real-time, and streaming systems that handled scalable data pipelines at scale. Companies had to limit their capabilities to one or the other, or they had to adopt multiple different technologies. If they chose multiple technologies, they would end up with a complex infrastructure that often resulted in data segregation and data silos, with one silo for message queues used to build application services and the other silo for streaming systems used to build data services. The figure below illustrates what this can look like. \\n\\n![](/img/280-1.png)\\n\\nHowever, with the diversity of data that companies need to process beyond operational data (like log data, click events, etc), coupled with the increase in the number of downstream systems that need access to combined business data and operational data, the system would need to support message queueing and streaming. \\n\\nBeyond that, companies need an infrastructure platform that would allow them to build all of their applications on top of it, and then have those applications handle in-motion data (messaging and streaming data) by default. This way real-time data infrastructure could be significantly simplified, as illustrated in the diagram below.\\n\\n![](/img/280-2.png)\\n\\nWith that vision, the Yahoo! team started working on building a unified messaging and streaming platform for in-motion data. Below is an overview of the key milestones on the Pulsar journey, from inception to today.\\n\\n## Step 1: A scalable storage for streams of data\\n\\nThe journey of Pulsar began with Apache BookKeeper. Apache BookKeeper implements a log-like abstraction for continuous streams and provides the ability to run it at internet-scale with simple write-read log APIs. A log provides a great abstraction for building distributed systems, such as distributed databases and pub-sub messaging. The write APIs are in the form of appends to the log. And the read APIs are in the form of continuous read from a starting offset defined by the readers. The implementation of BookKeeper created the foundation - a scalable log-backed messaging and streaming system. \\n\\n## Step 2: A multi-layered architecture that separates compute from storage.\\n\\nOn top of the scalable log storage, a stateless serving layer was introduced which runs stateless brokers for publishing and consuming messages. This multi-layered architecture separates serving/compute from storage, allowing Pulsar to manage serving and storage in separate layers.\\n\\nThis architecture also ensures instant scalability and higher availability. Both of these factors are extremely important and make Pulsar well-suited for building mission-critical services, such as billing platforms for financial use cases, transaction processing systems for e-commerce and retailers, and real-time risk control systems for financial institutions.\\n\\n## Step 3: Unified messaging model and API\\n\\nIn a modern data architecture, the real-time use cases can typically be categorized into two categories: queueing and streaming. Queueing is typically used for building core business application services while streaming is typically used for building real-time data services such as data pipelines.\\n\\nTo provide one platform able to serve both application and data services required a unified messaging model that integrates queuing and streaming semantics. The Pulsar topics become the source of truth for consumption. Messages can be stored only once on topics, but can be consumed in different ways via different subscriptions. Such unification significantly reduces the complexity of managing and developing messaging and streaming applications.\\n\\n## Step 4: Schema API\\n\\nNext, a new Pulsar schema registry and a new type-safe producer & consumer API were added. The built-in schema registry enables message producers and consumers on Pulsar topics to coordinate on the structure of the topic\u2019s data through the Pulsar broker itself, without needing an external coordination mechanism. With data schemas, every single piece of data traveling through Pulsar is completely discoverable, enabling you to build systems that can easily adapt as the data changes.\\n\\nFurthermore, the schema registry keeps track of data compatibility between versions of the schema. As the new schemas are uploaded the registry ensures that new schema versions are able to be read by old consumers. This ensures that Producers cannot break Consumers.\\n\\n## Step 5: Functions and IO API\\n\\nThe next step was to build APIs that made it easy to get data in and out of Pulsar and process it. The goal was to make it easy to build event-driven applications and real-time data pipelines with Apache Pulsar, so you can then process those events when they arrive, no matter where they originated from. \\n\\nThe Pulsar IO API allows you to build real-time streaming data pipelines by plugging various source connectors to get data from external systems into Pulsar and sink connectors to get data from Pulsar into external systems. Today, Pulsar provides several built-in connectors that you can use. \\n\\nAdditionally, StreamNative Hub (a registry of Pulsar connectors) provides dozens of connectors integrated with popular data systems. If the IO API is for building streaming data pipelines, the Functions API is for building event-driven applications and real-time stream processors. \\n\\nThe serverless function concepts were adopted into stream processing and then built the Functions API as a lightweight serverless library that you can write any event processing logic using any language you like. The underlying motivation was to enable your engineering team to write stream processing logic without the operational complexity of running and maintaining yet another cluster.\\n\\n## Step 6: Infinite storage for Pulsar via Tiered Storage\\n\\nAs adoption of Apache Pulsar continued and the amount of data stored in Pulsar increased, users eventually hit a \u201cretention cliff\u201d, at which point it became significantly more expensive to store, manage, and retrieve data in Apache BookKeeper. To work around this, operators and application developers typically use an external store like AWS S3 as a sink for long-term storage. This means you lose most of the benefits of Pulsar\u2019s immutable stream and ordering semantics, and instead end up having to manage two different systems with different access patterns.\\n\\nThe introduction of Tiered Storage allows Pulsar to offload the majority of the data to a remote cloud-native storage. This cheaper form of storage readily scales with the volume of data. More importantly, with the addition of Tiered Storage, Pulsar provides the batch storage capabilities needed to support batch processing when integrating with a unified batch and stream processor like Flink. The unified batch and stream processing capabilities integrated with Pulsar enable companies to query real-time streams with historical context quickly and easily, unlocking a unique competitive advantage.\\n\\n## Step 7: Protocol Handler\\n\\nAfter introducing tiered storage, Pulsar evolved from a Pub/Sub messaging system into a scalable stream data system that can ingest, store, and process streams of data. However, existing applications written using other messaging protocols such as Kafka, AMQP, MQTT, etc had to be rewritten to adopt Pulsar\u2019s messaging protocol.\\n\\nThe Protocol Handler API  further reduces the overhead of adopting Pulsar for building messaging and streaming applications, and allows developers to extend Pulsar capabilities to other messaging domains by leveraging all the benefits provided by Pulsar architecture. This resulted in major collaborations between Pulsar and other industry leaders to develop popular protocol handlers including:\\n- [Kafka-on-Pulsar (KoP)](https://hub.streamnative.io/protocol-handlers/kop/0.2.0), which was [launched in March 2020](https://streamnative.io/en/blog/tech/2020-03-24-bring-native-kafka-protocol-support-to-apache-pulsar) by OVHCloud and StreamNative. \\n- [AMQP-on-Pulsar (AoP)](https://hub.streamnative.io/protocol-handlers/aop/0.1.0), which was [announced in June 2020](https://streamnative.io/en/blog/tech/2020-06-15-announcing-aop-on-pulsar) by China Mobile and StreamNative.\\n- [MQTT-on-Pulsar (MoP)](https://hub.streamnative.io/protocol-handlers/mop/0.2.0), which was [announced in August 2020](https://streamnative.io/en/blog/tech/2020-09-28-announcing-mqtt-on-pulsar) by StreamNative.\\n- [RocketMQ-on-Pulsar (RoP)](https://github.com/streamnative/rop), which was launched in May 2021 by Tencent Cloud and StreamNative.\\n\\n## Step 8: Transaction API for exactly-once stream processing\\n\\nMore recently, transactions were added to Apache Pulsar to enable exactly-once semantics for stream processing. This is a fundamental feature that provides a strong guarantee for streaming data transformations, making it easy to build scalable, fault-tolerant, stateful messaging and streaming applications that process streams of data.\\n\\nFurthermore, the transaction API capabilities are not limited to a given language client. Pulsar\u2019s support for transactional messaging and streaming is primarily a protocol-level capability that can be presented in any language. Such protocol-level capability can be leveraged in all kinds of applications. \\n\\n# Building an ecosystem for unified messaging and streaming\\n\\nIn addition to contributing to the Pulsar technology, the community is also working to build a robust ecosystem to support it. Pulsar\u2019s ability to support a rich ecosystem of pub-sub libraries, connectors, functions, protocol handlers, and integrations with popular query engines will enable Pulsar adopters to streamline workflows and achieve new use cases.\\n\\n# What is Next?\\n\\nIf you are interested in learning more about Pulsar 2.8.0, you can [download 2.8.0](https://pulsar.apache.org/en/versions/) and try it out today! \\n\\nIf you want to learn more about how companies have adopted Pulsar, you can [sign up](https://hopin.com/events/pulsar-summit-north-america-2021) for Pulsar Summit NA 2021!\\n\\nFor more information about the Apache Pulsar project and the progress, please visit the official website at https://pulsar.apache.org and follow the project on Twitter [@apache_pulsar](https://twitter.com/apache_pulsar)."},{"id":"/2021/05/13/Apache-Pulsar-2-7-2","metadata":{"permalink":"/blog/2021/05/13/Apache-Pulsar-2-7-2","editUrl":"https://github.com/apache/pulsar/edit/master/site2/website-next/blog/2021-05-13-Apache-Pulsar-2-7-2.md","source":"@site/blog/2021-05-13-Apache-Pulsar-2-7-2.md","title":"Apache Pulsar 2.7.2","description":"We are very glad to see the Apache Pulsar community has successfully released the 2.7.2 version.","date":"2021-05-13T00:00:00.000Z","formattedDate":"May 13, 2021","tags":[],"readingTime":1.305,"truncated":true,"authors":[{"name":"Enrico Olivelli","url":"https://twitter.com/eolivelli"}],"prevItem":{"title":"Apache Pulsar 2.8.0","permalink":"/blog/2021/06/12/Apache-Pulsar-2-8-0"},"nextItem":{"title":"Apache Pulsar 2.7.0","permalink":"/blog/2020/12/24/Apache-Pulsar-2-7-0"}},"content":"We are very glad to see the Apache Pulsar community has successfully released the 2.7.2 version.\\nThis is a minor release that introduces stability fixes and a few new features without breaking changes.\\n\\n\x3c!--truncate--\x3e\\n\\n### News and noteworthy\\n\\nHere is a selection of the most awesome and major enhancements added to Pulsar 2.7.2.\\n\\n- Improvement in stability in the Kinesis connector [#10420](https://github.com/apache/pulsar/pull/10420).\\n- Improvement in passing ENV variables to the bookie (PULSAR_EXTRA_OPTS) [#10397](https://github.com/apache/pulsar/pull/10397).\\n- Allow the C++ client to be built in Windows and add CI for verification [#10387](https://github.com/apache/pulsar/pull/10387).\\n- Allow activating every BookKeeper client features in the broker [#9232](https://github.com/apache/pulsar/pull/9232).\\n- Improvement in Pulsar proxy.\\n- Upgrade core networking libraries: Jetty and Netty.\\n\\n[Here](https://github.com/apache/pulsar/pulls?page=1&q=is%3Apr+label%3Arelease%2F2.7.2]) you can find the list of all the improvements and bug fixes.\\n\\n### Contributors for 2.7.2 release\\n\\nWe would like to thank all the contributors for this release.\\nSame to other sustainable open source projects, Apache Pulsar is great because it is supported by a vibrant community.\\n\\nCode contributors (names taken from GitHub API):\\nAli Ahmed, Andrey Yegorov, Binbin Guo, David Kjerrumgaard, Deon van der Vyver, Devin Bost, Enrico Olivelli, Guangning E, Kevin Wilson,\\nLari Hotari, Marvin Cai, Masahiro Sakamoto, Matteo Merli, Michael Marshall, Rajan Dhabalia, Shen Liu, Ting Yuan, Vincent Royer,\\nYong Zhang, Yunze Xu, Zhanpeng Wu, Zike Yang, baomingyu, CongBo, dockerzhang, feynmanlin, hangc0276, li jinquan, limingnihao,\\nlinlinnn, mlyahmed, PengHui Li, Ran.\\n\\nDocumentation contributors:\\nAnonymitaet (Yu Liu), Jennifer Huang\\n\\nAlso, we want to thank everyone who spent his time reporting issues and sharing the story about using Pulsar.\\n\\nLooking forward to your contributions to [Apache Pulsar](https://github.com/apache/pulsar)."},{"id":"/2020/12/24/Apache-Pulsar-2-7-0","metadata":{"permalink":"/blog/2020/12/24/Apache-Pulsar-2-7-0","editUrl":"https://github.com/apache/pulsar/edit/master/site2/website-next/blog/2020-12-24-Apache-Pulsar-2-7-0.md","source":"@site/blog/2020-12-24-Apache-Pulsar-2-7-0.md","title":"Apache Pulsar 2.7.0","description":"We are very glad to see the Apache Pulsar community has successfully released the wonderful 2.7.0 version after accumulated hard work. It is a great milestone for this fast-growing project and the whole Pulsar community. This is the result of a huge effort from the community, with over 450 commits and a long list of new features, improvements, and bug fixes.","date":"2020-12-24T00:00:00.000Z","formattedDate":"December 24, 2020","tags":[],"readingTime":4.185,"truncated":true,"authors":[{"name":"Penghui Li","url":"https://twitter.com/lipenghui6"}],"prevItem":{"title":"Apache Pulsar 2.7.2","permalink":"/blog/2021/05/13/Apache-Pulsar-2-7-2"},"nextItem":{"title":"Apache Pulsar 2.6.2","permalink":"/blog/2020/11/09/Apache-Pulsar-2-6-2"}},"content":"We are very glad to see the Apache Pulsar community has successfully released the wonderful 2.7.0 version after accumulated hard work. It is a great milestone for this fast-growing project and the whole Pulsar community. This is the result of a huge effort from the community, with over 450 commits and a long list of new features, improvements, and bug fixes.\\n\\nHere is a selection of the most interesting and major features added to Pulsar 2.7.0.\\n\\n\x3c!--truncate--\x3e\\n\\n## Major features\\n\\n### Transaction support\\n\\nTransactional semantics enable event streaming applications to consume, process, and produce messages in one atomic operation. With transactions, Pulsar achieves the exactly-once semantics for a single partition and multiple partitions as well. This enables new use cases with Pulsar where a client (either as a producer or consumer) can work with messages across multiple topics and partitions and ensure those messages will all be processed as a single unit. This will strengthen the message delivery semantics of Apache Pulsar and processing guarantees for Pulsar Functions.\\n\\nCurrently, Pulsar transactions are in developer preview. The community will work further to enhance the feature to be used in the production environment soon.\\n\\nTo enable transactions in Pulsar, you need to configure the parameter in the `broker.conf` file.\\n\\n```\\n\\ntransactionCoordinatorEnabled=true\\n\\n```\\n\\nInitialize transaction coordinator metadata, so the transaction coordinators can leverage advantages of the partitioned topic, such as load balance.\\n\\n```\\n\\nbin/pulsar initialize-transaction-coordinator-metadata -cs 127.0.0.1:2181 -c standalone\\n\\n```\\n\\nFrom the client-side, you can also enable the transactions for the Pulsar client.\\n\\n```java\\n\\nPulsarClient pulsarClient = PulsarClient.builder()\\n        .serviceUrl(\\"pulsar://localhost:6650\\")\\n        .enableTransaction(true)\\n        .build();\\n\\n```\\n\\nHere is an example to demonstrate the Pulsar transactions.\\n\\n```java\\n\\n// Open a transaction\\nTransaction txn = pulsarClient\\n        .newTransaction()\\n        .withTransactionTimeout(5, TimeUnit.MINUTES)\\n        .build()\\n        .get();\\n\\n//  Publish messages with the transaction\\nproducer.newMessage(txn).value(\\"Hello Pulsar Transaction\\".getBytes()).send();\\n\\n// Consume and acknowledge messages with the transaction\\nMessage<byte[]> message = consumer.receive();\\nconsumer.acknowledgeAsync(message.getMessageId(), txn);\\n\\n// Commit the transaction\\ntxn.commit()\\n\\n```\\n\\nFor more details about the Pulsar transactions, refer to [here](http://pulsar.apache.org/docs/en/transactions/). For more details about the design of Pulsar transactions, refer to [here](https://github.com/apache/pulsar/wiki/PIP-31%3A-Transaction-Support).\\n\\n### Topic level policy\\n\\nPulsar 2.7.0 introduces the system topic which can maintain all policy change events to achieve the topic level policy. All policies at the namespace level are now also available at the topic level, so users can set different policies at the topic level flexibly without using lots of metadata service resources. The topic level policy enables users to manage topics more flexibly and adds no burden to ZooKeeper.\\n\\nTo enable topic level policy in Pulsar, you need to configure the parameter in the `broker.conf` file.\\n\\n```\\n\\nsystemTopicEnabled=true\\ntopicLevelPoliciesEnabled=true\\n\\n```\\n\\nAfter topic level policy is enabled, you can use Pulsar Admin to update the policy of a topic. Here is an example for setting the data retention for a specific topic.\\n\\n```\\n\\nbin/pulsar-admin topics set-retention -s 10G -t 7d persistent://public/default/my-topic\\n\\n```\\n\\nFor more details about the system topic and topic level policy, refer to [here](https://github.com/apache/pulsar/wiki/PIP-39%3A-Namespace-Change-Events)\\n\\n### Support Azure BlobStore offloader\\n\\nIn Pulsar 2.7.0, we add support for Azure BlobStore offloader, which allows users to offload topic data into Azure BlobStore. You can configure the Azure BlobStore offloader driver in the configuration `broker.conf` file.\\n\\n```\\n\\nmanagedLedgerOffloadDriver=azureblob\\n\\n```\\n\\nFor more details, refer to [here](https://github.com/apache/pulsar/pull/8436).\\n\\n### Native protobuf schema support\\n\\nPulsar 2.7.0 introduces a native protobuf schema support, which can provide more ability for protobuf users who want to integrate with Pulsar. Here is an example to show how to use native protobuf schema in Java client:\\n\\n```java\\n\\nConsumer<PBMessage> consumer = client.newConsumer(Schema.PROTOBUFNATIVE(PBMessage.class))\\n.topic(topic)\\n.subscriptionName(\\"my-subscription-name\\")\\n.subscribe();\\n\\n```\\n\\nFor more details, refer to [here](https://github.com/apache/pulsar/pull/8372).\\n\\n### Resource limitation\\n\\nIn Pulsar, tenant, namespace, and topic are the core resources of a cluster. Pulsar 2.7.0 enables you to limit the maximum tenants of a cluster, the maximum namespaces per tenant, the maximum topics per namespace, and the maximum subscriptions per topic.\\n\\nYou can configure the resource limitations in the `broker.conf` file.\\n\\n```\\n\\nmaxTenants=0\\nmaxNamespacesPerTenant=0\\nmaxTopicsPerNamespace=0\\nmaxSubscriptionsPerTopic=0\\n\\n```\\n\\nThis provides Pulsar administrators with great convenience in resource management.\\n\\n### Support e2e encryption for Pulsar Functions\\n\\nPulsar 2.7.0 enables you to add End-to-End (e2e) encryption for Pulsar Functions. You can use the public and private key pair that the application configured to perform encryption. Only consumers with a valid key can decrypt encrypted messages.\\n\\nTo enable End-to-End encryption on Functions Worker, you can set it by specifying `--producer-config` in the command line terminal. For more information, refer to [Pulsar Encryption](http://pulsar.apache.org/docs/en/security-encryption/).\\n\\nFor more details, you can see [here](https://github.com/apache/pulsar/pull/8432)\\n\\n### Function rebalance\\n\\nBefore 2.7.0, there was no mechanism for rebalancing functions scheduler on workers. The workload for functions m become skewed. Pulsar 2.7.0 supports manual trigger functions rebalance and automatic periodic functions rebalance.\\n\\nFor more details, refer to https://github.com/apache/pulsar/pull/7388  and https://github.com/apache/pulsar/pull/7449.\\n\\n## More information\\n\\n- To download Apache Pulsar 2.7.0, click [here](https://pulsar.apache.org/en/download/).\\n- For more information about Apache Pulsar 2.7.0, see [2.7.0 release notes](https://pulsar.apache.org/release-notes/#2.7.0) and [2.7.0 PR list](https://github.com/apache/pulsar/pulls?q=milestone%3A2.7.0+-label%3Arelease%2F2.6.2+-label%3Arelease%2F2.6.1+).\\n\\nIf you have any questions or suggestions, contact us with mailing lists or slack.\\n\\n- [users@pulsar.apache.org](mailto:users@pulsar.apache.org)\\n- [dev@pulsar.apache.org](mailto:dev@pulsar.apache.org)\\n- Pulsar slack channel: https://apache-pulsar.slack.com/\\n- Self-registration at https://apache-pulsar.herokuapp.com/\\n\\nLooking forward to your contributions to [Apache Pulsar](https://github.com/apache/pulsar)."},{"id":"/2020/11/09/Apache-Pulsar-2-6-2","metadata":{"permalink":"/blog/2020/11/09/Apache-Pulsar-2-6-2","editUrl":"https://github.com/apache/pulsar/edit/master/site2/website-next/blog/2020-11-09-Apache-Pulsar-2-6-2.md","source":"@site/blog/2020-11-09-Apache-Pulsar-2-6-2.md","title":"Apache Pulsar 2.6.2","description":"We are excited to see that the Apache Pulsar community has successfully released the 2.6.2 version after a lot of hard work. It is a great milestone for this fast-growing project and the Pulsar community. 2.6.2 is the result of a big effort from the community, with over 154 commits and a long list of improvements and bug fixes.","date":"2020-11-09T00:00:00.000Z","formattedDate":"November 9, 2020","tags":[],"readingTime":10.915,"truncated":true,"authors":[{"name":"Xiaolong Ran","url":"https://twitter.com/wolf4j1"}],"prevItem":{"title":"Apache Pulsar 2.7.0","permalink":"/blog/2020/12/24/Apache-Pulsar-2-7-0"},"nextItem":{"title":"Pulsar Summit Asia 2020 Schedule is Now Online","permalink":"/blog/2020/11/04/pulsar-summit-asia-schedule"}},"content":"We are excited to see that the Apache Pulsar community has successfully released the 2.6.2 version after a lot of hard work. It is a great milestone for this fast-growing project and the Pulsar community. 2.6.2 is the result of a big effort from the community, with over 154 commits and a long list of improvements and bug fixes.\\n\\nHere are some highlights and major features added in Pulsar 2.6.2.\\n\\n\x3c!--truncate--\x3e\\n\\n## Broker\\n\\n### Catch `throwable` when starting Pulsar\\n\\nBefore 2.6.2, Pulsar catched exceptions only when `BrokerStarter.start()` failed. Some errors such as `NoSuchMethodError` or `NoClassDefFoundError` could not be caught, and Pulsar was in abnormal status yet no error log was found in the log file.\\n\\nIn 2.6.2, we modify exceptions to use `throwable` to avoid this issue.\\n\\nFor more information about implementation, see [PR-7221](https://github.com/apache/pulsar/pull/7221).\\n\\n### Handle SubscriptionBusyException in resetCursor API\\n\\nIn `PersistentSubscription.resetCursor` method, `SubscriptionFencedException` is thrown in several places, but it is not handled in `PersistentTopicBase`, so error messages are not clear.\\n\\nIn 2.6.2, we export `SubscriptionBusyException` in `PersistentTopicBase` for `resetCursor`, so error messages in the REST API are clear. \\n\\nFor more information about implementation, see [PR-7335](https://github.com/apache/pulsar/pull/7335).\\n\\n### Update Jersey to 2.31\\n\\nBefore 2.6.1, Pulsar used the Jersey 2.27, which has security concerns. In Pulsar 2.6.2, we update the Jersey version to the latest stable version(2.31) to enhance security.\\n\\nFor more information about implementation, see [PR-7515](https://github.com/apache/pulsar/pull/7515).\\n\\n### Stop to dispatch when consumers using the Key_Shared subscription stuck\\n\\nConsumers using the `Key_Shared` subscription would encounter disorder messages occasionally. The following are steps to reproduce the situation:\\n\\n1. Connect Consumer1 to Key_Shared subscription `sub` and stop to receive\\n  - receiverQueueSize: 500\\n2. Connect Producer and publish 500 messages with key `(i % 10)`\\n3. Connect Consumer2 to same subscription and start to receive\\n  - receiverQueueSize: 1\\n  - since https://github.com/apache/pulsar/pull/7106, Consumer2 can\'t receive (expected)\\n4. Producer publish more 500 messages with same key generation algorithm\\n5. After that, Consumer1 start to receive\\n6. Check Consumer2 message ordering\\n  - sometimes message ordering was broken in same key\\n\\nIn 2.6.2, when consumers use the Key_Shared subscription, Pulsar stops dispatching messages to consumers that are stuck on delivery to guarantee message order. \\n\\nFor more information about implementation, see [PR-7553](https://github.com/apache/pulsar/pull/7553).\\n\\n### Reestablish namespace bundle ownership from false negative releasing and false positive acquiring\\n\\nIn acquiring/releasing namespace bundle ownership, ZooKeeper might be disconnected before or after these operations are persisted in the ZooKeeper cluster. It leads to inconsistency between the local ownership cache and ZooKeeper cluster.\\n\\nIn 2.6.2, we fix the issue with the following:\\n\\n* In ownership releasing, do not retain ownership in failure.\\n* In ownership checking, querying and acquiring, reestablish the lost ownership in false negative releasing and false positive acquiring.\\n\\nFor more information about implementation, see [PR-7773](https://github.com/apache/pulsar/pull/7773).\\n\\n### Enable users to configure the executor pool size\\n\\nBefore 2.6.2, the executor pool size in Pulsar was set to `20` when starting Pulsar services. Users could not configure the executor pool size.\\n\\n```\\n\\nprivate final ScheduledExecutorService executor = Executors.newScheduledThreadPool(20,\\n           new DefaultThreadFactory(\\"pulsar\\"));\\n\\n```\\n\\nIn 2.6.2, users can configure the executor pool size in the `broker.conf` file based on their needs.\\n\\nFor more information about implementation, see [PR-7782](https://github.com/apache/pulsar/pull/7782).\\n\\n### Add replicated check for `checkInactiveSubscriptions`\\n\\nAfter the replicated subscription is deleted by `checkInactiveSubscriptions`, replicated subscriptions are created with `receiveSubscriptionUpdated`. In this case, the position becomes the latest position.\\n\\n```\\n\\ntopic.createSubscription(update.getSubscriptionName(),\\n        InitialPosition.Latest, true /* replicateSubscriptionState */);\\n\\n```\\n\\nIn 2.6.2, the replicated subscription is excluded from automatic deletion by fixing the `PersistentTopic`.\\n\\nFor more information about implementation, see [PR-8066](https://github.com/apache/pulsar/pull/8066).\\n\\n### Upgrade jetty-util version to 9.4.31\\n\\nPulsar client depends on jetty-util. Jetty-util versions earlier than 9.4.30 contain known vulnerabilities.\\n\\nIn 2.6.2, we upgrade the jetty-util version to `9.4.31` to enhance security.\\n\\nFor more information about implementation, see [PR-8035](https://github.com/apache/pulsar/pull/8035).\\n\\n### Add command to delete a cluster\'s metadata from ZooKeeper\\n\\nWhen we share the same ZooKeeper and BookKeeper cluster among multiple broker clusters, if a cluster was removed, its metadata in ZooKeeper were also removed.\\n\\nIn 2.6.2, we fix the issue in the following ways:\\n\\n- Add a `PulsarClusterMetadataTeardown` class to delete the relative nodes from ZooKeeper;\\n- Wrap the class to `bin/pulsar` script.\\n\\nFor more information about implementation, see [PR-8169](https://github.com/apache/pulsar/pull/8169).\\n\\n### Replace EventLoop with ThreadPoolExecutor to improve performance instead of EventLoop\\n\\nIn 2.6.2, we replace EventLoop with a native JDK thread pool(ThreadPoolExecutor) to improve performance.\\n\\nThe following is the test result with pulsar perf.\\n\\nBefore 2.6.1:\\n\\n```\\n\\nAggregated throughput stats --- 11715556 records received --- 68813.420 msg/s --- 537.605 Mbit/s\\n\\n```\\n\\nIn 2.6.2\uff1a\\n\\n```\\n\\nAggregated throughput stats --- 18392800 records received --- 133314.602 msg/s --- 1041.520 Mbit/s\\n\\n```\\n\\nFor more information about implementation, see [PR-8208](https://github.com/apache/pulsar/pull/8208).\\n\\n### Fix deadlock that occurred during topic ownership check\\n\\nSome broker servers had deadlocks while splitting namespace bundles. When checking the thread dump of the broker, some threads were blocked in `NamespaceService#getBundle()`.\\n\\n```\\n\\n\\"pulsar-ordered-OrderedExecutor-7-0\\" #34 prio=5 os_prio=0 tid=0x00007eeeab05a800 nid=0x81a5 waiting on condition [0x00007eeeafbd2000]\\n  java.lang.Thread.State: WAITING (parking)\\n       at sun.misc.Unsafe.park(Native Method)\\n       - parking to wait for  <0x00007f17fa965418> (a java.util.concurrent.CompletableFuture$Signaller)\\n       at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)\\n       at org.apache.pulsar.common.naming.NamespaceBundleFactory.getBundles(NamespaceBundleFactory.java:155)\\n...\\n\\n```\\n\\nThe reason for the issue is that the `getBundle()` method leads to deadlock in `NamespaceService#isTopicOwned()`. To fix the issue, we remove the `getBundle()` method. When `isTopicOwned()` returns `false`, the bundle metadata is cached and can be got asynchronously. When the client reconnects the next time, Pulsar returns the correct bundle metadata from the cache.\\n\\nFor more information about implementation, see [PR-8406](https://github.com/apache/pulsar/pull/8406).\\n\\n## Proxy\\n\\n### Enable users to configure `advertisedAddress` in proxy \\n\\nBefore 2.6.2, users could not configure `advertisedAddress` on the proxy side. In 2.6.2, users can configure `advertisedAddress` in proxy just as they do in Pulsar broker.\\n\\nFor more information about implementation, see [PR-7542](https://github.com/apache/pulsar/pull/7542).\\n\\n### Add proxy plugin interface to support user defined additional servlet\\n\\nTo enable users to access the broker flexibly, Pulsar provides plugins similar to broker protocol and broker interceptor. However, users could not access the proxy before 2.6.2.\\n\\nTo enable users to customize data requests in proxy, we add the protocol plugin for proxy in 2.6.2.\\n\\nFor more information about implementation, see [PR-8067](https://github.com/apache/pulsar/pull/8067).\\n\\n### Fix the null exception when starting the proxy service\\n\\nWhen enabling the broker TLS and broker client authentication with OAuth2 plugin,\\nthe proxy service exits with an unexpected null exception.\\n\\nThe reason is that when initializing the flow, authentication is called, so the token client is not initialized before using.\\n\\nIn 2.6.2, we fix the null exception when starting the proxy service.\\n\\nFor more information about implementation, see [PR-8019](https://github.com/apache/pulsar/pull/8019).\\n\\n## Java Client\\n\\n### Support input-stream for trustStore cert\\n\\nIn 2.6.1, Pulsar supports dynamic cert loading by using input stream for TLS cert and key file. The feature is mainly used by container. However, container also requires dynamic loading for truststore certs and users cannot store trust-store cert into file-system. \\n\\nIn 2.6.2, Pulsar supports loading truststore cert dynamically using input stream.\\n\\nFor more information about implementation, see [PR-7442](https://github.com/apache/pulsar/pull/7442).\\n\\n### Avoid subscribing the same topic\\n\\nThe current key of `MultiTopicsConsumerImpl.topics` is the topic name passed by the user. The `topicNameValid` method checks if the name is valid and `topics` doesn\'t contain the key.\\n\\nHowever, if a multi-topic consumer subscribes a partition of a subscribed partitioned topic,  `subscribeAsync` succeeds and a new `ConsumerImpl` of the same partition is created, which is redundant.\\n\\nAlso, if a multi-topic consumer subscribes `public/default/topic` or `persistent://public/default/topic`, while the initial subscribed topic is `topic`, the redundant consumers would be created.\\n\\nIn 2.6.2, we fix the issue in the following ways to avoid subscribing the same topic again:\\n\\n- Use the full topic name as key for `MultiTopicsConsumerImpl.topics`.\\n- Check that both the full topic name and the full partitioned topic name do not exist in `MultiTopicsConsumerImpl.topics` when `subscribeAsync` is called.\\n- Throw a different exception to a different topic is invalid and the topic is already subscribed\\n\\nFor more information about implementation, see [PR-7823](https://github.com/apache/pulsar/pull/7823).\\n\\n## CPP Client\\n\\n### Wait for all seek operations complete\\n\\nWhen a partitioned consumer calls `seek`, it waits for only one partition\'s seek operation completion because each internal consumer calls callback(result) to complete the same promise.\\n\\nIn 2.6.2, we use the following methods to avoid this problem:\\n\\n- Add a `MultiResultCallback` implementation, the callback completes only when all N events complete successfully or one of N events fails.\\n- Use `MultiResultCallback` to wrap callback from `PartitionedConsumerImpl::seekAsync`.\\n\\nFor more information about implementation, see [PR-7216](https://github.com/apache/pulsar/pull/7216).\\n\\n### Make `clear()` thread-safe\\n\\nBefore 2.6.2, the `clear()` methods of `BatchAcknowledgementTracker` and `UnAckedMessageTrackerEnabled` are not thread-safe.\\n\\nIn 2.6.2, we acquire a mutex in these `clear()` methods to make it thread-safe.\\n\\nFor more information about implementation, see [PR-7862](https://github.com/apache/pulsar/pull/7862).\\n\\n### Add Snappy library to Docker images for building C++ packages\\n\\nThe program crashes when Snappy compression is enabled on the C++ client packaged as RPM/DEB. This is because Snappy library is not included in the Docker image for building the RPM/DEB package.\\n\\nIn 2.6.2, we add the Snappy library to the docker images to avoid the issue.\\n\\nFor more information about implementation, see [PR-8086](https://github.com/apache/pulsar/pull/8086).\\n\\n### Support key based batching\\n\\nSupport key based batching for the C++ client. In addition, currently, the implementation of `BatchMessageContainer` is coupling to `ProducerImpl` tightly. The batch message container registers a timer to the producer\'s executor and the timeout callback is also the producer\'s method. Even its `add` method could call `sendMessage` to send a batch to the producer\'s pending queue. These should be the producer\'s work.\\n\\nIn 2.6.2, we implement the feature in the following ways:\\n\\n- Add a `MessageAndCallbackBatch` to store a `MessageImpl` of serialized single messages and a callback list.\\n- Add a `BatchMessageContainerBase` to provide interface methods and methods like update/clear message number/bytes, create `OpSendMsg`.\\n- Let `ProducerImpl` manage the batch timer and determine whether to create `OpSendMsg` from `BatchMessageContainerBase` and send it.\\n- Make `BatchMessageContainer` inherit `BatchMessageContainerBase`, it only manages a `MessageAndCallbackBatch`.\\n- Add a `BatchMessageKeyBasedContainer` that inherits `BatchMessageContainerBase`, it manages a map of message key and `MessageAndCallbackBatch`.\\n- Add a producer config to change batching type.\\n\\nFor more information about implementation, see [PR-7996](https://github.com/apache/pulsar/pull/7996).\\n\\n## Functions\\n\\n### Enable Kubernetes runtime to customize function instance class path\\n\\nBefore 2.6.2, the function worker\'s classpath is used to configure the function instance (runner)\'s classpath. When the broker (function worker) uses an image that is different from the function instance (runner) for Kubernetes runtime, the classpath is wrong and the function instance could not load the instance classes.\\n\\nIn 2.6.2, we add a function instance classpath entry to the Kubernetes runtime config, and construct the function launch command accordingly.\\n\\nFor more information about implementation, see [PR-7844](https://github.com/apache/pulsar/pull/7844).\\n\\n### Set `dryrun` of Kubernetes Runtime to null\\n\\nBefore 2.6.2, we upgraded the `client-java` of Kubernetes to `0.9.2` to enhance security. However, during the creation of statefulsets, secrets, and services, the value of `dryrun` was set to `true`, which was not accepted by Kubernetes. Only `All` is allowed in Kubernetes. \\n\\nIn 2.6.2, we set the `dryrun` of Kubernetes Runtime to null.\\n\\nFor more information about implementation, see [PR-8064](https://github.com/apache/pulsar/pull/8064).\\n\\n## Pulsar SQL\\n\\n### Upgrade Presto version to 332\\n\\nUpgrade Presto version to 332. Resolve different packages between prestosql and prestodb. Although the latest version is 334, versions higher than 333 require Java 11.\\n\\nFor more information about implementation, see [PR-7194](https://github.com/apache/pulsar/pull/7194).\\n\\n## pulsar-admin\\n\\n### Add CLI command to get the last message ID\\n\\nAdd `last-message-id` command in CLI, so users can get the last message ID with this command.\\n\\nFor more information about implementation, see [PR-8082](https://github.com/apache/pulsar/pull/8082).\\n\\n### Support deleting schema ledgers when deleting topics\\n\\nUsers could not delete schema of topics with the `PersistentTopics#deleteTopic` and `PersistentTopics#deletePartitionedTopic` in REST APIs. After topics were deleted, the schema ledgers still existed with adding an empty schema ledger.\\n\\nIn 2.6.2, we implement the feature in the following ways:\\n\\n- Add a `deleteSchema` query param to REST APIs of deleting topics/partitioned topics;\\n- Add a map to record the created ledgers in `BookkeeperSchemaStorage`;\\n- Expose `deleteSchema` param in pulsar-admin APIs;\\n- Delete schema ledgers when deleting the cluster with `-a` option.\\n\\nFor more information about implementation, see [PR-8167](https://github.com/apache/pulsar/pull/8167).\\n\\n### Support deleting all data associated with a cluster\\n\\nWhen multiple broker clusters shared the same bookie cluster, if users wanted to remove a broker cluster, the associated ledgers in bookies were not deleted as expected.\\n\\nIn 2.6.2, we add a `cluster delete` command to enable users to delete all the data associated with the cluster.\\n\\nFor more information about implementation, see [PR-8133](https://github.com/apache/pulsar/pull/8133).\\n\\n## Pulsar Perf\\n\\n### Enable users to configure ioThread number in pulsar-perf\\n\\nIn pulsar-perf, the default Pulsar client ioThread number is `Runtime.getRuntime().availableProcessors()` and users could not configure it in the command line. When running a pulsar-perf producer, it may cause messages to enqueue competition and lead to high latency.\\n\\nIn 2.6.2, we implement the feature in the following ways:\\n\\n1. Enable users to configure the ioThread number in the command line;\\n2. Change the default ioThead number from `Runtime.getRuntime().availableProcessors()` to `1`\\n\\nFor more information about implementation, see [PR-8090](https://github.com/apache/pulsar/pull/8090).\\n\\n## More information\\n\\n- To download Apache Pulsar 2.6.2, click [download](https://pulsar.apache.org/en/download/).\\n- For more information about Apache Pulsar 2.6.2, see [2.6.2 release notes](https://pulsar.apache.org/release-notes/#2.6.2 and [2.6.2 PR list](https://github.com/apache/pulsar/pulls?q=is%3Apr+label%3Arelease%2F2.6.2+is%3Aclosed).\\n\\nIf you have any questions or suggestions, contact us with mailing lists or slack.\\n\\n- [users@pulsar.apache.org](mailto:users@pulsar.apache.org)\\n- [dev@pulsar.apache.org](mailto:dev@pulsar.apache.org)\\n- Pulsar slack channel: https://apache-pulsar.slack.com/\\n- Self-registration at https://apache-pulsar.herokuapp.com/\\n\\nLooking forward to your contributions to [Pulsar](https://github.com/apache/pulsar)."},{"id":"/2020/11/04/pulsar-summit-asia-schedule","metadata":{"permalink":"/blog/2020/11/04/pulsar-summit-asia-schedule","editUrl":"https://github.com/apache/pulsar/edit/master/site2/website-next/blog/2020-11-04-pulsar-summit-asia-schedule.md","source":"@site/blog/2020-11-04-pulsar-summit-asia-schedule.md","title":"Pulsar Summit Asia 2020 Schedule is Now Online","description":"The Pulsar Summit is a global conference dedicated to sharing best practices, project updates, and insights across the Apache Pulsar community. Pulsar\u2019s inaugural global summit, the Pulsar Summit Virtual Conference 2020, took place in June 2020 and featured more than 30 sessions from top Pulsar experts, developers and thought-leaders from companies such as Salesforce, Verizon Media, and Splunk, and the conference attracted 600+ attendees.","date":"2020-11-04T00:00:00.000Z","formattedDate":"November 4, 2020","tags":[],"readingTime":4.035,"truncated":false,"authors":[{"name":"Carolyn King, Dianjin Wang"}],"prevItem":{"title":"Apache Pulsar 2.6.2","permalink":"/blog/2020/11/09/Apache-Pulsar-2-6-2"},"nextItem":{"title":"Pulsar Summit Asia 2020 CFP is now open","permalink":"/blog/2020/09/01/pulsar-summit-asia-2020-cfp"}},"content":"The Pulsar Summit is a global conference dedicated to sharing best practices, project updates, and insights across the Apache Pulsar community. Pulsar\u2019s inaugural global summit, the [Pulsar Summit Virtual Conference 2020](https://pulsar-summit.org/en/event/virtual-conference-2020), took place in June 2020 and featured more than 30 sessions from top Pulsar experts, developers and thought-leaders from companies such as Salesforce, Verizon Media, and Splunk, and the conference attracted 600+ attendees. \\n\\nThe rapid adoption of Apache Pulsar over the past few years has led to a high demand for Pulsar events. Today, StreamNative, a cloud-native event streaming company powered by Apache Pulsar, and also the host of [Pulsar Summit Asia 2020](https://pulsar-summit.org/en/event/asia-2020), announced more details on the upcoming event. Taking place on November 28th & 29th, the two-day event will feature more than 30 live sessions by tech leads, open-source developers, software engineers, and software architects from **Splunk, Yahoo! JAPAN, TIBCO, China Mobile, Tencent, Dada Group, KingSoft Cloud, Tuya Smart, and PingCAP**, and will include sessions on Pulsar use cases, its ecosystem, operations, and technology deep dives. \\n\\nSee below for some of our featured sessions, which include both English and Mandarin tracks:\\n- [How Splunk is using Pulsar IO \uff08English\uff09](https://pulsar-summit.org/en/event/asia-2020/sessions/how-splunk-is-using-pulsar-io) - In this talk, Jerry Peng, Principal Software Engineer at Splunk will share insights on Splunk\u2019s evaluation and decision to adopt the Pulsar IO framework, details on how Splunk\'s DSP product leverages the Pulsar IO framework, and insights on batch sources, a feature that was recently added to Pulsar IO.\\n- [Apache Pulsar at Yahoo! JAPAN - Adoption, Operational Insights and the Future\uff08English\uff09](https://pulsar-summit.org/en/event/asia-2020/sessions/apache\u2013pulsar\u2013at\u2013yahoo\u2013japan\u2013adoption\u2013operational\u2013experiences\u2013and\u2013future) - In this talk, Nozomi Kurihara, Manager of the Messaging Platform team in Yahoo!Japan Corporation will share practical use cases of Apache Pulsar on production and insights on how to operate Apache Pulsar for large scale data streams.\\n- [Running Apache Pulsar on Tencent Cloud: New Challenges, Discussion, Practice (Mandarin)](https://pulsar-summit.org/en/event/asia-2020/sessions/running-apache-pulsar-on-tencent-cloud-new-challenges-discussion-practice) - In this talk, Lin Lin, senior engineer of Tencent Cloud will address how Pulsar helps solve challenges with message queues on Tencent Cloud, such as dynamic expansion and contraction, and large numbers of partitions.\\n- [How BIGO built a Real-Time Message System with Apache Pulsar and Flink (Mandarin) ](https://pulsar-summit.org/en/event/asia-2020/sessions/how-bigo-builds-real-time-message-system-with-apache-pulsar-and-flink) - In this talk, Hang Chen, Leader of the Messaging Platform team from BIGO will share how BIGO leveraged Apache Pulsar to build a real-time message system and how they tune Pulsar for production.\\n- [A Daredevil\' Story: Apache Pulsar in Zhaopin.com (Mandarin)](https://pulsar-summit.org/en/event/asia-2020/sessions/a-daredevil-story-apache-pulsar-in-zhaopin-com) - In this talk, Shunli Gao, Senior Engineer at Zhaopin will share details on the development and future prospects of Apache Pulsar at Zhaopin.\\n- [Transactional Event Streaming with Apache Pulsar (Mandarin)](https://pulsar-summit.org/en/event/asia-2020/sessions/transactional-event-streaming-with-apache-pulsar) - In this talk, Bo Cong, software engineer at StreamNative will share how Pulsar transaction works and how it is supported by Pulsar Functions.\\n- [Benchmarking Pulsar vs. Kafka on AWS: Process & Results (Mandarin) ](https://pulsar-summit.org/en/event/asia-2020/sessions/benchmarking-pulsar-vs-kafka-on-aws-process-results) - In this talk, Penghui Li, the Apache Pulsar PMC member and software engineer at StreamNative will share the results of a benchmark test comparing Pulsar and Kafka that was run on AWS. The test ran Pulsar and Kafka under the same hardware environments on the write throughput, tailing read throughput, catchup read throughput, publish latency, and end-to-end latency of these two systems.\\n\\nMore featured talks coming soon!\\n\\nThe number and diversity of the sessions demonstrate the accelerated adoption of Pulsar in PoC and production environments, as well as the rapid development in functionalities and diverse ecosystems. To learn more about how companies leverage Pulsar for **messaging and event streaming, serverless computing, real-time analytics, event-driven applications, and mission-critical deployment management in production**, [RSVP](https://hopin.to/events/pulsar-summit-asia-2020) today!\\n\\nWe would like to say special thanks to the speakers for sharing their Pulsar expertise and experience with the community.\\n\\n\\n# About Apache Pulsar [Apache Pulsar](https://pulsar.apache.org) is a cloud-native, distributed messaging and streaming platform that manages hundreds of billions of events per day. Pulsar was originally developed at Yahoo! as the unified messaging platform connecting critical Yahoo applications such as Yahoo Finance, Yahoo Mail, and Flickr to data. \\n\\nToday, Pulsar is used for real-time event streaming use cases, including data pipelines, microservices, and stream processing. Its cloud-native architecture and built-in multi-tenancy differentiate it from its predecessors and uniquely position it as an enterprise-ready, event streaming platform. Pulsar\'s multi-layer architecture enables stability, reliability, scalability, and high performance, simplifies management and reduces costs. Its built-in multi-tenancy and geo-replication ensure that companies are able to build applications with disaster recovery. \\n\\n\\n# About StreamNative [StreamNative](https://streamnative.io), founded by the original developers of Apache Pulsar and Apache BookKeeper, enables organizations to build the next generation of messaging and event streaming applications. Leveraging Apache Pulsar and BookKeeper, we optimize for scalability and resiliency while reducing the overhead management and complexity required by incumbent technologies. We do this by offering Pulsar and StreamNative\u2019s \u2018products as a service\u2019. StreamNative is building a world-class team that is passionate about building amazing products and committed to customer success."},{"id":"/2020/09/01/pulsar-summit-asia-2020-cfp","metadata":{"permalink":"/blog/2020/09/01/pulsar-summit-asia-2020-cfp","editUrl":"https://github.com/apache/pulsar/edit/master/site2/website-next/blog/2020-09-01-pulsar-summit-asia-2020-cfp.md","source":"@site/blog/2020-09-01-pulsar-summit-asia-2020-cfp.md","title":"Pulsar Summit Asia 2020 CFP is now open","description":"The Pulsar Summit is an annual conference dedicated to the Apache Pulsar community. The summit brings together an international audience of CTOs/CIOs, developers, data architects, data scientists, Apache Pulsar committers/contributors, and the messaging and streaming community. Together, they share experiences, ideas, and insights on Pulsar and its growing community, and receive hands-on training sessions led by Pulsar experts.","date":"2020-09-01T00:00:00.000Z","formattedDate":"September 1, 2020","tags":[],"readingTime":3.79,"truncated":false,"authors":[{"name":"Jennifer Huang","url":"https://twitter.com/Jennife06125739"}],"prevItem":{"title":"Pulsar Summit Asia 2020 Schedule is Now Online","permalink":"/blog/2020/11/04/pulsar-summit-asia-schedule"},"nextItem":{"title":"Apache Pulsar Celebrates 300 Contributors","permalink":"/blog/2020/08/24/Pulsar-300-contributors"}},"content":"The Pulsar Summit is an annual conference dedicated to the Apache Pulsar community. The summit brings together an international audience of CTOs/CIOs, developers, data architects, data scientists, Apache Pulsar committers/contributors, and the messaging and streaming community. Together, they share experiences, ideas, and insights on Pulsar and its growing community, and receive hands-on training sessions led by Pulsar experts.\\n\\nAfter a very successful Pulsar Summit Virtual Conference in June, we have decided to present our Pulsar Summit Asia 2020 in the same way on November 28-29, 2020. The two-day conference will be free to attend! Are you interested in presenting? Suggested topics include Pulsar use cases, operations, technology deep dive, and ecosystem. CFP and registration are now open!\\n\\n![](/img/pulsar-summit-asia-2020.png)\\n\\n## Speak at Pulsar Summit\\nThe opportunity to speak at the second global Pulsar Summit is a great chance to participate in the rapidly growing Apache Pulsar community. Join us for the opportunity to be on stage with top Pulsar thought-leaders, including Apache Pulsar PMC members Sijie Guo and Jia Zhai from [StreamNative](https://streamnative.io/), Penghui Li from Zhaopin.com, Nozomi Kurihara from [Yahoo Japan Corporation](https://about.yahoo.co.jp/), and other community leaders such as Dezhi Liu from [Tencent](https://www.tencent.com/en-us), Vincent Xie from [Orange Finance](https://www.bestpay.com.cn/). Proposals for speaker presentations are currently being accepted. Suggested topics include Pulsar use cases, operations, technology deep dive, and ecosystem. Submissions are open until **October 14, 2020**.\\n\\nIf you have questions about submitting a proposal, or want some feedback or advice in general, please do not hesitate to reach out to [organizers@pulsar-summit.org](mailto:organizers@pulsar-summit.org). We are happy to help out! Details are available on the [CFP website](https://pulsar-summit.org/en/event/asia-2020/cfp).\\n\\n## Dates to remember\\n- CFP opens: September 1, 2020\\n- CFP closes: October 21, 2020 - 23:59 (CST: China Standard Time/UTC+8 time zone)\\n- CFP notification: October 28, 2020\\n- Schedule announcement: November 4, 2020\\n\\n## Speaker benefits\\nWhen your speaking proposal is approved, you will enjoy the following benefits:\\n\\n- The opportunity to expand your network and raise your profile in the Apache Pulsar community.\\n- The chance to demonstrate your experience and deep knowledge in the rapidly growing event streaming space.\\n- Your name, title, company, and bio will be featured on the Pulsar Summit Asia 2020 website.\\n- Your session will be added to the Pulsar Summit YouTube Channel and promoted on Twitter and LinkedIn.\\n- A professionally produced video of your presentation.\\n\\n## Speaker requirements\\nIn addition to your talk, we ask that you actively participate in promoting the event via your personal and company channels. These include posting on your Twitter, LinkedIn, WeChat, Weibo, blog and other channels. We would also like to work directly with your marketing team on co-marketing opportunities. These include, but are not limited to, posting to your company\u2019s Twitter, LinkedIn, WeChat and other developer communities and sending a dedicated Pulsar Summit email to your company\u2019s email list. Contact us at [organizers@pulsar-summit.org](mailto:organizers@pulsar-summit.org) with any questions. \\n\\n## Registration\\nIf you are interested in attending Pulsar Summit Asia 2020, please sign in Hopin and [checkout our event](https://hopin.to/events/pulsar-summit-asia-2020). Your ideas are very important to us, and we will prepare the content accordingly. \\n\\nAfter you checkout the event in Hopin, you will be notified with the event update at the first time when announcing.\\n\\n## Sponsor Pulsar Summit\\nPulsar Summit is a community run conference and your support is needed. Sponsoring this event will provide a great opportunity for your organization to further engage with the Apache Pulsar community. [Contact us](mailto:partners@pulsar-summit.org) to learn more.\\n\\nHelp us make #PulsarSummit 2020 a big success by spreading the word and submitting your proposal! Follow us on Twitter ([@pulsarsummit](https://twitter.com/PulsarSummit)) to receive the latest updates of the conference!\\n\\nHope to see you at Pulsar Summit Asia 2020!\\n\\n## About Apache Pulsar\\nApache Pulsar is a cloud-native, distributed messaging and streaming platform that manages hundreds of billions of events per day. Pulsar was originally developed and deployed inside Yahoo as the consolidated messaging platform connecting critical Yahoo applications such as Yahoo Finance, Yahoo Mail, and Flickr, to data. Pulsar was contributed to open source by Yahoo in 2016 and became a top-level Apache Software Foundation project in 2018.\\n\\n## About StreamNative\\nStreamNative is the organizer of Pulsar Summit Asia 2020. StreamNative is enabling organizations to build the next generation of messaging and event streaming applications. Leveraging Apache Pulsar and BookKeeper, we optimize for scalability and resiliency while reducing the overhead management and complexity required by incumbent technologies. We do this by offering Pulsar and StreamNative\u2019s \\"products as a service\\". StreamNative is building a world-class team that is passionate about building amazing products and committed to customer success."},{"id":"/2020/08/24/Pulsar-300-contributors","metadata":{"permalink":"/blog/2020/08/24/Pulsar-300-contributors","editUrl":"https://github.com/apache/pulsar/edit/master/site2/website-next/blog/2020-08-24-Pulsar-300-contributors.md","source":"@site/blog/2020-08-24-Pulsar-300-contributors.md","title":"Apache Pulsar Celebrates 300 Contributors","description":"Dear Pulsar community,","date":"2020-08-24T00:00:00.000Z","formattedDate":"August 24, 2020","tags":[],"readingTime":4.735,"truncated":false,"authors":[{"name":"Jennifer Huang","url":"https://twitter.com/Jennife06125739"}],"prevItem":{"title":"Pulsar Summit Asia 2020 CFP is now open","permalink":"/blog/2020/09/01/pulsar-summit-asia-2020-cfp"},"nextItem":{"title":"Apache Pulsar 2.6.1","permalink":"/blog/2020/08/21/Apache-Pulsar-2-6-1"}},"content":"Dear Pulsar community,\\n\\nOver the last few years, the shift to real-time streaming technologies has bolstered the adoption of Pulsar and there has been a major increase in both the interest and adoption of Pulsar in 2020 alone. With Pulsar being sought out by companies developing messaging and event-streaming applications \u2014 from Fortune 100 companies to forward-thinking start-ups \u2014 the community is growing quickly. \\n\\nThis community growth has contributed to a new milestone for Pulsar - our [300th contributor](https://github.com/apache/pulsar/graphs/contributors) to the Pulsar repository. This milestone is even more exciting given that we added 100 contributors in the last 8 months alone!\\n\\nAs many of you know, Apache Pulsar is a cloud-native messaging and event streaming platform that has experienced rapid growth since it was committed to open source in 2016. Pulsar graduated as a Top-Level Project (TLP) in September 2018, has launched 92 releases, attracted 5100+ commits from 300 contributors, received 6.5k+ stars, 1.6k+ forks, and 2.2k+ Slack users. \\n\\nThe influx of developers joining the Pulsar community is in large part due to the high market demand for next-generation messaging technologies, big-data insights, and real-time streaming. Top developers and industry leaders are joining the Pulsar community for the opportunity to help shape the future of this technology. \\n\\n## Community Events\\nTo meet the high demand for education and training in the Pulsar community, the community has launched some key initiatives this year. We host weekly TGIP(Thank God It\'s Pulsar) training, which features Pulsar thought-leaders and Pulsar PMC Members. To meet global demand, we currently host two different weekly trainings. One [TGIP training](https://www.youtube.com/watch?v=Vc_a2ppRzlI&list=PLqRma1oIkcWhWAhKgImEeRiQi5vMlqTc-) runs on Pacific Time, and the other [TGIP-CN training](https://github.com/streamnative/tgip-cn) runs on Beijing Time. \\n\\nWe also host monthly [webinars](https://www.youtube.com/watch?v=mncXc_T6JkU&list=PLqRma1oIkcWhfmUuJrMM5YIG8hjju62Ev) to bring together Pulsar and messaging community thought-leaders to share best practices, insights and product news. Thank [Matteo Merli](https://twitter.com/merlimat), [Addison Higham](https://twitter.com/addisonjh), Joe Francis, [Shivji Kumar Jha](https://twitter.com/ShivjiJha), [Devin Bost](https://twitter.com/DevinBost), [Pierre Zemb](https://twitter.com/PierreZ), [Jesse Anderson](https://twitter.com/jessetanderson), [Sijie Guo](https://twitter.com/sijieg) and other speakers for contributing so much valuable knowledge.\\n\\nThis year also marked our first global summit, held in June 2020. Hosted by StreamNative and Splunk, the first-ever [Pulsar Summit Virtual Conference](https://pulsar-summit.org/) featured 30+ talks from 20+ organizations. Thank all speakers for sharing your stories about Pulsar, and thank you to all of the attendees for joining the event.\\n\\nWe are excited to announce that we will be hosting Pulsar Summit Asia 2020 on November 28 and 29, and the call for presentations for this event will be coming soon.\\n\\n## Pulsar Adoption\\nIn addition to the growth in contributors, we are excited to see accelerated adoption of Pulsar in PoC and production environments. Pulsar is helping companies globally to unlock the power of real-time data and to grow their businesses with efficiency and simplicity. \\n\\nKey adoption stories illustrate Pulsar\'s ability to handle mission-critical applications. These include [Tencent\u2019s adoption](https://streamnative.io/success-stories/tencent) of Pulsar for its transactional billing system, which processes more than 10 billion transactions and 10+ TBs of data daily. [Verizon Media is another success story](https://www.youtube.com/watch?v=FXQvsHz_S1A), having operated Pulsar in production for more than 5 years, managing millions of write requests/second, and supporting the business across six global data centers. Most recently Splunk, which had used Kafka in production environments for years, [adopted Pulsar for their new data processor](https://www.youtube.com/watch?v=_q8s3_0-BRQ). \\n\\nFor more insights on Pulsar adoption, you can find a list for companies using or contributing to Apache Pulsar on [Pulsar Powered by page](http://pulsar.apache.org/en/powered-by/). \\n\\n## Ecosystem Development\\nCommitted community partners have also contributed to key project advancements. Below, we look at two recent product launches.\\n\\n### OVHCloud Helps Companies Move from Kafka to Pulsar\\nIn March 2020, [OVHCloud and StreamNative launched Kafka-on-Pulsar (KoP)](https://streamnative.io/blog/tech/2020-03-24-bring-native-kafka-protocol-support-to-apache-pulsar), the result of the two companies working closely in partnership. [KoP](https://github.com/streamnative/kop) enables Kafka users to migrate their existing Kafka applications and services to Pulsar without modifying the code. Although only recently released, KoP has already been adopted by several organizations and is being used in production environments. Moreover, KoP\'s availability is helping to expand Pulsar\'s adoption.\\n\\n### China Mobile Helps Companies Move from RabbitMQ to Pulsar\\nIn June 2020, [China Mobile and StreamNative announced the launch of another major platform upgrade, AMQP-on-Pulsar (AoP)](https://streamnative.io/blog/tech/2020-06-15-announcing-aop-on-pulsar). Similar to KoP, [AoP](https://github.com/streamnative/aop) allows organizations currently using RabbitMQ (or other AMQP message brokers) to migrate existing applications and services to Pulsar without code modification. Again, this is a key initiative that will help drive the adoption and usage of Pulsar.\\n\\nYou can find a number of other connections and integrations, such as MQTT-on-Pulsar for building IoT applications, in the [StreamNative Hub](https://hub.streamnative.io/).\\n\\nThese events and initiatives illustrate the Pulsar community\'s firm commitment to education and ecosystem development. More importantly, they demonstrate the momentum and growth we can expect in the future.\\n\\n## Special Thanks\\nWe would like to thank the Pulsar community, contributors and committers, who have helped to drive development, growth and adoption for Pulsar. We would especially like to recognize our distinguished contributors and committers (including but not limited to): \\n- [Matteo Merli](https://github.com/merlimat) from [Splunk](https://www.splunk.com/)\\n- [Rajan Dhabalia](https://github.com/rdhabalia) from [Verizon Media](https://www.verizonmedia.com/)\\n- [Sijie Guo](https://github.com/sijie) from [StreamNative](https://streamnative.io/)\\n- [Sanjeev Kulkarni](https://github.com/srkukarni) from [Splunk](https://www.splunk.com/)\\n- [Boyang Jerry Peng](https://github.com/jerrypeng) from [Splunk](https://www.splunk.com/)\\n- [Ivan Brendan Kelly](https://github.com/ivankelly) from [Splunk](https://www.splunk.com/)\\n- [Penghui Li](https://github.com/codelipenghui) from [Zhaopin.com](http://www.zhaopin.com/)\\n- [Jia Zhai](https://github.com/jiazhai) from [StreamNative](https://streamnative.io/)\\n\\nTo view other contributors, see [Pulsar contributor list](https://github.com/apache/pulsar/graphs/contributors).\\n\\n## Get Involved\\nWe invite you to join this fast-growing community. Together, we will continue to develop technology to meet today\u2019s most innovative messaging and event-streaming use cases and to help companies unlock the value of real-time data. \\n\\nWhether it is joining our [Pulsar Slack channel](https://apache-pulsar.slack.com/), sharing your Pulsar story via a sponsored [webinar](https://www.youtube.com/watch?v=mncXc_T6JkU&list=PLqRma1oIkcWhfmUuJrMM5YIG8hjju62Ev) or case study, joining a [TGIP](https://github.com/streamnative/tgip)/[TGIP-CN](https://github.com/streamnative/tgip-cn), or attending or speaking at the next Pulsar Summit, we look forward to connecting with you. \\n\\nYou can also subscribe our mailing lists: [users@pulsar.apache.org](mailto:users-subscribe@pulsar.apache.org) and [dev@pulsar.apache.org](mailto:dev-subscribe@pulsar.apache.org)."},{"id":"/2020/08/21/Apache-Pulsar-2-6-1","metadata":{"permalink":"/blog/2020/08/21/Apache-Pulsar-2-6-1","editUrl":"https://github.com/apache/pulsar/edit/master/site2/website-next/blog/2020-08-21-Apache-Pulsar-2-6-1.md","source":"@site/blog/2020-08-21-Apache-Pulsar-2-6-1.md","title":"Apache Pulsar 2.6.1","description":"We are excited to see that the Apache Pulsar community has successfully released 2.6.1 version after a lot of hard work. It is a great milestone for this fast-growing project and the Pulsar community. 2.6.1 is the result of a big effort from the community, with over 100 commits and a long list of improvements and bug fixes.","date":"2020-08-21T00:00:00.000Z","formattedDate":"August 21, 2020","tags":[],"readingTime":10.045,"truncated":true,"authors":[{"name":"XiaoLong Ran","url":"https://twitter.com/wolf4j1"}],"prevItem":{"title":"Apache Pulsar Celebrates 300 Contributors","permalink":"/blog/2020/08/24/Pulsar-300-contributors"},"nextItem":{"title":"Apache Pulsar 2.6.0","permalink":"/blog/2020/06/18/Apache-Pulsar-2-6-0"}},"content":"We are excited to see that the Apache Pulsar community has successfully released 2.6.1 version after a lot of hard work. It is a great milestone for this fast-growing project and the Pulsar community. 2.6.1 is the result of a big effort from the community, with over 100 commits and a long list of improvements and bug fixes.\\n\\nHere are some highlights and major features added in Pulsar 2.6.1.\\n\\n\x3c!--truncate--\x3e\\n\\n## Broker\\n\\n### Limit the batch size to the minimum of the `maxNumberOfMessages` and `maxSizeOfMessages`\\n\\n1. Batch size is not limited to the minimum of the `maxNumberOfMessages` and `maxSizeOfMessages` from the BatchReceive policy.\\n2. When the batch size is greater than the `receiveQ` of the consumer (for example, the batch size is 3000 and a receiveQ is 500), the following issue occurs:\\n\\t\\n\\tIn a multi-topic (pattern) consumer, the client stops receiving any messages. The client gets paused and never resumed when setting a timeout in the batch policy. Only one batch is fetched and the client is never resumed.\\n\\nFor more information about implementation, see [PR-6865](https://github.com/apache/pulsar/pull/6865).\\n\\n### Fix hash range conflict issue in Key_Shared subscription with sticky hash range\\nIn `Key_Shared` subscription where the `stickyHashRange` is used, consumers are not allowed to use interleaving hashes.\\n\\nThe pull request fixes the hash range conflict issue in `Key_Shared` with sticky hash range.\\n\\nFor more information about implementation, see [PR-7231](https://github.com/apache/pulsar/pull/7231).\\n\\n### Fix get lookup permission error\\n\\nIf the `canProduce` or `canConsume` method throws an exception, the `canLookup` method just throws the exception and does not check other permissions. The code snippet is as follows: \\n\\n```java\\n\\ntry {\\n    return canLookupAsync(topicName, role, authenticationData)\\n            .get(conf.getZooKeeperOperationTimeoutSeconds(), SECONDS);\\n}\\n\\n```\\n\\nPR-7234 invokes `canLookupAsync`. When Pulsar AuthorizationService checks lookup permission, if the user has the `canProducer` or `canConsumer` role, the user performs `canLookup` operations.\\n\\nFor more information about implementation, see [PR-7234](https://github.com/apache/pulsar/pull/7234).\\n\\n### Avoid introducing null read position for the managed cursor\\n\\nAvoid introducing null read position for the managed cursor. The most doubtful thing is the `getNextValidPosition` method in the `ManagedLedgerImpl`. If a given position is greater than the position added last time, it returns a `null` value, and the read position is also `null`.\\n\\nIn this PR, we add a log and print the stack trace to find the root cause and fallback to the next position if the `null` occurs at the next valid position.\\n                                                           \\nFor more information about implementation, see [PR-7264](https://github.com/apache/pulsar/pull/7264).\\n\\n### Fix error in creation of non-durable cursor\\n\\nAn NPE occurs when we fail to create a non-durable cursor and continue to create the subscription instance. \\n\\n```java\\n\\ntry {\\n    cursor = ledger.newNonDurableCursor(startPosition, subscriptionName);\\n} catch (ManagedLedgerException e) {\\n    subscriptionFuture.completeExceptionally(e);\\n}\\n\\nreturn new PersistentSubscription(this, subscriptionName, cursor, false);\\n\\n```\\n\\nAdditionally, the NPE leads to the topic usage count increasing to 1. When deleting a topic, the topic cannot be deleted even if you use the force flag.\\n\\nFor more information about implementation, see [PR-7355](https://github.com/apache/pulsar/pull/7355).\\n\\n### Avoid an NPE occurs in the `ManagedLedgerImpl.isOffloadedNeedsDelete` method\\n\\nWhen the default value of the `offload-deletion-lag` is set to `null`, an NPE occurs. To fix the bug, null check is added in the `ManagedLedgerImpl.isOffloadedNeedsDelete` method.\\n                                                                                         \\nFor more information about implementation, see [PR-7389](https://github.com/apache/pulsar/pull/7389).\\n\\n### Fix producer stuck issue due to NPE when creating a new ledger\\n\\nNPE occurs when creating a ledger if the network address is unresolvable. If NPE occurs before adding the timeout task, the timeout mechanism does not work. The unresolvable network address is common in the Kubernetes environment. It happens when a bookie pod or a worker node restarts.\\n\\nThis pull request fixes from the following perspectives:\\n\\n1. Catch the NPE when creating a new ledger.\\n2. When the timeout task is triggered, it always executes the callback. It is totally fine because we already have the logic to ensure the callback is triggered only once.\\n3. Add a mechanism to detect that the `CreatingLedger` state is not moving.\\n\\nFor more information about implementation, see [PR-7401](https://github.com/apache/pulsar/pull/7401).\\n\\n\\n### Fix NPE when using advertisedListeners\\n\\nThe broker failed to acquire ownership for the namespace bundle when using `advertisedListeners=internal:pulsar://node1:6650,external:pulsar://node1.external:6650` with external listener name. Correct `BrokerServiceUrlTls` when TLS is not enabled.\\n\\nFor more information about implementation, see [PR-7620](https://github.com/apache/pulsar/pull/7620).\\n\\n### Fix the issue that the deduplication cursor cannot be deleted after message deduplication is disabled\\n\\nWhen enabling the message deduplication in the `broker.conf` file, disabling it and then restarting the broker, the deduplication cursor is not deleted.\\n\\nThis PR fixes the issue, so when you disable message deduplication, you can delete the deduplication cursor.\\n\\nFor more information about implementation, see [PR-7656](https://github.com/apache/pulsar/pull/7656).\\n\\n### Fix the issue that GetLastEntry() reads entry `-1`\\n\\nPreviously, the code does not include a return statement. If the entry is set to `-1`, after sending code, the response reads the entry and sends a second response, as shown in the following example.\\n\\n```\\n\\n16:34:25.779 [pulsar-io-54-7:org.apache.bookkeeper.client.LedgerHandle@748] ERROR org.apache.bookkeeper.client.LedgerHandle - IncorrectParameterException on ledgerId:0 firstEntry:-1 lastEntry:-1\\n16:34:25.779 [pulsar-client-io-82-1:org.apache.pulsar.client.impl.ConsumerImpl@1986] INFO  org.apache.pulsar.client.impl.ConsumerImpl - [persistent://external-repl-prop/pulsar-function-admin/assignment][c-use-fw-localhost-0-function-assignment-initialize-reader-b21f7607c9] Successfully getLastMessageId 0:-1\\n16:34:25.779 [pulsar-client-io-82-1:org.apache.pulsar.client.impl.ClientCnx@602] WARN  org.apache.pulsar.client.impl.ClientCnx - [id: 0xc78f4a0e, L:/127.0.0.1:55657 - R:localhost/127.0.0.1:55615] Received error from server: Failed to get batch size for entry org.apache.bookkeeper.mledger.ManagedLedgerException: Incorrect parameter input\\n16:34:25.779 [pulsar-client-io-82-1:org.apache.pulsar.client.impl.ClientCnx@612] WARN  org.apache.pulsar.client.impl.ClientCnx - [id: 0xc78f4a0e, L:/127.0.0.1:55657 - R:localhost/127.0.0.1:55615] Received unknown request id from server: 10\\n\\n```\\n\\nPR-7495 adds a return statement to code, so GetLastEntry() reads the last entry, instead of `-1`.  \\n\\nFor more information about implementation, see [PR-7495](https://github.com/apache/pulsar/pull/7495).\\n\\n### Fix the error of updating partitions for non-persistent topic\\n\\nWhen updating partitions on a non-persistent topic, Error 409 is returned. The pull request fixes partitions errors for non-persistent topics.\\n\\nFor more information about implementation, see [PR-7459](https://github.com/apache/pulsar/pull/7459).\\n\\n## ZooKeeper\\n\\n### Use hostname for bookie rack awareness mapping\\n\\nIn [PR-5607](https://github.com/apache/pulsar/pull/5607), the `useHostName()` is added with `return false`. The rack-aware policy passes the Bookie\'s hostname into an IP address and then uses that IP address to figure out to which rack the bookie belongs.\\n\\nThen two issues occur: \\n 1. The IP does not match the hostname which is recorded in the `/bookies` z-node\\n 2. If there is an error in parsing the bookie hostname (eg: transient DNS error), an NPE is triggered and the BK client never realizes that this bookie is available in the cluster.\\n\\nThe exception is thrown at Line 77(as shown in the following code snippet), since `getAddress()` returns a `null` given that the address is parsed.  \\n\\n```java\\n\\n74        if (dnsResolver.useHostName()) {\\n75            names.add(addr.getHostName());\\n76        } else {\\n77            names.add(addr.getAddress().getHostAddress());\\n78        }\\n\\n```\\n\\nThe default implementation for the `DnsResolver.useHostName()` returns `true`.\\n\\nFor more information about implementation, see [PR-7361](https://github.com/apache/pulsar/pull/7361).\\n\\n## Java Client\\n\\n### Fix the issue that the HTTP header used in Athenz authentication can not be renamed\\n\\nThe authentication plugin for Athenz allows users to change the name of the HTTP header for sending an authentication token to a broker server with a parameter named `roleHeader`. The change uses the value of the `roleHeader` parameter on the `AuthenticationAthenz` side, and uses it directly as the header name.\\n                                                                                                                                                                                                    \\nFor more information about implementation, see [PR-7311](https://github.com/apache/pulsar/pull/7311).\\n\\n### Fix the issue that batch ack set is recycled multiple times\\n\\nThe batch ack sets are recycled multiple times, due to race condition in group ack flush and cumulative Ack. So we add a recycled state check for the ack set in PR-7409, and fix the recycle issue.\\n\\nFor more information about implementation, see [PR-7409](https://github.com/apache/pulsar/pull/7409).\\n\\n### Add authentication client with OAuth2 support\\n\\nPulsar supports authenticating clients using OAuth 2.0 access tokens. You can use tokens to identify a Pulsar client and associate with some \\"principal\\" (or \\"role\\") that is permitted to do some actions, for example, publish messages to a topic or consume messages from a topic. \\n\\nThis module is to support Pulsar Client Authentication Plugin for OAuth 2.0 directly. The client communicates with the Oauth 2.0 server, gets an `access token` from the Oauth 2.0 server, and passes the `access token` to Pulsar broker to do the authentication.\\n\\nSo, the broker can use `org.apache.pulsar.broker.authentication.AuthenticationProviderToken`,\\nand the user can add their own `AuthenticationProvider` to work with this module.\\n\\nFor more information about implementation, see [PR-7420](https://github.com/apache/pulsar/pull/7420).\\n\\n\\n### Not subscribe to the topic when the consumer is closed\\n\\nFix race condition on the closed consumer while reconnecting to the broker.\\n\\nThe race condition happens when the consumer reconnects to the broker. The connection of the consumer is set to `null` when the consumer reconnects to the broker. If the consumer is not connected to broker at this time, the client does not send the consumer command to the broker. So, when the consumer reconnects to the broker, the consumer sends the subscribe command again. \\n\\nThis pull request adds a state check when the `connectionOpened()` of the consumer opens. If the consumer is in closing or closed state, the consumer does not send the subscribe command.\\n\\nFor more information about implementation, see [PR-7589](https://github.com/apache/pulsar/pull/7589).\\n\\n### OAuth2 authentication plugin uses AsyncHttpClient\\n\\nPreviously, the OAuth2 client authentication plugin used Apache HTTP client lib to make requests, Apache HTTP client is used to validate hostname. As suggested in [#7612](https://github.com/apache/pulsar/issues/7612), we get rid of the dependency of using Apache HTTP client.\\n\\nIn PR-7615, OAuth2 client authentication plugin uses AsyncHttpClient, which is used in client and broker. For more information about implementation, see [PR-7615](https://github.com/apache/pulsar/pull/7615).\\n\\n\\n## CPP Client\\n\\n### CPP Oauth2 authentication client\\n\\nPulsar supports authenticating clients using OAuth 2.0 access tokens. You can use tokens to identify a Pulsar client and associate with some \\"principal\\" (or \\"role\\") that is permitted to do some actions (eg: publish messages to a topic or consume messages from a topic). This change tries to support it in cpp client.\\n\\nFor more information about implementation, see [PR-7467](https://github.com/apache/pulsar/pull/7467).\\n\\n### Fix partition index error in close callback\\n\\nIn partitioned producer/consumer\'s close callback, the partition index is always `0`. The `ProducerImpl/ConsumerImpl` internal partition index field should be passed to `PartitionedProducerImpl/PartitionedConsumerImpl` close callback.\\n\\nFor more information about implementation, see [PR-7282](https://github.com/apache/pulsar/pull/7282).\\n\\n### Fix segment crashes caused by race condition of timer in CPP client\\n\\nSegment crashes occur in a race condition:\\n    - The close operation calls the `keepAliveTimer_.reset()`.\\n    - The `keepAliveTimer` is called by `startConsumerStatsTimer` and `handleKeepAliveTimeout` methods. Actually, the `keepAliveTimer` should not be called by those two methods.\\n\\nThis pull request fixes those issues.\\n\\nFor more information about implementation, see [PR-7572](https://github.com/apache/pulsar/pull/7572).\\n\\n### Add support to read credentials from file\\n\\nSupport reading credentials from a file to make it align with the Java client.\\n\\nFor more information about implementation, see [PR-7606](https://github.com/apache/pulsar/pull/7606).\\n\\n### Fix multi-topic consumer segfault on connection error\\n\\nThe multi-topic consumer triggers a segfault when an error occurs in creating a consumer. This is due to the calls to close the partial consumers with a null callback.\\n\\nFor more information about implementation, see [PR-7588](https://github.com/apache/pulsar/pull/7588).\\n\\n## Functions\\n\\n### Use fully qualified hostname as default to advertise worker\\n\\nThere is a difference in getting hostnames between `Java 8` and `Java 11`. In Java 8, `InetAddress.getLocalHost().getHostName()` returns the fully qualified hostname; in Java 11, it returns a simple hostname. In this case, we should rather use the `getCanonicalHostName()`, which returns the fully qualified hostname. This is the same method to get the advertised address for workers as well.\\n\\nFor more information about implementation, see [PR-7360](https://github.com/apache/pulsar/pull/7360).\\n\\n### Fix the function BC issue introduced in release 2.6.0\\n\\nA backwards compatibility breakage is introduced in [PR-5985](https://github.com/apache/pulsar/pull/5985). When the running function workers are separated from brokers, updating workers and brokers independently from release 2.5.0 to 2.6.0 results in the following error:\\n\\n```text\\n\\njava.lang.NullPointerException: null\\\\n\\\\tat java.net.URI$Parser.parse(URI.java:3104) ~[?:?]\\njava.net.URI.<init>(URI.java:600) ~[?:?]\\\\n\\\\tat java.net.URI.create(URI.java:881) ~[?:?]\\norg.apache.pulsar.functions.worker.WorkerUtils.initializeDlogNamespace(WorkerUtils.java:160) ~[org.apache.pulsar-pulsar-functions-worker-2.7.0-SNAPSHOT.jar:2.7.0-SNAPSHOT]\\norg.apache.pulsar.functions.worker.Worker.initialize(Worker.java:155) ~[org.apache.pulsar-pulsar-functions-worker-2.7.0-SNAPSHOT.jar:2.7.0-SNAPSHOT] \\norg.apache.pulsar.functions.worker.Worker.start(Worker.java:69) ~[org.apache.pulsar-pulsar-functions-worker-2.7.0-SNAPSHOT.jar:2.7.0-SNAPSHOT] \\norg.apache.pulsar.functions.worker.FunctionWorkerStarter.main(FunctionWorkerStarter.java:67) [org.apache.pulsar-pulsar-functions-worker-2.7.0-SNAPSHOT.jar:2.7.0-SNAPSHOT]\\n\\n```\\n\\nThis is because the broker 2.5.0 supports \\"bookkeeperMetadataServiceUri\\" and the admin client returns a `null` field, thus causing the NPE.\\n\\nFor more information about implementation, see [PR-7528](https://github.com/apache/pulsar/pull/7528).\\n\\n## pulsar-perf\\n\\n### Support `tlsAllowInsecureConnection` in pulsar-perf produce/consume/read performance tests\\n\\nAdd `tlsAllowInsecureConnection` config to the CLI tool **pulsar-perf**, to support produce/consume/read performance tests to clusters with insecure TLS connections.\\n\\nFor more information about implementation, see [PR-7300](https://github.com/apache/pulsar/pull/7300).\\n\\n## More information\\n\\n- To download Apache Pulsar 2.6.1, click [download](https://pulsar.apache.org/en/download/).\\n- For more information about Apache Pulsar 2.6.1, see [2.6.1 release notes](https://pulsar.apache.org/release-notes/#2.6.1) and [2.6.1 PR list](https://github.com/apache/pulsar/pulls?q=is%3Apr+label%3Arelease%2F2.6.1+is%3Aclosed).\\n\\nIf you have any questions or suggestions, contact us with mailing lists or slack.\\n\\n- [users@pulsar.apache.org](mailto:users@pulsar.apache.org)\\n- [dev@pulsar.apache.org](mailto:dev@pulsar.apache.org)\\n- Pulsar slack channel: https://apache-pulsar.slack.com/\\n- Self-registration at https://apache-pulsar.herokuapp.com/\\n\\nLooking forward to your contributions to [Pulsar](https://github.com/apache/pulsar)."},{"id":"/2020/06/18/Apache-Pulsar-2-6-0","metadata":{"permalink":"/blog/2020/06/18/Apache-Pulsar-2-6-0","editUrl":"https://github.com/apache/pulsar/edit/master/site2/website-next/blog/2020-06-18-Apache-Pulsar-2-6-0.md","source":"@site/blog/2020-06-18-Apache-Pulsar-2-6-0.md","title":"Apache Pulsar 2.6.0","description":"We are very glad to see the Apache Pulsar community has successfully released the wonderful 2.6.0 version after accumulated hard work. It is a great milestone for this fast-growing project and the whole Pulsar community. This is the result of a huge effort from the community, with over 450 commits and a long list of new features, improvements, and bug fixes.","date":"2020-06-18T00:00:00.000Z","formattedDate":"June 18, 2020","tags":[],"readingTime":16.255,"truncated":true,"authors":[{"name":"Penghui Li","url":"https://twitter.com/lipenghui6"}],"prevItem":{"title":"Apache Pulsar 2.6.1","permalink":"/blog/2020/08/21/Apache-Pulsar-2-6-1"},"nextItem":{"title":"Apache Pulsar 2.5.2","permalink":"/blog/2020/05/19/Apache-Pulsar-2-5-2"}},"content":"We are very glad to see the Apache Pulsar community has successfully released the wonderful 2.6.0 version after accumulated hard work. It is a great milestone for this fast-growing project and the whole Pulsar community. This is the result of a huge effort from the community, with over 450 commits and a long list of new features, improvements, and bug fixes.\\n\\nHere is a selection of some of the most interesting and major features added to Pulsar 2.6.0.\\n\\n\x3c!--truncate--\x3e\\n\\n## Core Pulsar\\n\\n### [PIP-37] Large message size support\\n\\nThis PIP adds support for producing and consuming large size messages by splitting the large message into multiple chunks. This is a very powerful feature for sending and consuming very large messages.\\n\\nCurrently, this feature only works for the non-shared subscription and it has client-side changes. You need to upgrade the Pulsar client version to 2.6.0. You can enable the message trunk at the producer side as below.\\n\\n```java\\n\\nclient.newProducer()\\n\\t.topic(\\"my-topic\\")\\n\\t.enableChunking(true)\\n\\t.create();\\n\\n```\\n\\nFor more information about PIP-37, see [here](https://github.com/apache/pulsar/wiki/PIP-37:-Large-message-size-handling-in-Pulsar). <br /> For more information about implementation details, see [PR-4440](https://github.com/apache/pulsar/pull/4400).\\n\\n### [PIP-39] Namespace change events (system topic)\\n\\nThis PIP introduces the system topic to store namespace change events. Previously, Pulsar only allowed you to set the namespace policy, all topics under the namespace followed the namespace policy. Many users want to set the policy for topics. The main reason for not using the same way as namespace level policy is to avoid introducing more workload on the ZooKeeper. \\n\\nThe original intention of the system topic is to be able to store topic policy in a topic rather than ZooKeeper. So this is the first step to achieve topic level policy. And we can easily add support for the topic level policy with this feature.\\n\\nFor more information about PIP-39, see [here](https://github.com/apache/pulsar/wiki/PIP-39%3A-Namespace-Change-Events).<br /> For more information about implementation details, see  [PR-4955](https://github.com/apache/pulsar/pull/4955).\\n\\n### [PIP-45] Pluggable metadata interface\\n\\nWe have been advancing to enable Pulsar to use other metastore services rather than ZooKeeper. This PIP converts `ManagedLedger` to use the `MetadataStore` interface. This facilitates the metadata server plug-in process. Through the `MetadataStore` interface, it is easy to add other metadata servers into Pulsar such as [etcd](https://github.com/etcd-io/etcd).\\n\\nFor more information about PIP-45, see [here](https://github.com/apache/pulsar/wiki/PIP-45%3A-Pluggable-metadata-interface). <br /> For more information about implementation details, see [PR-5358](https://github.com/apache/pulsar/pull/5358).\\n\\n### [PIP-54] Support acknowledgment at the batch index level\\n\\nPreviously, the broker only tracked the acknowledged state in the batch message level. If a subset of the batch messages was acknowledged, the consumer could still get the acknowledged message of that batch message while the batch message redelivery happened. \\n\\nThis PIP adds support for acknowledging the local batch index of a batch. This feature is not enabled by default. You can enable it in the `broker.conf` as below.\\n\\n```\\n\\nacknowledgmentAtBatchIndexLevelEnabled=true\\n\\n```\\n\\nFor more information about PIP-54, see [here](https://github.com/apache/pulsar/wiki/PIP-54:-Support-acknowledgment-at-batch-index-level). <br /> For more information about implementation details, see [PR-6052](https://github.com/apache/pulsar/pull/6052).\\n\\n### [PIP-58] Support consumers setting custom message retry delay\\n\\nFor many online business systems, various exceptions usually occur in business logic processing, so the message needs to be re-consumed, but users hope that this delay time can be controlled flexibly. Previously, processing methods were usually to send messages to special retry topics, because production can specify any delay, so consumers subscribe to the business topic and retry topic at the same time. Now you can set a retry delay for each message as below.\\n\\n```java\\n\\nConsumer<byte[]> consumer = pulsarClient.newConsumer(Schema.BYTES)\\n    .enableRetry(true)\\n    .receiverQueueSize(100)\\n    .deadLetterPolicy(DeadLetterPolicy.builder()\\n        .maxRedeliverCount(maxRedeliveryCount)\\n        .retryLetterTopic(\\"persistent://my-property/my-ns/my-subscription-custom-Retry\\")\\n        .build())\\n    .subscribe();\\n\\nconsumer.reconsumeLater(message, 10, TimeUnit.SECONDS);\\n\\n```\\n\\nFor more information about PIP-58, see [here](https://github.com/apache/pulsar/wiki/PIP-58-%3A-Support-Consumers--Set-Custom-Retry-Delay). <br /> For more information about implementation details, see [PR-6449](https://github.com/apache/pulsar/pull/6449).\\n\\n### [PIP-60] Support SNI routing to support various proxy servers\\n\\nPreviously, Pulsar did not provide support to use other proxies, such as Apache Traffic Server (ATS), HAProxy, Nginx, and Envoy, which are more scalable and secured. Most of these proxy servers support SNI routing which can route traffic to a destination without having to terminate the SSL connection. This PIP adds SNI routing and makes changes to the Pulsar client.\\n\\nFor more information about PIP-60, see [here](https://github.com/apache/pulsar/wiki/PIP-60:-Support-Proxy-server-with-SNI-routing). <br /> For more information about implementation details, see  [PR-6566](https://github.com/apache/pulsar/pull/6566).\\n\\n### [PIP-61] Advertise multiple addresses\\n\\nThis PIP allows the broker to expose multiple advertised listeners and to support the separation of internal and external network traffic. You can specify multiple advertised listeners in `broker.conf` as below.\\n\\n```\\n\\nadvertisedListeners=internal:pulsar://192.168.1.11:6660,external:pulsar://110.95.234.50:6650\\n\\n```\\n\\nFrom the client side, you can specify the listener name for the client as below.\\n\\n```java\\n\\nPulsarClient.builder()\\n    .serviceUrl(url)\\n    .listenerName(\\"internal\\")\\n    .build();\\n\\n```\\n\\nFor more information about PIP-61, see [here](https://github.com/apache/pulsar/wiki/PIP-61%3A-Advertised-multiple-addresses). <br /> For more information about implementation details, see [PR-6903](https://github.com/apache/pulsar/pull/6903).\\n\\n### [PIP-65] Adapt Pulsar IO sources to support `BatchSources`  \\n\\nThis PIP introduces `BatchSource` as a new interface for writing batch-based connectors. It also introduces `BatchSourceTriggerer` as an interface to trigger the data collection of a `BatchSource`. It then provides system implementation in `BatchSourceExecutor`.\\n\\nFor more information about PIP-65, see [here](https://github.com/apache/pulsar/wiki/PIP-65%3A-Adapting-Pulsar-IO-Sources-to-support-Batch-Sources). <br /> For more information about implementation details, see [PR-7090](https://github.com/apache/pulsar/pull/7090).\\n\\n### [Load balancer] Add `ThresholdShedder` strategy for the load balancer\\n\\nThe `ThresholdShedder` strategy is more flexible than `LoadSheddingStrategy` for Pulsar. The `ThresholdShedder` calculates the average resource usage of the brokers, and individual broker resource usage compares with the average value. If it is greater than the average value plus threshold, the overload shedder is triggered. You can enable it in `broker.conf` as below.\\n\\n```\\n\\nloadBalancerLoadSheddingStrategy=org.apache.pulsar.broker.loadbalance.impl.ThresholdShedder\\n\\n```\\n\\nYou can customize more parameters for the `ThresholdShedder` if needed as below.\\n\\n```\\n\\n# The broker resource usage threshold.\\n# When the broker resource usage is greater than the pulsar cluster average resource usage,\\n# the threshold shedder will be triggered to offload bundles from the broker.\\n# It only takes effect in ThresholdShedder strategy.\\nloadBalancerBrokerThresholdShedderPercentage=10\\n\\n# When calculating new resource usage, the history usage accounts for.\\n# It only takes effect in ThresholdShedder strategy.\\nloadBalancerHistoryResourcePercentage=0.9\\n\\n# The BandWithIn usage weight when calculating new resource usage.\\n# It only takes effect in ThresholdShedder strategy.\\nloadBalancerBandwithInResourceWeight=1.0\\n\\n# The BandWithOut usage weight when calculating new resource usage.\\n# It only takes effect in ThresholdShedder strategy.\\nloadBalancerBandwithOutResourceWeight=1.0\\n\\n# The CPU usage weight when calculating new resource usage.\\n# It only takes effect in ThresholdShedder strategy.\\nloadBalancerCPUResourceWeight=1.0\\n\\n# The heap memory usage weight when calculating new resource usage.\\n# It only takes effect in ThresholdShedder strategy.\\nloadBalancerMemoryResourceWeight=1.0\\n\\n# The direct memory usage weight when calculating new resource usage.\\n# It only takes effect in ThresholdShedder strategy.\\nloadBalancerDirectMemoryResourceWeight=1.0\\n\\n# Bundle unload minimum throughput threshold (MB), avoiding bundle unload frequently.\\n# It only takes effect in ThresholdShedder strategy.\\nloadBalancerBundleUnloadMinThroughputThreshold=10\\n\\n```\\n\\nFor more information about implementation details, see [PR-6772](https://github.com/apache/pulsar/pull/6772).\\n\\n### [Key Shared] Add consistent hashing in the Key_Shared distribution\\n\\nPreviously, the implementation of the Key_Shared subscription used a mechanism to divide their hash space across the available consumers. This was based on dividing the currently assigned hash ranges when a new consumer joined or left. Pulsar 2.6.0 introduces a new consistent hash distribution for the Key_Shared subscription. You can enable the consistent hash distribution in `broker.conf` and the auto split approach is still selected by default.\\n\\n```\\n\\n# On KeyShared subscriptions, with default AUTO_SPLIT mode, use splitting ranges or\\n# consistent hashing to reassign keys to new consumers\\nsubscriptionKeySharedUseConsistentHashing=false\\n\\n# On KeyShared subscriptions, number of points in the consistent-hashing ring.\\n# The higher the number, the more equal the assignment of keys to consumers\\nsubscriptionKeySharedConsistentHashingReplicaPoints=100\\n\\n```\\n\\nWe plan to use consistent hash distribution by default in the subsequent versions.\\nFor more information about implementation details, see  [PR-6791](https://github.com/apache/pulsar/pull/6791).\\n\\n### [Key Shared] Fix ordering issue in KeyShared dispatcher when adding consumers\\n\\nThis is a great fix for the Key_Shared subscription. Previously, ordering was broken in a KeyShared dispatcher if a new consumer c2 came in and an existing consumer c1 went out. This was because messages with keys previously assigned to c1 may route to c2, which might break the message ordering dispatch guarantee in the Key_Shared subscription. This PR introduces new consumers joining in a \\"paused\\" state until the previous messages are acknowledged to ensure the messages are dispatched orderly. \\n\\nIf you still want the relaxed ordering, you can set up at the consumer side as below.\\n\\n```java\\n\\npulsarClient.newConsumer()\\n\\t.keySharedPolicy(KeySharedPolicy.autoSplitHashRange().setAllowOutOfOrderDelivery(true))\\n\\t.subscribe();\\n\\n```\\n\\nFor more information about implementation details, see [PR-7106](https://github.com/apache/pulsar/pull/7106) and [PR-7108](https://github.com/apache/pulsar/pull/7108).\\n\\n### [Key Shared] Add support for key hash range reading\\n\\nThis PR supports sticky key hash range reader. A broker only dispatches messages whose hash of the message key contains by a specified key hash range. Besides, multiple key hash ranges can be specified on a reader.\\n\\n```java\\n\\npulsarClient.newReader()\\n    .topic(topic)\\n    .startMessageId(MessageId.earliest)\\n    .keyHashRange(Range.of(0, 10000), Range.of(20001, 30000))\\n    .create();\\n\\n```\\n\\nFor more information about implementation details, see  [PR-5928](https://github.com/apache/pulsar/pull/5928).\\n\\n### Use pure-java Air-Compressor instead of JNI based libraries\\n\\nPreviously, JNI based libraries were used to perform data compression. While these libraries do have an overhead in terms of size and affect the JNI overhead which is typically measurable when compressing many small payloads. This PR replaces compression libraries for LZ4, ZStd, and Snappy with [AirCompressor](https://github.com/airlift/aircompressor), which is a pure Java compression library used by Presto.\\n\\nFor more information about implementation details, see  [PR-5390](https://github.com/apache/pulsar/pull/5390).\\n\\n### Support multiple Pulsar clusters using the same BookKeeper cluster\\n\\nThis PR allows multiple pulsar clusters to use the specified BookKeeper cluster by pointing BookKeeper client to the ZooKeeper connection string of BookKeeper cluster. This PR adds a configuration (`bookkeeperMetadataServiceUri`) to discover BookKeeper cluster metadata store and uses metadata service URI to initialize BookKeeper clients.\\n\\n```\\n\\n# Metadata service uri that bookkeeper is used for loading corresponding metadata driver\\n# and resolving its metadata service location.\\n# This value can be fetched using `bookkeeper shell whatisinstanceid` command in BookKeeper cluster.\\n# For example: zk+hierarchical://localhost:2181/ledgers\\n# The metadata service uri list can also be semicolon separated values like below:\\n# zk+hierarchical://zk1:2181;zk2:2181;zk3:2181/ledgers\\nbookkeeperMetadataServiceUri=\\n\\n```\\n\\nFor more information about implementation details, see [PR-5985](https://github.com/apache/pulsar/pull/5985).\\n\\n### Support deleting inactive topics when subscriptions are caught up\\n\\nPreviously, Pulsar supported deleting inactive topics which do not have active producers and subscriptions. This PR supports deleting inactive topics when all subscriptions of the topic are caught up and when there are no active producers or consumers. This PR exposes inactive topic delete mode in `broker.conf`. In the future, we can support a namespace level configuration for the inactive topic delete mode.\\n\\n```\\n\\n# Set the inactive topic delete mode. Default is delete_when_no_subscriptions\\n# \'delete_when_no_subscriptions\' mode only delete the topic which has no subscriptions and no active producers\\n# \'delete_when_subscriptions_caught_up\' mode only delete the topic that all subscriptions has no backlogs(caught up)\\n# and no active producers/consumers\\nbrokerDeleteInactiveTopicsMode=delete_when_no_subscriptions\\n\\n```\\n\\nFor more information about implementation details, see [PR-6077](https://github.com/apache/pulsar/pull/6077).\\n\\n### Add a flag to skip broker shutdown on transient OOM\\n\\nA high dispatch rate on one of the topics may cause a broker to go OOM temporarily. It is a transient error and the broker can recover within a few seconds as soon as some memory gets released. However, in 2.4 release ([#4196](https://github.com/apache/pulsar/pull/4196)), the \u201crestarted broker on OOM\u201d feature can cause huge instability in a cluster, where a topic moves from one broker to another and restarts multiple brokers and disrupts other topics as well. So this PR provides a dynamic flag to skip broker shutdown on OOM to avoid instability in a cluster.\\n\\nFor more information about implementation details, see [PR-6634](https://github.com/apache/pulsar/pull/6634).\\n\\n### Make ZooKeeper cache expiry time configurable\\n\\nPreviously, ZooKeeper cache expiry time was hardcoded and it needed to be configurable to refresh the value based on various requirements, for example, refreshing the value quickly in case of zk-watch miss, avoiding frequent cache refresh to avoid zk-read or avoiding issue due to zk read timeout, and so on. Now you can configure ZooKeeper cache expiry time in `broker.conf` as below.\\n\\n```\\n\\n# ZooKeeper cache expiry time in seconds\\nzooKeeperCacheExpirySeconds=300\\n\\n```\\n\\nFor more information about implementation details, see [PR-6668](https://github.com/apache/pulsar/pull/6668).\\n\\n### Optimize consumer fetch messages in case of batch message\\n\\nWhen a consumer sends a fetch request to a broker server, it contains a fetch message number telling the server how many messages should be pushed to a consumer client. However, the broker server stores data in BookKeeper or broker cache according to entry rather than a single message if the producer produces messages using the batch feature. There is a gap to map the number of messages to the number of entries when dealing with consumer fetch requests. This PR adds a variable `avgMessagesPerEntry` to record average messages stored in one entry. It updates when a broker server pushes messages to a consumer. When dealing with consumer fetch requests, it maps fetch request number to entry number. Additionally, this PR exposes the `avgMessagePerEntry` static value to consumer stat metric json.\\n\\nYou can enable `preciseDispatcherFlowControl` in ` broker.conf` as below.\\n\\n```\\n\\n# Precise dispatcher flow control according to history message number of each entry\\npreciseDispatcherFlowControl=false\\n\\n```\\n\\nFor more information about implementation details, see  [PR-6719](https://github.com/apache/pulsar/pull/6719)\\n\\n### Introduce precise topic publish rate limiting\\n\\nPreviously, Pulsar supported the publish rate limiting but it is not a precise control. Now, for some use cases that need precise control, you can enable it in `broker.conf` as below.\\n\\n```\\n\\npreciseTopicPublishRateLimiterEnable=true\\n\\n```\\n\\nFor more information about implementation details, see  [PR-7078](https://github.com/apache/pulsar/pull/7078).\\n\\n### Expose check delay of new entries in `broker.conf`\\n\\nPreviously, the check delay of new entries was 10 ms and could not be changed by users. Currently, for consumption latency sensitive scenarios, you can set the value of check delay of new entries to a smaller value or 0 in `broker.conf` as below. Using a smaller value may degrade consumption throughput. \\n\\n```\\n\\nmanagedLedgerNewEntriesCheckDelayInMillis=10\\n\\n```\\n\\nFor more information about implementation details, see  [PR-7154](https://github.com/apache/pulsar/pull/7154).\\n\\n### [Schema]  Supports `null` key and `null` value in KeyValue schema\\n\\nFor more information about implementation details, see  [PR-7139](https://github.com/apache/pulsar/pull/7139).\\n\\n### Support triggering ledger rollover when `maxLedgerRolloverTimeMinutes` is met\\n\\nThis PR implements a monitoring thread to check if the current topic ledger meets the constraint of `managedLedgerMaxLedgerRolloverTimeMinutes` and triggers a rollover to make the configuration take effect. Another important idea is that if you trigger a rollover, you can close the current ledger so that you can release the storage of the current ledger. For some less commonly used topics, the current ledger data is likely to be expired and the current rollover logic is only triggered when adding a new entry. Obviously, this results in a waste of disk space. The monitoring thread is scheduled at a fixed time interval and the interval is set to `managedLedgerMaxLedgerRolloverTimeMinutes`. Each inspection makes two judgments at the same time, for example, `currentLedgerEntries > 0` and `currentLedgerIsFull()`. When the number of current entries is equal to 0, it does not trigger a new rollover and you can use this to reduce the ledger creation.\\n\\nFor more information about implementation details, see  [PR-7116](https://github.com/apache/pulsar/pull/7111).\\n\\n## Proxy\\n\\n### Add REST API to get connection and topic stats\\n\\nPreviously, Pulsar proxy did not have useful stats to get internal information about the proxy. It is better to have internal-stats of proxy to get information, such as live connections, topic stats (with higher logging level), and so on. This PR adds REST API to get stats for connection and topics served by proxy.\\n\\nFor more information about implementation details, see [PR-6473](https://github.com/apache/pulsar/pull/6473).\\n\\n## Admin\\n\\n### Support getting a message by message ID in pulsar-admin\\n\\nThis PR adds a new command `get-message-by-id` to the pulsar-admin. It allows users to check a single message by providing ledger ID and entry ID. \\n\\nFor more information about implementation details, see [PR-6331](https://github.com/apache/pulsar/pull/6331).\\n\\n### Support deleting subscriptions forcefully\\n\\nThis PR adds the method `deleteForcefully` to support force deleting subscriptions. \\n\\nFor more information about implementation details, see [PR-6383](https://github.com/apache/pulsar/pull/6383).\\n\\n## Functions\\n\\n### Built-in functions\\n\\nThis PR implements the possibility of creating built-in functions in the same way as adding built-in connectors.\\n\\nFor more information about implementation details, see [PR-6895](https://github.com/apache/pulsar/pull/6895).\\n\\n### Add Go Function heartbeat (and gRPC service) for production usage\\n \\nFor more information about implementation details, see [PR-6031](https://github.com/apache/pulsar/pull/6031).\\n\\n### Add custom property options to functions\\n\\nThis PR allows users to set custom system properties while submitting functions. This can be used to pass credentials via a system property.\\n\\nFor more information about implementation details, see [PR-6348](https://github.com/apache/pulsar/pull/6348).\\n\\n### Separate TLS configurations of function worker and broker\\n \\nFor more information about implementation details, see [PR-6602](https://github.com/apache/pulsar/pull/6602).\\n\\n### Add the ability to build consumers in functions and sources\\n\\nPreviously, function and source context give their writers an ability to create publishers but not consumers. This PR fixes this issue.\\n\\nFor more information about implementation details, see [PR-6954](https://github.com/apache/pulsar/pull/6954).\\n\\n## Pulsar SQL\\n\\n### Support KeyValue schema\\n\\nPreviously, Pulsar SQL could not read the KeyValue schema data.\\n\\nThis PR adds KeyValue schema support for Pulsar SQL. It adds the prefix `key.` for the key field name and `value.` for the value field name.\\n\\nFor more information about implementation details, see [PR-6325](https://github.com/apache/pulsar/pull/6325).\\n\\n### Support multiple Avro schema versions\\n\\nPreviously, if you have multiple Avro schema versions for a topic, using the Pulsar SQL to query data from this topic will introduce some problems. With this change, You can evolve the schema of the topic and keep transitive backward compatibility of all schemas of the topic if you want to query data from this topic. \\n  \\nFor more information about implementation details, see [PR-4847](https://github.com/apache/pulsar/pull/4847).\\n\\n## Java client\\n\\n### Support waiting for inflight messages while closing a producer\\n\\nPreviously, when you closed a producer, the pulsar-client immediately failed inflight messages even if it persisted successfully at the broker. Most of the time, users want to wait for those inflight messages rather than fail them. While the pulsar-client library did not provide a way to wait for inflight messages before closing the producer. This PR supports closing API with a flag where you can control waiting for inflight messages. With this change, you can close a producer by waiting for inflight messages and the pulsar-client does not fail those messages immediately.\\nPreviously, when you closed a producer, the pulsar-client immediately failed inflight messages even if it persisted successfully at the broker. Most of the time, users want to wait for those inflight messages rather than fail them. While the pulsar-client library did not provide a way to wait for inflight messages before closing the producer. This PR supports closing API with a flag where you can control waiting for inflight messages. With this change, you can close a producer by waiting for inflight messages and the pulsar-client does not fail those messages immediately.\\n\\nFor more information about implementation details, see [PR-6648](https://github.com/apache/pulsar/pull/6648).\\n\\n### Support loading TLS certs/key dynamically from input stream\\n\\nPreviously, the pulsar-client provided TLS authentication support and the default TLS provider `AuthenticationTls` expected file path of cert and key files. However, there were use cases where it was difficult for user applications to store certs/key files locally for TLS authentication. This PR adds stream support in `AuthenticationTls` to provide X509Certs and PrivateKey which also perform auto-refresh when streaming changes in a given provider.\\n\\nFor more information about implementation details, see [PR-6760](https://github.com/apache/pulsar/pull/6760).\\n\\n### Support returning sequence ID when throwing an exception for async send messages\\n\\nPreviously, when sending messages asynchronously failed, an exception was thrown, but did not know which message was abnormal, and users did not know which messages needed to be retried. This PR makes changes supported on the client side. When throwing an exception, the sequenceId `org.apache.pulsar.client.api.PulsarClientException` is set.\\n\\nFor more information about implementation details, see [PR-6825](https://github.com/apache/pulsar/pull/6825).\\n\\n\\n## More information\\n\\n- To download Apache Pulsar 2.6.0, click [here](https://pulsar.apache.org/en/download/).\\n- For more information about Apache Pulsar 2.6.0, see [2.6.0 release notes](https://pulsar.apache.org/release-notes/#2.6.0) and [2.6.0 PR list](https://github.com/apache/pulsar/pulls?q=milestone%3A2.6.0+-label%3Arelease%2F2.5.2+-label%3Arelease%2F2.5.1+).\\n\\nIf you have any questions or suggestions, contact us with mailing lists or slack.\\n\\n- [users@pulsar.apache.org](mailto:users@pulsar.apache.org)\\n- [dev@pulsar.apache.org](mailto:dev@pulsar.apache.org)\\n- Pulsar slack channel: https://apache-pulsar.slack.com/\\n- Self-registration at https://apache-pulsar.herokuapp.com/\\n\\nLooking forward to your contributions to [Pulsar](https://github.com/apache/pulsar)."},{"id":"/2020/05/19/Apache-Pulsar-2-5-2","metadata":{"permalink":"/blog/2020/05/19/Apache-Pulsar-2-5-2","editUrl":"https://github.com/apache/pulsar/edit/master/site2/website-next/blog/2020-05-19-Apache-Pulsar-2-5-2.md","source":"@site/blog/2020-05-19-Apache-Pulsar-2-5-2.md","title":"Apache Pulsar 2.5.2","description":"We are proud to publish Apache Pulsar 2.5.2. This is the result of a huge effort from the community, with over 56 commits, general improvements and bug fixes.","date":"2020-05-19T00:00:00.000Z","formattedDate":"May 19, 2020","tags":[],"readingTime":7.115,"truncated":true,"authors":[{"name":"Jia Zhai","url":"https://twitter.com/Jia_Zhai"}],"prevItem":{"title":"Apache Pulsar 2.6.0","permalink":"/blog/2020/06/18/Apache-Pulsar-2-6-0"},"nextItem":{"title":"Apache Pulsar 2.5.1","permalink":"/blog/2020/04/23/Apache-Pulsar-2-5-1"}},"content":"We are proud to publish Apache Pulsar 2.5.2. This is the result of a huge effort from the community, with over 56 commits, general improvements and bug fixes.\\n\\nFor detailed changes related to 2.5.2 release, refer to the <b>[release notes](/release-notes/#2.5.2)</b> and the <b>[PR list for Pulsar 2.5.2](https://github.com/apache/pulsar/pulls?q=is:pr%20label:release/2.5.2%20is:closed)</b>.\\n\\nThe following highlights some improved features and fixed bugs in this release.\\n\\n\x3c!--truncate--\x3e\\n\\n## Implement AutoTopicCreation by namespace level override\\n\\nIntroduce a new namespace policy `autoTopicCreationOverride`, which enables an override of broker `autoTopicCreation` settings on the namespace level. You can disable `autoTopicCreation` for the broker while allowing it on a specific namespace.\\n\\n## Add customized deletionLag and threshold for offloading policies per namespace\\n\\nSupport configuring `deletionLag` and threshold in the offloading policy on the namespace level to remove data from the offloaded tiered storage.\\n\\n## Invalidate managed ledgers ZooKeeper cache instead of reloading on watcher triggered\\n\\nThe ZooKeeper children cache is reloaded for z-nodes when topics are frequently created or deleted. This creates additional load on the ZooKeeper and the broker, slows down brokers and makes them less stable. In this release, `ZooKeeperManagedLedgerCache` is introduced to invalidate instead of reloading the ZooKeeper cache, when topics are created or deleted. This helps reduce pressures on the ZooKeeper.\\n\\n## Respect retention policy when there is no traffic\\n\\nIn previous releases, retention is checked when the ledger rollover happens. So if the traffic is stopped, the ledgers are not cleaned up even if all the messages are already acknowledged. In Pulsar 2.5.2, `retentionCheckIntervalInSeconds` is introduced to check if consumed ledgers need to be trimmed between intervals. If the value is set to 0 or a negative number, the system does not check the consumed ledgers.\\n\\n## Bump Netty version to 4.1.48.Final\\n\\nThe ZlibDecoders in Netty 4.1.x (before 4.1.46) allow for unbounded memory allocation while decoding a ZlibEncoded byte stream. An attacker could send a large ZlibEncoded byte stream to the Netty server, forcing the server to allocate all of its free memory to a single decoder. The bug is fixed in Netty `4.1.48.Final` .\\n\\n## Increase timeout for loading topics\\n\\nLoading replicated topics is quite an expensive operation and involves global ZooKeeper lookups and the start of many sub-processes. In Pulsar 2.5.2, we increase the timeout for loading topics which have many replicated clusters to 60 seconds.\\n\\n## Fix incorrect cursor state for cursor without consumers\\n\\nIf consumers of a subscription are closed, the cursor is set to inactive. But the cursor is set to active during `PulsarStats.updateStats()` when the backlog size is less than `backloggedCursorThresholdEntries`. In Pulsar 2.5.2, we move the `checkBackloggedCursors()` from `ManagedLedger` to `Topic` and check the consumer list to fix this bug.\\n\\n## Change non-durable cursor to active to improve performance\\n\\nIn non-durable subscription mode, the cursor is not active, which leads to the written entries not being put into cache. This would degrade the reading performance. In Pulsar 2.5.2, we set the `NonDurableCursorImpl` to active and remove three override methods `setActive()`, `isActive()`, `setInactive()` to improve the reading performance.\\n\\n## Add keystore configurations to TLS\\n\\nIn Pulsar 2.5.2, we add keystore configurations to the TLS to allow users to define their own CA certificates while the internal communication uses an internal CA certificate. This change keeps the original TLS settings untouched, and adds new configurations in needed paths.\\n\\n## Close producer when the topic does not exists\\n\\nIn previous releases, when we create a producer for a non-existent topic, the `ProducerImpl` object is hanging in the dump. This leads to OOM in micro-service which by mistake tries to produce consistently to a non-existent topic. In Pulsar 2.5.2, we fix the bug in the following two aspects:\\n\\n- Fix the exception handle for a non-existent topic.\\n- Change state to `Close` when the producer gets the `TopicDoesNotExists` exception.\\n\\n## Fix `topicPublishRateLimiter` not effective after restarting broker\\n\\nIn previous releases, when a publishing rate is configured on the namespace, it can limit the publishing rate. But when the broker is restarted, the limit expires. In Pulsar 2.5.2, this bug is fixed.\\n\\n## Expose pulsar_out_bytes_total and pulsar_out_messages_total for namespace/subscription/consumer\\n\\nAdd pulsar_out_bytes_total and pulsar_out_messages_total for the namespace, subscription, and consumer. This helps to avoid missing the rate to be computed in Prometheus or missing change of rates within the scraping interval.\\n\\n## Fix `ttlDurationDefaultInSeconds` policy\\n\\nThe TTL for namespaces should be retrieved from the broker configuration if it is not configured at namespace policies. In previous releases, the code only returns the value stored in namespace policies directly without judging if the TTL is configured or not. In Pulsar 2.5.2, we add a condition to test if TTL is configured at namespace policies. If not, the broker retrieves value stored in broker configuration and returns it as the output.\\n\\n## Fix long field parse in GenricJsonRecord\\n\\nFor messages sent in JSON schema, the long field is decoded as int if its value is smaller than `Integer.MAX_VALUE`. Otherwise, the long field is decoded as a string. Pulsar 2.5.2 introduces a field type check in GenericJsonRecord to fix this bug.\\n\\n## Fix the leak of cursor reset if message encode fails in Avro schema\\n\\nIf the Avro encode for a message fails after a few bytes are written, the cursor in the stream is not reset. The following `flush()`, which normally resets the cursor, is skipped if there is an exception. In Pulsar 2.5.2, we introduced a `flush()` in the finally block to fix this bug.\\n\\n## Update topic partitions automatically\\n\\nIn Pulsar 2.5.2, the C++ client supports previously-created producers and consumers to automatically update partitions when the partitions for a topic are updated.\\n\\n- Add a `boost::asio::deadline_timer` to `PartitionedConsumerImpl` and `PartitionedProducerImpl` to register a lookup task to detect partition changes periodically.\\n- Add an unsigned int configuration parameter to indicate the period of detecting partition changes.\\n- Unlock the `mutex_` in `PartitionedConsumerImpl::receive` after `state_` were checked.\\n\\n## Fix default message ID in sent callback\\n\\nIn previous releases, the `MessageId` in the callback is always the default value (`-1, -1, -1, -1`). In Pulsar 2.5.2, we remove the useless field `messageId` of `BatchMessageContainer::MessageContainer` and add the `const MessageId&` argument to `batchMessageCallBack`. Therefore, we can get the correct message ID in the callback if the message is sent successfully.\\n\\n## Fix message ID error if messages are sent to partitioned topics\\n\\nIf messages are sent to a partitioned topic, the `partition` field of the message ID is always set to -1 because the `SendReceipt` command only contains the ledger ID and the entry ID. In Pulsar 2.5.2, we fix this bug by adding a `partition` field to `ProducerImpl` and setting the `partition` field of the message ID with it in the `ackReceived` method.\\n\\n## Support Async mode for Pulsar Functions\\n\\nIn previous releases, Pulsar Functions does not support the Async mode, such as the user passed in a Function in the following format:\\n\\n```\\n\\nFunction<I, CompletableFuture<O>>\\n\\n```\\n\\nThis kind of function is useful if the Pulsar Functions use RPCs to call external systems. Therefore, in Pulsar 2.5.2, we introduce Async mode support for Pulsar Functions.\\n\\n\\n## Fix localrunner netty dependency issue\\n\\nIn Pulsar 2.5.2, we add a Log4j2 configuration file for pulsar-functions-local-runner to log to console by default. This helps troubleshoot the problem that Netty libraries are missing and the class is not found, when pulling in pulsar-functions-local-runner as a dependency and attempting to run Pulsar Functions locally.\\n\\n## Fix SerDe validation of Pulsar Functions update\\n\\nIn previous releases, the `outputSchemaType` field is improperly used to validate parameters for Pulsar Function updates. In fact, the `outputSerdeClassName` parameter should be used. In Pulsar 2.5.2, we fix this bug.\\n\\n## Avoid pre-fetching too much data when offloading data to HDFS\\n\\nIf too much data is pre-fetched when data is offloaded to HDFS, it may cause severe OOM. In Pulsar 2.5.2, the `managedLedgerOffloadPrefetchRounds` is introduced, which is used to set the maximum pre-fetch rounds for ledger reading for offloading data.\\n\\n## JDBC sink handles null fields in schema\\n\\nJDBC sink does not handle `null` fields. The schema registered in Pulsar allows for it and the table schema in MySQL has a column of the same name. When messages are sent to the JDBC sink without that field, an exception is thrown. In Pulsar 2.5.2, the JDBC sink uses the `setColumnNull` method to properly reflect the null field value in the database row.\\n\\n## Reference\\n\\nTo download Apache Pulsar 2.5.2, click [here](https://pulsar.apache.org/en/download/).\\n\\nIf you have any questions or suggestions, contact us with mailing lists or slack.\\n\\n- [users@pulsar.apache.org](mailto:users@pulsar.apache.org)\\n- [dev@pulsar.apache.org](mailto:dev@pulsar.apache.org)\\n- Pulsar slack channel: https://apache-pulsar.slack.com/\\n- Self-registration at https://apache-pulsar.herokuapp.com/\\n\\nLooking forward to your contributions to [Pulsar](https://github.com/apache/pulsar)."},{"id":"/2020/04/23/Apache-Pulsar-2-5-1","metadata":{"permalink":"/blog/2020/04/23/Apache-Pulsar-2-5-1","editUrl":"https://github.com/apache/pulsar/edit/master/site2/website-next/blog/2020-04-23-Apache-Pulsar-2-5-1.md","source":"@site/blog/2020-04-23-Apache-Pulsar-2-5-1.md","title":"Apache Pulsar 2.5.1","description":"We are proud to publish Apache Pulsar 2.5.1. This is the result of a huge effort from the community, with over 130 commits and a long list of new features, general improvements and bug fixes.","date":"2020-04-23T00:00:00.000Z","formattedDate":"April 23, 2020","tags":[],"readingTime":6.55,"truncated":true,"authors":[{"name":"Guangning E","url":"https://twitter.com/tuteng3"}],"prevItem":{"title":"Apache Pulsar 2.5.2","permalink":"/blog/2020/05/19/Apache-Pulsar-2-5-2"},"nextItem":{"title":"Announcing: The Apache Pulsar 2020 User Survey Report","permalink":"/blog/2020/03/17/announcing-the-apache-pulsar-2020-user-survey-report"}},"content":"We are proud to publish Apache Pulsar 2.5.1. This is the result of a huge effort from the community, with over 130 commits and a long list of new features, general improvements and bug fixes.\\n\\nFor detailed changes related to 2.5.1 release, refer to the <b>[release notes](/release-notes/#2.5.1)</b> and the <b>[PR list for Pulsar 2.5.1](https://github.com/apache/pulsar/pulls?q=is:pr%20label:release/2.5.1%20is:closed)</b>.\\n\\nThe following justs highlights a tiny subset of new features.\\n\\n\x3c!--truncate--\x3e\\n\\n## Refresh authentication credentials\\n\\nIn Pulsar 2.5.1, two more methods are introduced in the single `AuthenticationState` interface credentials holder. This helps enhance the Pulsar authentication framework to support credentials that expire over time and need to be refreshed by forcing clients to re-authenticate.\\n\\nExisting authentication plugins are unaffected. If a new plugin wants to support expiration, it just overrides the `isExpired()` method. The Pulsar broker ensures to periodically check the expiration status for the AuthenticationState of every `ServerCnx` object. You can also use the `authenticationRefreshCheckSeconds` setting to control the frequency of the expiration check.\\n\\n## Upgrade Avro to 1.9.1\\n\\nThe library used to handle logical datetime values has been changed from Joda-Time to JSR-310. For keeping forward compatibility, Pulsar java client uses Joda-Time conversion for logical datetime. To use JSR-310 conversion, you can enable it in the schema definition.\\n\\n```java\\n\\nAvroSchema.of(SchemaDefinition.builder()\\n.withJSR310ConversionEnabled(true)\\n.build()\\n\\n```\\n\\n:::note\\n\\nBy default, Avro 1.9.1 enables the JSR310 datetimes, which might introduce some regression problems if users use source codes generated by Avro compiler 1.8.x and the source codes contain datetimes fields. It is recommended to use Avro 1.9.x compiler to recompile.\\n\\n:::\\n\\nAnd, Avro may remove the Joda time support in the future. This may also be deleted in Pulsar in the future.\\n## Support unloading all partitions of a partitioned topic\\nBefore Pulsar 2.5.1, Pulsar supports unloading a non-partitioned topic or a partition of a partitioned topic. If there is a partitioned topic with too many partitions, users need to get all partitions and unload them one by one. In Pulsar 2.5.1, we support unloading all partitions of a partitioned topic.\\n## Supports evenly distributing topics count when splitting bundle\\nIn Pulsar 2.5.1, we introduce an option(`-balance-topic-count`) for bundle split. When setting this option to true, the given bundle is split into two parts and each part has the same amount of topics. In addition, we bring in a new Load Manager implementation named `org.apache.pulsar.broker.loadbalance.impl.BalanceTopicCountModularLoadManager`. The new Load Manager implementation splits the bundle with balance topics count.\\nYou can enable this feature in the broker.conf:\\n\\n```\\n\\ndefaultNamespaceBundleSplitAlgorithm=topic_count_equally_divide\\n\\n```\\n\\nIf you use the Pulsar Admin to split a bundle, you can use following command to split bundle based on topics count:\\n\\n```\\n\\nbin/pulsar-admin namespaces split-bundle -b 0x00000000_0xffffffff --split-algorithm-name topic_count_equally_divide public/default\\n\\n```\\n\\n## Support KeyValue schema for Pulsar SQL\\nBefore Pulsar 2.5.1, Pulsar SQL cannot read the keyValue schema data. In Pulsar 2.5.1, we add the prefix `key.` for the key field name, add the prefix `value.` for the value field name. Therefore, Pulsar SQL can read the keyValue schema data.\\n## Update Netty version to `4.1.45.Final`\\nNetty 4.1.43 has a bug, which prevents it from using Linux native Epoll transport. This makes Pulsar brokers fail over to NioEventLoopGroup even when running on Linux. The bug is fixed in Netty  `4.1.45.Final` .\\n## Improve Key_Shared subscription message dispatching performance\\nIn Pulsar 2.5.1, to improve Key_Shared subscription message dispatching performance, we make the following operations for saving CPU usage which can improve non-batched message dispatch performance:\\n- Reduce making hash for the message key.\\n- Reduce the number of finding consumers for message keys..\\n## Add Joda time logical type conversion\\nIn Pulsar 2.5.1, Avro is upgraded to 1.9.x and the default time conversion is changed to JSR-310. For forwarding compatibility, we add the Joda time conversion in Pulsar 2.5.1 and enable it by default\\n## Support deleting inactive topic when subscriptions caught up\\nBefore Pulsar 2.5.1, Pulsar supported deleting inactive topics that have no active producers or subscriptions. In Pulsar 2.5.1, we expose inactive topic delete mode in `broker.conf` to delete inactive topics that have no active producers or consumers but all subscriptions of the topic are caught up. You can enable this feature in the broker.conf:\\n\\n```\\n\\nbrokerDeleteInactiveTopicsMode=delete_when_subscriptions_caught_up\\n\\n```\\n\\n## Introduce maxMessagePublishBufferSizeInMB configuration to avoid broker OOM\\nBefore Pulsar 2.5.1, if a broker has a smaller direct memory (e.g. 2G) and runs pulsar-perf to write messages, the broker becomes unstable. Because the broker reads messages from the channel automatically and the ByteBuf cannot be released until the entry is written to Bookie successfully or the timeout expires.\\nIn Pulsar 2.5.1, we introduce the `maxMessagePublishBufferSizeInMB` configuration to avoid broker OOM (Out of Memory). If the processing message size exceeds this value, the broker stops reading data from the connection. When the available size is greater than half of the maxMessagePublishBufferSizeInMB,  the broker starts automatically reading data from the connection. You can set up the publish buffer size in broker.conf:\\n\\n```\\n\\n# Max memory size for broker handling messages sending from producers.\\n# If the processing message size exceed this value, broker will stop read data\\n# from the connection. The processing messages means messages are sends to broker\\n# but broker have not send response to client, usually waiting to write to bookies.\\n# It\'s shared across all the topics running in the same broker.\\n# Use -1 to disable the memory limitation. Default is 1/2 of direct memory.\\nmaxMessagePublishBufferSizeInMB=\\n\\n```\\n\\n## Support BouncyCastle FIPS provider\\nIn Pulsar 2.5.1, Pulsar supports BC-FIPS (BouncyCastle FIPS) provider. Before Pulsar 2.5.1, Pulsar only supported BouncyCastle (BC) provider, and BC JARs are tied strongly into both the broker and the client code. Users fail to change from the BC provider to the BC-FIPS provider. This feature splits the BC dependency out into a separate module. Therefore, users can freely switch between the BC provider and the BC-FIPS provider.\\n## Allow tenant Admin to manage subscription permission\\nIn previous releases, we have added support to grant subscriber-permission to manage subscription based APIs. However, grant-subscription-permission API requires super-user access and it creates too much dependency on system-admin when many tenants want to grant subscription permission.\\nIn Pulsar 2.5.1, through the Restful API or the Pulsar Admin, we allow each tenant Admin to manage subscription permission in order to reduce administrative efforts for super users.\\n## Allow to enable/disable delayed delivery for messages on namespace\\nIn Pulsar 2.5.1, we add the `set-delayed-delivery` and  `set-delayed-delivery-time`  policies for the namespace. Therefore, Pulsar 2.5.1 allows to enable or disable delayed delayed delivery for messages on namespace.\\n## Support offloader at namespace level\\nIn previous releases, the offload operation only had the cluster-level configuration. Users cannot set the offload configuration at the namespace level. In Pulsar 2.5.1, we support using the Pulsar Admin to set the offloader at the namespace level. \\n## Disallow sub auto creation by Admin when disabling topic auto creation\\nIn previous releases, when Auto topic creation is disabled in KoP, non-partitioned topics are created with Flink Pulsar Source. To fix this bug, in Pulsar 2.5.1, we change the admin code to disable sub auto creation by the Admin when Auto topic creation is disabled.\\n## Support Python 3.8 for Pulsar client\\nIn pulsar 2.5.1, we add `3.8 cp38-cp38` to support Python 3.8 for the Pulsar client. Therefore, users can install the Pulsar client on Python 3.8 .\\n## Provide another `libpulsarwithdeps.a` in Debian/RPM cpp client library\\nPulsar 2.5.1 mainly provides 2 additional pulsar c++ client libraries in Debian/RPM:\\n- pulsarSharedNossl (libpulsarnossl.so): it is similar to pulsarShared(libpulsar.so), and has no SSL statically linked.\\n- pulsarStaticWithDeps(libpulsarwithdeps.a): it is similar to pulsarStatic(libpulsar.a), and is archived in the dependencies libraries of `libboost_regex`, `libboost_system`, `libcurl`, `libprotobuf`, `libzstd` and `libz` statically.\\n## Reference\\nTo download Apache Pulsar 2.5.1, click [here](https://pulsar.apache.org/en/download/).\\nIf you have any questions or suggestions, contact us with mailing lists or slack.\\n- [users@pulsar.apache.org](mailto:users@pulsar.apache.org)\\n- [dev@pulsar.apache.org](mailto:dev@pulsar.apache.org)\\n- Pulsar slack channel: https://apache-pulsar.slack.com/\\n- Self-registration at https://apache-pulsar.herokuapp.com/\\nLooking forward to your contributions to [Pulsar](https://github.com/apache/pulsar)."},{"id":"/2020/03/17/announcing-the-apache-pulsar-2020-user-survey-report","metadata":{"permalink":"/blog/2020/03/17/announcing-the-apache-pulsar-2020-user-survey-report","editUrl":"https://github.com/apache/pulsar/edit/master/site2/website-next/blog/2020-03-17-announcing-the-apache-pulsar-2020-user-survey-report.md","source":"@site/blog/2020-03-17-announcing-the-apache-pulsar-2020-user-survey-report.md","title":"Announcing: The Apache Pulsar 2020 User Survey Report","description":"For the first time ever, the Apache Pulsar PMC team is publishing a user survey report.","date":"2020-03-17T00:00:00.000Z","formattedDate":"March 17, 2020","tags":[],"readingTime":2.245,"truncated":false,"authors":[{"name":"Sijie Guo","url":"https://twitter.com/sijieg"}],"prevItem":{"title":"Apache Pulsar 2.5.1","permalink":"/blog/2020/04/23/Apache-Pulsar-2-5-1"},"nextItem":{"title":"Pulsar milestone celebration\u2014200 contributors!","permalink":"/blog/2019/12/20/pulsar-milestone-200-contributors"}},"content":"For the first time ever, the Apache Pulsar PMC team is publishing a user survey report.\\n**The 2020 Apache Pulsar User Survey Report** reveals Pulsar\u2019s accelerating rate of global\\nadoption, details how organizations are leveraging Pulsar to build real-time streaming\\napplications, and highlights key features on Pulsar\u2019s product roadmap.\\n\\n![](/img/pulsar-user-ban.jpg)\\n\\nPulsar adoption has largely been driven by the market\u2019s increased demand for real-time,\\ndata-enabled technologies. While companies have tried to leverage monolithic messaging\\nsystems to build-out real-time offerings, they\u2019ve hit major roadblocks. Ultimately, these\\ntechnologies are not equipped to provide the scale or reliability that mission-critical\\napplications require.\\n\\nAs a result, companies have sought-out Apache Pulsar for its cloud-native, distributed\\nmessaging and streaming platform capabilities. From asynchronous applications to core\\nbusiness applications to ETL, companies are increasingly leveraging Pulsar to develop\\nreal-time applications.\\n\\nPulsar has received global adoption from major technology companies such as Verizon Media,\\nNarvar, Overstock, Nutanix, Yahoo! JAPAN, Tencent, OVHCloud, and Clever Cloud, who rely on\\nits ability to deliver on performance, scalability, and resiliency. As the Pulsar project\\nand community garner increasing attention, we\u2019re excited to share the **2020 Apache Pulsar User Survey Report**.\\n\\n![](/img/pulsar-adoption.png)\\n\\nIn the 2020 Apache Pulsar User Survey Report, we hear from 165 users and learn how their\\ncompanies are leveraging Pulsar\u2019s cloud-native, multi-layer design architecture, built-in\\nmulti-tenancy, and multi-cluster replication, to build scalable real-time offerings. This\\nreport details insights and use cases on how organizations are deploying Pulsar today.\\n\\nThe report also reveals Pulsar\u2019s top-used features, its most popular applications, and how\\nit is delivering scalable, reliable, real-time streaming solutions for organizations. In\\nthis quotation from Qiang Fei, Tech Lead for Tencent, we see how [one organization is leveraging Pulsar to improve their offering](https://streamnative.io/whitepaper/case-studay-apache-pulsar-tencent-billing/):\\n\\n> Pulsar provides us with a highly consistent and highly reliable distributed message queue that\\n> fits well in our financial use cases. Multi-tenant and storage separation architecture design\\n> greatly reduces our operational and maintenance overhead. We have used Pulsar on a very large\\n> scale in our organization and we are impressed that Pulsar is able to provide high consistency\\n> while supporting high concurrent client connections.\\n> \\n> - Qiang Fei, Tech Lead at Tencent\\n\\nFrom its built-in multi-tenancy, which reduces architectural complexity and enables organizations\\nto scale, to its multi-datacenter replication, which allows Pulsar to handle data center failures,\\nwe see how Pulsar has evolved into a robust and differentiated messaging and streaming platform.\\nThe report also reveals some of the community-driven features on Pulsar\u2019s product roadmap for 2020\\nand beyond. To find out more, [download the report today](https://streamnative.io/whitepaper/oss-apache-pulsar-user-survey-report-2020/).\\n\\nJoin us for the first-ever Apache Pulsar Summit on August 26, 2020, in San Francisco, CA.\\nMore details on the Summit to come!"},{"id":"/2019/12/20/pulsar-milestone-200-contributors","metadata":{"permalink":"/blog/2019/12/20/pulsar-milestone-200-contributors","editUrl":"https://github.com/apache/pulsar/edit/master/site2/website-next/blog/2019-12-20-pulsar-milestone-200-contributors.md","source":"@site/blog/2019-12-20-pulsar-milestone-200-contributors.md","title":"Pulsar milestone celebration\u2014200 contributors!","description":"Dear Apache Pulsar enthusiast,","date":"2019-12-20T00:00:00.000Z","formattedDate":"December 20, 2019","tags":[],"readingTime":1.38,"truncated":false,"authors":[{"name":"Yu Liu","url":"https://twitter.com/Anonymitaet1"}],"prevItem":{"title":"Announcing: The Apache Pulsar 2020 User Survey Report","permalink":"/blog/2020/03/17/announcing-the-apache-pulsar-2020-user-survey-report"},"nextItem":{"title":"Pulsar Summit San Francisco 2020 CFP is now open","permalink":"/blog/2019/12/18/Pulsar-summit-cfp"}},"content":"Dear Apache Pulsar enthusiast,\\n\\nAs we know, when assessing the health of an open-source community, it is tempting to focus on various quantitative metrics, for example, activity, size (contributors), demographics, diversity, and so on, among which the number of contributors is a key metric for measuring the health and popularity of a project and a way to inform the trends. \\n\\nAnd today, we are very proud to see that **Apache Pulsar has attracted its 200th contributor!** It is an important milestone for our community growth.\\n\\nOver the years, there\u2019s been an upward trend that more organizations embracing real-time data and stream processing, and Pulsar is the key component of that shift. As an open-source distributed pub-sub messaging system originally created at Yahoo! and graduated as a Top-Level Project (TLP) in September 2018, Pulsar has launched 79 releases, attracted 4100+ commits from 200 contributors, and received 4.6k+ stars, 1.2k+ forks, and 1.3k+ Slack users up to now.\\n\\n![](/img/p-200.png)\\n\\nThis achievement is worth celebrating, and at the same time, we would like to **express sincere gratitude to you** for making what Pulsar is today and shape what Pulsar will be tomorrow.\\n\\nPulsar aims to empower the next generation of event streaming systems by delivering a unified solution that connects, stores and processes real-time event streams. Going forward, we will be continuously dedicated to making Pulsar as a highly flexible, scalable and reliable product and creating a welcoming and sustainable community where Pulsar and you can thrive together.\\n\\n![](/img/cooperation.png)\\n\\nP.S. want to be a Pulsar contributor? \\n\\nGet started today by [reading contribution guidelines](http://pulsar.apache.org/en/contributing/) and [submitting a PR](https://github.com/apache/pulsar), any contribution on codes, docs or other is highly appreciated. Thank you."},{"id":"/2019/12/18/Pulsar-summit-cfp","metadata":{"permalink":"/blog/2019/12/18/Pulsar-summit-cfp","editUrl":"https://github.com/apache/pulsar/edit/master/site2/website-next/blog/2019-12-18-Pulsar-summit-cfp.md","source":"@site/blog/2019-12-18-Pulsar-summit-cfp.md","title":"Pulsar Summit San Francisco 2020 CFP is now open","description":"Pulsar Summit is an annual conference dedicated to Apache Pulsar community, bringing together an international audience of CTOs/CIOs, developers, data architects, data scientists, Apache Pulsar committers/contributors, and the messaging and streaming community, to share experiences, exchange ideas and knowledge about Pulsar and its growing community, and receive hands-on training sessions led by Pulsar experts.","date":"2019-12-18T00:00:00.000Z","formattedDate":"December 18, 2019","tags":[],"readingTime":2.075,"truncated":false,"authors":[{"name":"Jennifer Huang","url":"https://twitter.com/Jennife06125739"}],"prevItem":{"title":"Pulsar milestone celebration\u2014200 contributors!","permalink":"/blog/2019/12/20/pulsar-milestone-200-contributors"},"nextItem":{"title":"Apache Pulsar 2.4.2","permalink":"/blog/2019/12/04/Apache-Pulsar-2-4-2"}},"content":"Pulsar Summit is an annual conference dedicated to Apache Pulsar community, bringing together an international audience of CTOs/CIOs, developers, data architects, data scientists, Apache Pulsar committers/contributors, and the messaging and streaming community, to share experiences, exchange ideas and knowledge about Pulsar and its growing community, and receive hands-on training sessions led by Pulsar experts.\\n\\nWe are excited to announce that the first Pulsar Summit will be held in San Francisco in April, 2020. Talk submissions, pre-registration, and sponsorship opportunities are now open for the conference!\\n\\n## Speak at Pulsar Summit\\nPresentations and lightning talks are accepted for speaking proposals. Suggested topics cover Pulsar use cases, operations, technology deep dive, and ecosystem. Submissions are open until **January 31, 2020**.\\n\\nIf you are unsure about your proposal, or want some feedback or advice in general, please do not hesitate to reach out to [sf-2020@pulsar-summit.org](mailto:sf-2020@pulsar-summit.org). We are happy to help out! Further details are available on the [CFP website](https://pulsar-summit.org/call-for-presentations/).\\n\\n## Dates to remember\\n- CFP opens: December 15, 2019\\n- CFP closes: January 31, 2020 - 23:59 PST\\n- CFP notification: February 21, 2020\\n- Schedule announcement: February 24, 2020\\n\\n## Speaker benefits\\nWhen your speaking proposal is approved, you will enjoy the following benefits:\\n\\n- Full conference pass.\\n- Exclusive swag only available to speakers.\\n- Expand your network and raise your profile in the Pulsar community.\\n- A professionally produced video of your presentation.\\n- Your name, title, company, and bio will be featured on the Pulsar Summit San Francisco 2020 website.\\n- Your session will be added to the Pulsar Summit YouTube Channel and promoted on Twitter and LinkedIn.\\n\\n## Pre-registration\\nIf you are interested in attending Pulsar Summit San Francisco 2020, we\u2019d like to hear from you with your [pre-registration](https://pulsar-summit.org/pre-registration/). Your ideas are very important to us, and we will prepare the content accordingly. \\n\\nAfter you submit the pre-registration form, you will be added to the waitlist of Pulsar Summit San Francisco 2020. Once the registration is open, you will be notified with an email.\\n\\n## Sponsor Pulsar Summit\\nPulsar Summit is a community run conference and your support is needed. Sponsoring this event will provide a great opportunity for your organization to further engage with the Apache Pulsar community. [Contact us](mailto:partners@pulsar-summit.org) to learn more.\\n\\nHelp us make #PulsarSummit 2020 a big success by spreading the word and submitting your proposal! Follow us on Twitter ([@pulsarsummit](https://twitter.com/PulsarSummit)) to receive the latest updates of the conference!\\n\\nHope to see you at Pulsar Summit San Francisco 2020!"},{"id":"/2019/12/04/Apache-Pulsar-2-4-2","metadata":{"permalink":"/blog/2019/12/04/Apache-Pulsar-2-4-2","editUrl":"https://github.com/apache/pulsar/edit/master/site2/website-next/blog/2019-12-04-Apache-Pulsar-2-4-2.md","source":"@site/blog/2019-12-04-Apache-Pulsar-2-4-2.md","title":"Apache Pulsar 2.4.2","description":"We are proud to publish Apache Pulsar 2.4.2. Thank the great efforts from Apache Pulsar community with over 110 commits, covering improvements and bug fixes.","date":"2019-12-04T00:00:00.000Z","formattedDate":"December 4, 2019","tags":[],"readingTime":5.105,"truncated":true,"authors":[{"name":"Xiaolong Ran","url":"https://twitter.com/wolf4j1"}],"prevItem":{"title":"Pulsar Summit San Francisco 2020 CFP is now open","permalink":"/blog/2019/12/18/Pulsar-summit-cfp"},"nextItem":{"title":"Apache Pulsar 2.4.0","permalink":"/blog/2019/07/05/Apache-Pulsar-2-4-0"}},"content":"We are proud to publish Apache Pulsar 2.4.2. Thank the great efforts from Apache Pulsar community with over 110 commits, covering improvements and bug fixes.\\n\\nFor detailed changes related to 2.4.2 release, refer to <b>[release notes](/release-notes/#2.4.2)</b>.\\n\\nI will highlight some improvements and bug fixes in this blog.\\n\\n\x3c!--truncate--\x3e\\n\\n## Use classLoaders to load Java functions\\nIn Pulsar 2.4.2, windowed functions can work well whether Java Functions instances use shaded JAR or classLoaders, and functionClassLoader is set correctly when the `--output-serde-classname` option is enabled.\\n\\nBefore Pulsar 2.4.2, Java Functions instances are started with a shaded JAR, and different classLoaders are used to load the internal Pulsar code, user code, and the interfaces that the two interacts with each other. This change results in two issues:\\n- The windowed functions do not work well if Java Functions instances use classLoaders. \\n- When using the `--output-serde-classname` option, functionClassLoader is not set correctly.  \\n\\n## Start Broker with Functions worker  \\nIn Pulsar 2.4.2, we can start Broker with Functions worker when broker client is enabled with TLS. Before Pulsar 2.4.2, when we run Functions worker with the broker, it checks whether TLS is enabled in the `function_worker.yml` file. If TLS is enabled, it uses TLS port. However, when TLS is enabled on Functions worker, it checks the `broker.conf`. Since Functions worker runs with the broker, it makes sense to check the `broker.conf` as the single source of truth about whether or not to use TLS. \\n\\n## Add error code and error message when a key does not exist\\nIn Pulsar Functions, BookKeeper is supported to store the state of Functions. When users attempt to fetch a key that does not exist from function state, an NPE(NullPointerException) error occurs. In Pulsar 2.4.2, we add error code and error message for the case when a key does not exist.\\n\\n## Deduplication\\nDeduplication removes messages based on the the largest sequence ID that pre-persisted. If an error is persisted to BookKeeper, a retry attempt is \u201cdeduplicated\u201d with no message ever getting persisted. In version 2.4.2, we fix the issue from the following two aspects:                                                                                              \\n- Double check the pending messages and return error to the producer when the duplication status is uncertain. For example, when a message is still pending.\\n- Sync back the lastPushed map with the lastStored map after failures.\\n\\n## Consume data from the earliest location\\nIn Pulsar 2.4.2, we add `--subs-position` for Pulsar Sinks, so users can consume data from the latest and earliest locations. Before 2.4.2 release, data in topics is consumed from the latest location in Pulsar Sinks by default, and users can not consume the earliest data in sink topic. \\n\\n## Close previous dispatcher when the subscription type changes\\n\\nIn Pulsar 2.4.2, when the type of a subscription changes, a new dispatcher is created, and the old dispatcher is closed, thus avoiding memory leaks. Before 2.4.2, when the subscription type of a topic changes, a new dispatcher is created and the old one is discarded, yet not closed, which causes memory leaks. If the cursor is not durable, the subscription is closed and removed from the topic when all consumers are removed. The dispatcher should be closed at this time. Otherwise, RateLimiter instances are not garbage collected, which results in a memory leak. \\n\\n## Select an active consumer based on the subscription order\\nIn Pulsar 2.4.2, the active consumer is selected based on the subscription order. The first consumer in the consumer list is selected as an active consumer without sorting. Before 2.4.2, the active consumer is selected based on the priority level and consumer name. In this case, the active consumer joins and leaves, and no consumer is actually elected as \\"active\\" or consumes messages. \\n\\n## Remove failed stale producer from the connection\\nIn Pulsar 2.4.2, failed producer is removed correctly from the connection. Before Pulsar 2.4.2, broker cannot clean up the old failed producer correctly from the connection. When broker tries to clean up `producer-future` in the failed producer, it removes the newly created `producer-future` rather than the old failed producer, and the following error occurs in broker.\\n\\n```text\\n\\n17:22:00.700 [pulsar-io-21-26] WARN  org.apache.pulsar.broker.service.ServerCnx - [/1.1.1.1:1111][453] Producer with id persistent://prop/cluster/ns/topic is already present on the connection\\n\\n```\\n\\n## Add new APIs for schema\\nIn Pulsar 2.4.2, we add the following APIs for schema:\\n- `getAllVersions`: return the list of schema versions for a given topic.\\n- `testCompatibility`: be able to test the compatibility for a schema without registering it.\\n- `getVersionBySchema`: provide a schema definition and provide the schema version for it.\\n\\n## Expose `getLastMessageId()` method in consumerImpl\\nIn Pulsar 2.4.2, we expose `getLastMessageId()` method in consumerImpl. It benefits users when they want to know the lag messages, or only consume messages before the current time.                                                     \\n\\n## Add new `send()` interface in C++/Go\\nIn Pulsar 2.4.2, we add new `send()` interface in C++/Go, so the `MessageID` will be returned to users. The logic is consistent with that in Java. In Java client, the `MessageId send(byte[] message)` returns `MessageId` for users.\\n\\n## Consumer background tasks are cancelled after subscription failures\\nIn Pulsar 2.4.2, we ensure that consumer background tasks are cancelled after subscription failures. Before 2.4.2, some background consumer tasks are started in the ConsumerImpl constructor though these tasks are not cancelled if the consumer creation fails, leaving active references to these objects. \\n\\n## Delete topics attached with regex consumers\\nIn Pulsar 2.4.2, we can delete topics attached with a regex consumer. The followings are detailed methods.\\n- Add a flag in CommandSubscribe so that a regex consumer will never trigger the creation of a topic.\\n- Subscribe to a non-existing topic. When a specific error occurs, the consumer is interpreted as a permanent failure and thus stopping retrying.\\n\\nBefore 2.4.2, it\'s not possible to delete topics when there is a regex consumer attached to them. The reason is that the regex consumer will immediately reconnect and re-create the topic. \\n\\n## Reference\\n\\nDownload Pulsar 2.4.2 [here](https://pulsar.apache.org/en/download/). \\n\\nIf you have any questions or suggestions, contact us with mailing lists or slack. \\n- [users@pulsar.apache.org](mailto:users@pulsar.apache.org) \\n- [dev@pulsar.apache.org](mailto:dev@pulsar.apache.org) \\n- Pulsar slack channel: https://apache-pulsar.slack.com/\\n- You can self-register at https://apache-pulsar.herokuapp.com/\\n\\nLooking forward to your contributions to [Pulsar](https://github.com/apache/pulsar)."},{"id":"/2019/07/05/Apache-Pulsar-2-4-0","metadata":{"permalink":"/blog/2019/07/05/Apache-Pulsar-2-4-0","editUrl":"https://github.com/apache/pulsar/edit/master/site2/website-next/blog/2019-07-05-Apache-Pulsar-2-4-0.md","source":"@site/blog/2019-07-05-Apache-Pulsar-2-4-0.md","title":"Apache Pulsar 2.4.0","description":"We are glad to publish Apache Pulsar 2.4.0. This is the result of a huge","date":"2019-07-05T00:00:00.000Z","formattedDate":"July 5, 2019","tags":[],"readingTime":2.44,"truncated":true,"authors":[{"name":"Penghui Li","url":"https://twitter.com/lipenghui6"}],"prevItem":{"title":"Apache Pulsar 2.4.2","permalink":"/blog/2019/12/04/Apache-Pulsar-2-4-2"},"nextItem":{"title":"Apache Pulsar 2.3.0","permalink":"/blog/2019/02/20/Apache-Pulsar-2-3-0"}},"content":"We are glad to publish Apache Pulsar 2.4.0. This is the result of a huge \\neffort from the community, with over 460 commits and a long list of new features, \\ngeneral improvements and bug fixes.\\n\\nCheck out the <b>[release notes](/release-notes/#2.4.0)</b> for a detailed list of \\nthe changes, with links to the relevant pull requests, discussions and documentation.\\n\\nRegarding new features introduced, I just want to highlight here a tiny subset of them:\\n\\n\x3c!--truncate--\x3e\\n\\n### Delayed message delivery\\n\\nIt\'s now possible to send a delayed message by Pulsar producer, and a delayed message will be\\navailable after a delay time.\\n\\nThe Java code for a client using delayed messages delivery looks as follows:\\n\\n```java\\n\\nproducer.newMessage().value(\\"delayed message\\").deliverAfter(10, TimeUnit.SECONDS).send()\\n\\n```\\n\\n:::note\\n\\n1. Messages are only delayed on shared subscriptions, other subscriptions will deliver immediately.\\n2. Delayed messages are sent individually even if you enable message batching on producer.\\n\\n:::\\n\\n### Go Functions\\n\\nBefore 2.4.0 release, Java and Python are supported to write Pulsar Functions. Now, you can \\nuse Go to write Pulsar Functions, the following is an example of \\na Pulsar Function written in Go.\\n\\n```go\\n\\nimport (\\n    \\"fmt\\"\\n    \\"context\\"\\n\\n    \\"github.com/apache/pulsar/pulsar-function-go/pf\\"\\n)\\n\\nfunc HandleRequest(ctx context.Context, in []byte) error {\\n    fmt.Println(string(in) + \\"!\\")\\n    return nil\\n}\\n\\nfunc main() {\\n    pf.Start(HandleRequest)\\n}\\n\\n```\\n\\n### Key_Shared subscription\\n\\nA new subscription mode `Key_shared` is introduced in 2.4.0. In `Key_shared` subscription mode, \\none partition could have several consumers to consume messages in parallelism and ensure messages \\nwith the same key are distributed to a consumer in order. \\nHere is [architecture](http://pulsar.apache.org/docs/en/concepts-messaging/#key_shared) \\nfor Key_Shared.\\n\\nThe following is an example to use `Key_shared` subscription:\\n\\n```java\\n\\nclient.newConsumer()\\n        .topic(\\"topic\\")\\n        .subscriptionType(SubscriptionType.Key_Shared)\\n        .subscriptionName(\\"sub-1\\")\\n        .subscribe();\\n\\n```\\n\\n### Schema versioning\\n\\nBefore 2.4.0 release, Avro schema used one schema for both writer schema and reader schema. \\nMultiple schemas version is supported now.\\n\\nWith multiple schemas, a producer can send messages with different schema versions and a consumer \\ncan read messages with different schemas.\\n\\nIn 2.4.0 release, `FORWARD_TRANSITIVE`, `BACKWARD_TRANSITIVE` and `FULL_TRANSITIVE` compatibility \\nstrategies are added to check the compatibility with all existing schema version.\\n\\n### Replicated subscription\\n\\nIn 2.4.0 release, a mechanism is added to keep subscription state in sync, within a sub-second timeframe, \\nin the context of a topic that is being asynchronously replicated across multiple geographical \\nregions. Here is [architecture](https://github.com/apache/pulsar/wiki/PIP-33%3A-Replicated-subscriptions) \\nfor replicated subscription.\\n\\nThe following is an example to use replicated subscription:\\n\\n```java\\n\\nConsumer<String> consumer = client.newConsumer(Schema.STRING)\\n            .topic(\\"my-topic\\")\\n            .subscriptionName(\\"my-subscription\\")\\n            .replicateSubscriptionState(true)\\n            .subscribe();\\n\\n```\\n\\n### New IO connectors\\n\\nA new batch of connectors is added, including Flume, Redis sink, Solr sink, RabbitMQ sink. \\nThe following lists builtin [connectors](http://pulsar.apache.org/docs/en/io-connectors/) \\nthat Pulsar supports.\\n\\n### Security\\n\\nIn 2.4.0 release, Kerberos is supported in Apache Pulsar broker and client. \\nTo enable Kerberos authentication, refer to the [document](http://pulsar.apache.org/docs/en/security-kerberos/).\\n\\nAlso added role based Pulsar Function authentication and authorization.\\n\\n## Conclusion\\n\\nIf you want to download Pulsar 2.4.0, click [here](/download). You can send any questions or suggestions \\nto our mailing lists, contribute to Pulsar on [GitHub](https://github.com/apache/pulsar) or join \\nthe Apache Pulsar community on [Slack](https://apache-pulsar.herokuapp.com/)."},{"id":"/2019/02/20/Apache-Pulsar-2-3-0","metadata":{"permalink":"/blog/2019/02/20/Apache-Pulsar-2-3-0","editUrl":"https://github.com/apache/pulsar/edit/master/site2/website-next/blog/2019-02-20-Apache-Pulsar-2-3-0.md","source":"@site/blog/2019-02-20-Apache-Pulsar-2-3-0.md","title":"Apache Pulsar 2.3.0","description":"The Apache Pulsar PMC is happy to announce the release of Pulsar 2.3.0. This","date":"2019-02-20T00:00:00.000Z","formattedDate":"February 20, 2019","tags":[],"readingTime":3.36,"truncated":true,"authors":[{"name":"Matteo Merli","url":"https://twitter.com/merlimat"}],"prevItem":{"title":"Apache Pulsar 2.4.0","permalink":"/blog/2019/07/05/Apache-Pulsar-2-4-0"},"nextItem":{"title":"Apache Pulsar 2.1.0-incubating","permalink":"/blog/2018/08/06/Apache-Pulsar-2-1-0"}},"content":"The Apache Pulsar PMC is happy to announce the release of Pulsar 2.3.0. This\\nis the result of huge effort from the community, with over 480 commits and\\na long list of new features, general improvements and bug fixes.\\n\\nThese improvements have been across the board in all of Pulsar components,\\nfrom new messaging features, to improved usability for Pulsar Functions\\nand Pulsar IO.\\n\\nCheck out the official <b>[release notes](/release-notes/#2.3.0)</b> for a\\ndetailed list of the changes, with links to the relevant pull-requests,\\ndiscussions and documentation.\\n\\nRegarding new features introduced, I just want to highlight here a tiny\\nsubset of them:\\n\\n\x3c!--truncate--\x3e\\n\\n### Pulsar functions in Kubernetes\\n\\nIt\'s now possible to use Kubernetes as the scheduler for Pulsar Functions.\\n\\nWhen a Pulsar cluster is configured to use Kubernetes, submitting a\\nfunction, using CLI tools or REST API, will cause the function instances\\nto be submitted as Kubernetes pods rather than running as processes\\nor threads within the Pulsar functions worker.\\n\\nWith this runtime manager, it\'s possible to set quota on CPU/Mem and\\nhave Kubernetes assign the required resources and enforce isolation\\nbetween different instances and functions.\\n\\n###  New Pulsar IO connectors:\\n\\nA new batch of connectors was added, including MongoDB, Elastic Search,\\nHBase and local files source and sink.\\n\\nWe introduce support for doing [Change-Data-Capture](https://en.wikipedia.org/wiki/Change_data_capture)\\nwith [Debezium](https://debezium.io/). This allows to record all\\nthe update from a database into a Pulsar topic and use it for replication,\\nstreaming jobs, cache updating, etc..\\n\\nWith Pulsar IO, Debezium will run as a regular Pulsar IO source,\\ncompletely managed by Pulsar. Users can easily submit a Debezium\\nbuiltin connector to a Pulsar cluster and start feeding data\\nfrom a long list of supported databases like MySQL, MongoDB,\\nPostgreSQL, Oracle and SQL Server.\\n\\nCheck out the [Debezium connector](/docs/io-cdc) documentation for how\\nto get started in capturing database changes.\\n\\n### Token Authentication\\n\\nToken Authentication provides a very simple and secure method of authentication for Pulsar.\\nThis is based on [JSON Web Tokens](https://jwt.io/).\\n\\nWith tokens authentication, a client only needs to provide a single credential, or \\"token\\", in the\\nform of an opaque string provided by either the system administrator or some automated service.\\n\\nThe Java code for a client using token authentication will look like:\\n\\n```java\\n\\nPulsarClient client = PulsarClient.builder()\\n    .serviceUrl(\\"pulsar://broker.example.com:6650/\\")\\n    .authentication(\\n        AuthenticationFactory.token(\\"eyJhbGciOiJIUzI1NiJ9.eyJzdWIiOiJKb2UifQ.ipevRNuRP6HflG8cFKnmUPtypruRC4fb1DWtoLL62SY\\")\\n    .build();\\n\\n```\\n\\nSee [Client Authentication using tokens](/docs/security-token-client) for a complete walk through\\nand instructions on how to set it up and manage it.\\n\\n\\n### Schema support in Python client library\\n\\nThis feature adds a Python idiomatic way to declare the schema\\nof a producer or consumer and integrates directly with the Pulsar\\nschema registry.\\n\\n```python\\n\\nimport pulsar\\nfrom pulsar.schema import *\\n\\nclass Example(Record):\\n    a = String()\\n    b = Integer()\\n    c = Boolean()\\n\\nproducer = client.create_producer(\\n                    topic=\'my-topic\',\\n                    schema=AvroSchema(Example) )\\n\\nproducer.send(Example(a=\'Hello\', b=1))\\n\\n```\\n\\nThe above example will make the producer `Example` schema to be\\nvalidated by broker when we try to publish on `my-topic`. If the\\ntopic has a schema that is incompatible, the producer creation will\\nfail.\\n\\nCurrently, the Python schema support Avro and JSON, in addition to\\nregular types like `str` and `bytes`.\\n\\nThe complete documentation is available at [Python schema](/docs/client-libraries-python/#schema).\\n\\n### Function state API in Python\\n\\nFrom 2.3.0, Python function can access the state in as similar\\nway as Java functions, through the context object.\\n\\n```python\\n\\nimport pulsar\\n\\n# The classic ExclamationFunction that appends an\\n# exclamation at the end of the input\\nclass WordCountFunction(pulsar.Function):\\n    def process(self, input, context):\\n        for word in input.split():\\n            context.incr_counter(word, 1)\\n        return input + \\"!\\"\\n\\n```\\n\\nAvailable methods for state management in the context object are:\\n\\n```python\\n\\ndef incr_counter(self, key, amount):\\n  \\"\\"incr the counter of a given key in the managed state\\"\\"\\n\\ndef get_counter(self, key):\\n  \\"\\"\\"get the counter of a given key in the managed state\\"\\"\\"\\n\\ndef put_state(self, key, value):\\n  \\"\\"\\"update the value of a given key in the managed state\\"\\"\\"\\n\\ndef get_state(self, key):\\n  \\"\\"\\"get the value of a given key in the managed state\\"\\"\\"\\n\\n```\\n\\n## Conclusion\\n\\nPlease [download](/download) Pulsar 2.3.0 and report feedback, issues or any comment into our mailing lists,\\nslack channel or Github page. ([Contact page](/contact))"},{"id":"/2018/08/06/Apache-Pulsar-2-1-0","metadata":{"permalink":"/blog/2018/08/06/Apache-Pulsar-2-1-0","editUrl":"https://github.com/apache/pulsar/edit/master/site2/website-next/blog/2018-08-06-Apache-Pulsar-2-1-0.md","source":"@site/blog/2018-08-06-Apache-Pulsar-2-1-0.md","title":"Apache Pulsar 2.1.0-incubating","description":"We are glad to present the new 2.1.0-incubating release of Pulsar.","date":"2018-08-06T00:00:00.000Z","formattedDate":"August 6, 2018","tags":[],"readingTime":3.36,"truncated":true,"authors":[{"name":"Sijie Guo","url":"https://twitter.com/sijieg"}],"prevItem":{"title":"Apache Pulsar 2.3.0","permalink":"/blog/2019/02/20/Apache-Pulsar-2-3-0"}},"content":"We are glad to present the new 2.1.0-incubating release of Pulsar.\\nThis release is the culmination of 2 months of work that have\\nbrought multiple new features and improvements to Pulsar. \\n\\nIn Pulsar 2.1 you\'ll see:\\n\\n- [Pulsar IO](/docs/io-overview) connector framework and a list of [builtin connectors](/docs/io-connectors)\\n- [PIP-17](https://github.com/apache/incubator-pulsar/wiki/PIP-17:-Tiered-storage-for-Pulsar-topics): [Tiered Storage](/docs/concepts-tiered-storage)\\n- Pulsar [Stateful Functions](/docs/functions-state)\\n- [Go Client](/docs/client-libraries-go)\\n- [Avro](https://github.com/apache/incubator-pulsar/blob/v2.1.0-incubating/pulsar-client-schema/src/main/java/org/apache/pulsar/client/impl/schema/AvroSchema.java)\\n  and [Protobuf](https://github.com/apache/incubator-pulsar/blob/v2.1.0-incubating/pulsar-client-schema/src/main/java/org/apache/pulsar/client/impl/schema/ProtobufSchema.java) Schemas\\n\\nFor details information please check the detailed [release notes](/release-notes/#2.1.0-incubating) and [2.1.0 documentation](/versions).\\n\\n\x3c!--truncate--\x3e\\n\\nWe\'ll provide a brief summary of these features in the section below.\\n\\n## Pulsar IO\\n\\nSince Pulsar 2.0, we introduced a serverless inspired lightweight computing framework [Pulsar Functions](/docs/functions-overview),\\nproviding the easiest possible way to implement application-specific in-stream processing logic of any complexity. A lot of developers\\nlove Pulsar Functions because they require minimal boilerplate and are easy to reason about.\\n\\nIn Pulsar 2.1, we continued following this \\"simplicity first\\" principle on developing Pulsar. We developed this IO (input/output) connector\\nframework on top of Pulsar Functions, to simplify getting data in and out of Apache Pulsar. You don\'t need to write any single line of code.\\nAll you need is prepare a configuration file of the system your want to connect to, and use Pulsar admin\\nCLI to submit a connector to Pulsar. Pulsar will take care of all the other stuffs, such as fault-tolerance, rebalancing and etc.\\n\\nThere are 6 built-in connectors released in 2.1 release. They are:\\n\\n- [Aerospike Connector](/docs/io-aerospike/)\\n- [Cassandra Connector](/docs/io-cassandra/)\\n- [Kafka Connector](/docs/io-kafka/)\\n- [Kinesis Connector](/docs/io-kinesis/)\\n- [RabbitMQ Connector](/docs/io-rabbitmq/)\\n- [Twitter Firehose Connector](/docs/io-twitter/) \\n\\nYou can follow [the tutorial](/docs/io-quickstart) to try out Pulsar IO on connecting Pulsar with [Apache Cassandra](http://cassandra.apache.org/).\\n\\nMore connectors will be coming in future releases. If you are interested in contributing a connector to Pulsar, checkout the guide on [Developing Connectors](/docs/io-develop).\\nIt is as simple as writing a Pulsar function.\\n\\n## Tiered Storage\\n\\nOne of the advantages of Apache Pulsar is [its segment storage](https://streaml.io/blog/pulsar-segment-based-architecture) using [Apache BookKeeper](https://bookkeeper.apache.org/). You can store a topic backlog as large as you want.\\nWhen the cluster starts to run out of space, you just add another storage node, and the system will automatically\\npickup the new storage nodes and start using them without rebalancing partitions. However, this can start to get expensive after a while.\\n\\nPulsar mitigates this cost/size trade-off by providing Tiered Storage. Tiered Storage turns your Pulsar topics into real *infinite* streams,\\nby offloading older segments into a long term storage, such as AWS S3, GCS and HDFS, which is designed for storing cold data. To the end user,\\nthere is no perceivable difference between consuming streams whose data is stored in BookKeeper or in long term storage. All the underlying\\noffloading mechanisms and metadata management are transparent to applications.\\n\\nCurrently [S3](https://aws.amazon.com/s3/) is supported in 2.1. More offloaders (such as Google GCS, Azure Blobstore, and HDFS) are coming\\nin future releases.\\n\\nIf you are interested in this feature, you can checkout more details [here](/docs/cookbooks-tiered-storage).\\n\\n## Stateful Function\\n\\nThe greatest challenge that stream processing engines face is managing *state*. So does Pulsar Functions. As the goal for Pulsar Functions\\nis to simplify developing stream native processing logic, we also want to provide an easier way for Pulsar Functions to manage their state.\\nWe introduced a set of [State API](/docs/functions-state/#api) for Pulsar Functions to store their state. It integrates with the table service\\nin Apache BookKeeper for storing the state.\\n\\nIt is released as a developer preview feature in Pulsar Functions Java SDK. We would like to collect feedback to improve it in future releases.\\n\\n## Schemas\\n\\nPulsar 2.0 introduces native support for schemas in Pulsar. It means you can declare how message data looks and have Pulsar enforce that\\nproducers can only publish valid data on the topics. In 2.0, Pulsar only supports `String`, `bytes` and `JSON` schemas. We introduced the\\nsupport for [Avro](https://avro.apache.org/) and [Protobuf](https://developers.google.com/protocol-buffers/) in this release. \\n\\n## Clients\\n\\nWe have introduced a new [Go](/docs/client-libraries-go) client in 2.1 release. The Pulsar Go client library is based on the [C++](/docs/client-libraries-cpp/) client library.\\n\\nFollow [the instructions](/docs/client-libraries-go/#installing-go-package) to try it out in your Go applications!"}]}')}}]);