<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
    <id>https://pulsar.apache.com/blog</id>
    <title>Apache Pulsar Blog</title>
    <updated>2021-12-14T00:00:00.000Z</updated>
    <generator>https://github.com/jpmonette/feed</generator>
    <link rel="alternate" href="https://pulsar.apache.com/blog"/>
    <subtitle>Apache Pulsar Blog</subtitle>
    <icon>https://pulsar.apache.com/img/favicon.ico</icon>
    <entry>
        <title type="html"><![CDATA[What’s New in Apache Pulsar 2.7.4]]></title>
        <id>/2021/12/14/Apache-Pulsar-2-7-4</id>
        <link href="https://pulsar.apache.com/blog/2021/12/14/Apache-Pulsar-2-7-4"/>
        <updated>2021-12-14T00:00:00.000Z</updated>
        <summary type="html"><![CDATA[The Apache Pulsar community releases version 2.7.4! 32 contributors provided improvements and bug fixes that delivered 98 commits.]]></summary>
        <content type="html"><![CDATA[<p>The Apache Pulsar community releases version 2.7.4! 32 contributors provided improvements and bug fixes that delivered 98 commits.</p><p>Highlights of this release are as below:</p><ul><li><p>Upgrade Log4j to 2.17.0 - <a href="https://pulsar.apache.org/blog/2021/12/11/Log4j-CVE/">CVE-2021-45105</a>. <a href="https://github.com/apache/pulsar/pull/13392">PR-13392</a></p></li><li><p><code>ManagedLedger</code> can be referenced correctly when <code>OpAddEntry</code> is recycled. <a href="https://github.com/apache/pulsar/pull/12103">PR-12103</a></p></li><li><p>NPE does not occur on <code>OpAddEntry</code> while ManagedLedger is closing. <a href="https://github.com/apache/pulsar/pull/12364">PR-12364</a></p></li></ul><p>This blog walks through the most noteworthy changes grouped by the affected functionalities. For the complete list including all enhancements and bug fixes, check out the <a href="https://pulsar.apache.org/en/release-notes/#274">Pulsar 2.7.4 Release Notes</a>.</p><h1>Notable bug fixes and enhancements</h1><h3>Upgrade Log4j to 2.17.0 - <a href="https://pulsar.apache.org/blog/2021/12/11/Log4j-CVE/">CVE-2021-45105</a>. <a href="https://github.com/apache/pulsar/pull/13392">PR-13392</a></h3><ul><li><p><strong>Issue</strong></p><p>A serious vulnerability was reported regarding Log4j that can allow remote execution for attackers. The vulnerability issue is described and tracked under <a href="https://nvd.nist.gov/vuln/detail/CVE-2021-44228">CVE-2021-44228</a>.</p></li><li><p><strong>Resolution</strong></p><p>Pulsar 2.7.4 upgraded Log4j to 2.17.0.</p></li></ul><h3><code>ManagedLedger</code> can be referenced correctly when <code>OpAddEntry</code> is recycled. <a href="https://github.com/apache/pulsar/pull/12103">PR-12103</a></h3><ul><li><p><strong>Issue</strong></p><p>Previously, after a write failure, a task was scheduled in the background to force close the ledger and trigger the creation of  a new ledger. If the <code>OpAddEntry</code> instance was already recycled, that could lead to either an NPE or undefined behavior.</p></li><li><p><strong>Resolution</strong></p><p>The <code>ManagedLedgerImpl</code> object reference is copied to a final variable so the background task will not be dependent on the lifecycle of the <code>OpAddEntry</code> instance.</p></li></ul><h3>No potential race condition in the <code>BlobStoreBackedReadHandler</code>. <a href="https://github.com/apache/pulsar/pull/12123">PR-12123</a></h3><ul><li><p><strong>Issue</strong></p><p>Previously, <code>BlobStoreBackedReadHandler</code> entered an infinite loop when reading an offload ledger. There was a race condition between the operation of reading entries and closing BlobStoreBackedReadHandler.</p></li><li><p><strong>Resolution</strong></p><p>Added a state check before reading entries and made the <code>BlobStoreBackedReadHandler</code> exit loop when the <code>entryID</code> is bigger than the <code>lastEntryID</code>.</p></li></ul><h3>NPE does not occur on <code>OpAddEntry</code> while ManagedLedger is closing. <a href="https://github.com/apache/pulsar/pull/12364">PR-12364</a></h3><ul><li><p><strong>Issue</strong> </p><p>Previously, the test <code>ManagedLedgerBkTest#managedLedgerClosed</code> closed ManagedLedger object on some <code>asyncAddEntry</code> operations and failed with NPE.</p></li><li><p><strong>Resolution</strong></p><p>Closed <code>OpAddEntry</code>  when <code> ManagedLedger</code> signaled  <code>OpAddEntry</code> to fail. In this way, the <code>OpAddEntry</code> object was correctly recycled and the failed callback was correctly triggered.</p></li></ul><h3>Set a topic policy through the topic name of a partition correctly. <a href="https://github.com/apache/pulsar/pull/11294">PR-11294</a></h3><ul><li><p><strong>Issue</strong></p><p>Previously, the topic name of a partition could not be used to set a topic policy.</p></li><li><p><strong>Resolution</strong></p><p>Allowed setting a topic policy through a topic name of a partition by converting the topic name of a partition in <code>SystemTopicBasedTopicPoliciesService</code>.</p></li></ul><h3>Dispatch rate limiter takes effect for consumers. <a href="https://github.com/apache/pulsar/pull/8611">PR-8611</a></h3><ul><li><p><strong>Issue</strong></p><p>Previously, dispatch rate limiter did not take effect in cases where all consumers started reading in the next second since <code>acquiredPermits</code> was reset to 0 every second.</p></li><li><p><strong>Resolution</strong></p><p>Changed the behaviour of <code>DispatchRateLimiter</code> by minus <code>permits</code> every second instead of reset <code>acquiredPermits</code> to 0. Consumers stopped reading entries temporarily until <code>acquiredPermits</code> returned to a value less than <code>permits</code> .</p></li></ul><h3>NPE does not occur when executing unload bundles operations. <a href="https://github.com/apache/pulsar/pull/11310">PR-11310</a></h3><ul><li><p><strong>Issue</strong></p><p>When performing pressure tests on persistent partitioned topics, NPE occurred when executing unload bundles operations. Concurrently, producers did not write messages.</p></li><li><p><strong>Resolution</strong></p><p>Added more safety checks to fix this issue.</p></li></ul><h3>Fix inconsistent behavior for Namespace bundles cache. <a href="https://github.com/apache/pulsar/pull/11346">PR-11346</a></h3><ul><li><p><strong>Issue</strong></p><p>Previously, namespace bundle cache was not invalidated after a namespace was deleted.</p></li><li><p><strong>Resolution</strong></p><p>Invalidated namespace policy cache when bundle cache was invalidated.</p></li></ul><h3>Close the replicator and replication client after a cluster is deleted. <a href="https://github.com/apache/pulsar/pull/11342">PR-11342</a></h3><ul><li><p><strong>Issue</strong></p><p>Previously, the replicator and the replication client were not closed after a cluster was deleted. The producer of the replicator would then try to reconnect to the deleted cluster continuously.</p></li><li><p><strong>Resolution</strong></p><p>Closed the relative replicator and replication client.</p></li></ul><h3>Publish rate limiter takes effect as expected. <a href="https://github.com/apache/pulsar/pull/10384">PR-10384</a></h3><ul><li><p><strong>Issue</strong></p><p>Previously, there were various issues if <code>preciseTopicPublishRateLimiterEnable</code>  was set to <code>true</code> for rate limiting:</p><ul><li><p>Updating the limits did not set a boundary when changing the limits from a bounded limit to an unbounded limit.</p></li><li><p>Each topic created a scheduler thread for each limiter instance.</p></li><li><p>Topics did not release the scheduler thread when the topic was unloaded or the operation closed.</p></li><li><p>Updating the limits did not close the scheduler thread related to the replaced limiter instance</p></li></ul></li><li><p><strong>Resolution</strong></p><ul><li><p>Cleaned up the previous limiter instances before creating new limiter instances.</p></li><li><p>Used <code>brokerService.pulsar().getExecutor()</code> as the scheduler for the rate limiter instances.</p></li><li><p>Added resource cleanup hooks for topic closing (unload).</p></li></ul></li></ul><h3>Clean up newly created  ledgers if fails to update ZNode list. <a href="https://github.com/apache/pulsar/pull/12015">PR-12015</a></h3><ul><li><p><strong>Issue</strong></p><p>When updating a ZNode list, ZooKeeper threw an exception and did not clean up the created ledger. Newly created ledgers were not  indexed to a topic <code>managedLedger</code> list and could not be cleared up as topic retention. Also, ZNode numbers increased in ZooKeeper if the ZNode version mismatch exception was thrown out.</p></li><li><p><strong>Resolution</strong></p><p>Deleted the created ledger from broker cache and BookKeeper regardless of exception type when the ZNode list failed to update.</p></li></ul><h1>What’s Next?</h1><p>If you are interested in learning more about Pulsar 2.7.4, you can <a href="https://pulsar.apache.org/en/versions/">download</a> and try it out now! </p><p>Pulsar Summit Asia 2021 will take place on January 15-16, 2022. <a href="https://pulsar-summit.org/">Register now</a> and help us make it an even bigger success by spreading the word on social media!</p><p>For more information about the Apache Pulsar project and current  progress, visit
the <a href="https://pulsar.apache.org">Pulsar website</a>, follow the project on Twitter <a href="https://twitter.com/apache_pulsar">@apache_pulsar</a>, and join <a href="https://apache-pulsar.herokuapp.com/">Pulsar Slack</a>!</p>]]></content>
        <author>
            <name>Technoboy-, Anonymitaet</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Log4j2 Zero Day vulnerability (CVE-2021-44228)]]></title>
        <id>/2021/12/11/Log4j-CVE</id>
        <link href="https://pulsar.apache.com/blog/2021/12/11/Log4j-CVE"/>
        <updated>2021-12-11T00:00:00.000Z</updated>
        <summary type="html"><![CDATA[Yesterday, a new serious vulnerability was reported regarding Log4j that can]]></summary>
        <content type="html"><![CDATA[<p>Yesterday, a new serious vulnerability was reported regarding Log4j that can
allow remote execution for attackers.</p><p>The vulnerability issue is described and tracked under <a href="https://nvd.nist.gov/vuln/detail/CVE-2021-44228">CVE-2021-44228</a>.</p><p>Current releases of Apache Pulsar are bundling Log4j2 versions that are affected by this vulnerability.
Default configuration, combined with JVM version and other factors, can render it exploitable.
We strongly recommend to follow the advisory of the Apache Log4j community and patch your systems
as soon as possible, as well as looking for unexpected behavior in your Pulsar logs.</p><p>There are 2 workarounds to patch a Pulsar deployments. You can set either of:</p><ol><li>Java property: <code>-Dlog4j2.formatMsgNoLookups=true</code></li><li>Environment variable: <code>LOG4J_FORMAT_MSG_NO_LOOKUPS=true</code></li></ol><p>Both approaches are effective in mitigating the vulnerability for Pulsar
services.</p><p>Additionally, when running Pulsar Functions with Kubernetes runtime, you should update
your Docker images, following the example described <a href="https://github.com/lhotari/pulsar-docker-images-patch-CVE-2021-44228">here</a>.</p><p>If you are using the Pulsar Helm Chart for deploying in Kubernetes, a <a href="https://github.com/apache/pulsar-helm-chart/releases/tag/pulsar-2.7.6">new
version of the chart</a> is already available and it applies the above mentioned workaround.
If upgrading is not an option, you may also mitigate by adding <code>-Dlog4j2.formatMsgNoLookups=true</code> to the <code>PULSAR_EXTRA_OPTS</code> in the <code>configData</code> section for proxy, broker, bookkeeper, zookeeper, auto-recovery, and relative components in the helm values file.</p><p>We are already preparing new patch releases, 2.7.4, 2.8.2 and 2.9.1. These
releases will be ready in the next few days and will bundle the Log4j2 2.15.0,
which contains the vulnerability fix.</p>]]></content>
        <author>
            <name>Matteo Merli</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Apache Pulsar 2.8.1]]></title>
        <id>/2021/09/23/Apache-Pulsar-2-8-1</id>
        <link href="https://pulsar.apache.com/blog/2021/09/23/Apache-Pulsar-2-8-1"/>
        <updated>2021-09-23T00:00:00.000Z</updated>
        <summary type="html"><![CDATA[The Apache Pulsar community releases version 2.8.1! 49 contributors provided improvements and bug fixes that delivered 213 commits.]]></summary>
        <content type="html"><![CDATA[<p>The Apache Pulsar community releases version 2.8.1! 49 contributors provided improvements and bug fixes that delivered 213 commits.</p><p>Highlights of this release are as below:</p><ul><li><p>Key-shared subscriptions no longer stop dispatching to consumers when repeatedly opening and closing consumers. <a href="https://github.com/apache/pulsar/pull/10920">PR-10920</a></p></li><li><p>System topic no longer has potential data loss when not configured for compaction. <a href="https://github.com/apache/pulsar/pull/11003">PR-11003</a></p></li><li><p>Consumers are not allowed to read data on topics to which they are not subscribed. <a href="https://github.com/apache/pulsar/pull/11912">PR-11912</a></p></li></ul><p>This blog walks through the most noteworthy changes grouped by component. For the complete list including all features, enhancements, and bug fixes, check out the <a href="https://pulsar.apache.org/release-notes/#281-mdash-2021-09-10-a-id281a">Pulsar 2.8.1 Release Notes</a>.</p><h1>Notable bug fixes and enhancements</h1><h2>Broker</h2><h3>Precise publish rate limit takes effect as expected. <a href="https://github.com/apache/pulsar/pull/11446">PR-11446</a></h3><p><strong>Issue</strong>: Previously, when setting precise publish rate limits on topics, it did not work.</p><p><strong>Resolution</strong>: Implemented a new <code>RateLimiter</code> using the <code>LeakingBucket</code> and <code>FixedWindow</code> algorithms.</p><h3>Messages with the same keys are delivered to the correct consumers on Key-Shared subscriptions. <a href="https://github.com/apache/pulsar/pull/10762">PR-10762</a></h3><p><strong>Issue</strong>: Messages with the same keys were out of order when message redelivery occurred on a Key-Shared subscription.</p><p><strong>Resolution</strong>: When sending a message to <code>messagesToRedeliver</code>, the broker saved the hash value of the key. If the dispatcher attempted to send newer messages to the consumer that had a key corresponding to any one of the saved hash values, they were added to <code>messagesToRedeliver</code> instead of being sent. This prevented messages with the same key from being out of order.</p><h3>Active producers with the same name are no longer removed from the topic map. <a href="https://github.com/apache/pulsar/pull/11804">PR-11804</a></h3><p><strong>Issue</strong>: Previously, when there were producers with the same name, an error would be triggered and the old producer would be removed even though it was still writing to a topic.</p><p><strong>Resolution</strong>: Validated producers based on a connection ID (local &amp; remote addresses and unique ID) and a producer ID within that connection rather than a producer name.</p><h3>Topics in a fenced state can recover when producers continue to reconnect to brokers. <a href="https://github.com/apache/pulsar/pull/11737">PR-11737</a></h3><p><strong>Issue</strong>: Previously, when a producer continued to reconnect to a broker, the fenced state of the topic was always set to true, which caused the topic to be unable to recover.</p><p><strong>Resolution</strong>: Add an entry to <code>ManagedLedgerException</code> when the polled operation is not equal to the current operation.</p><h3>Topic properly initializes the cursor to prevent data loss. <a href="https://github.com/apache/pulsar/pull/11547">PR-11547</a></h3><p><strong>Issue</strong>: Previously, when subscribing to a topic with the earliest position, data would be lost because <code>ManagedLedger</code> used a wrong position to initialize a cursor.</p><p><strong>Resolution</strong>: Added a test to check a cursor&#x27;s position when subscribing to a topic with the earliest position.</p><h3>Deadlock no longer occurs when using <code>hasMessageAvailableAsync</code> and <code>readNextAsync</code>. <a href="https://github.com/apache/pulsar/pull/11183">PR-11183</a></h3><p><strong>Issue</strong>: Previously, when messages were added to an incoming queue, a deadlock might occur. The deadlock might happen in two possible scenarios. First, if the message was added to the queue before the message was read. Second, if <code>readNextAsync</code> was completed before <code>future.whenComplete</code> was called.</p><p><strong>Resolution</strong>: Used an internal thread to process the callback of <code>hasMessageAvailableAsync</code>.</p><h3>Memory leak does not occur when calling getLastMessageId API. <a href="https://github.com/apache/pulsar/pull/10977">PR-10977</a></h3><p><strong>Issue</strong>: Previously, the broker ran out of memory when calling the <code>getLastMessageId</code> API.</p><p><strong>Resolution</strong>: Added the <code>entry.release()</code> call to the <code>PersistentTopic.getLastMessageId</code>.</p><h3>Compaction is triggered for system topics. <a href="https://github.com/apache/pulsar/pull/10941">PR-10941</a></h3><p><strong>Issue</strong>: Previously, when a topic had only non-durable subscriptions, the compaction was not triggered because it had 0 estimated backlog size. </p><p><strong>Resolution</strong>: Used the total backlog size to trigger the compaction. Changed the behavior in the case of no durable subscriptions to use the total backlog size</p><h3>Key-shared subscriptions no longer stop dispatching to consumers when repeatedly opening and closing consumers. <a href="https://github.com/apache/pulsar/pull/10920">PR-10920</a></h3><p><strong>Issue</strong>: Repeatedly opening and closing consumers with a Key-Shared subscription might occasionally stop dispatching messages to all consumers.</p><p><strong>Resolution</strong>: Moved the mark-delete position and removed the consumer from the selector before calling <code>removeConsumer()</code>.</p><h3>Consumers are not allowed to read data on topics to which they are not subscribed. <a href="https://github.com/apache/pulsar/pull/11912">PR-11912</a></h3><p><strong>Issue</strong>: Previously, the request ledger was not checked whether it belonged to a consumer’s connected topic, which allowed the consumer to read data that does not belong to the connected topic.</p><p><strong>Resolution</strong>: Added a check on the <code>ManagedLedger</code> level before executing read operations. </p><h2>Topic Policy</h2><h3>Retention policy works as expected. <a href="https://github.com/apache/pulsar/pull/11021">PR-11021</a></h3><p><strong>Issue</strong>: Previously, the retention policy did not work because it was not set in the <code>managedLedger</code> configuration.</p><p><strong>Resolution</strong>: Set the retention policy in the <code>managedLedger</code> configuration to the <code>onUpdate</code> listener method.</p><h3>System topic no longer has potential data loss when not configured for compaction. <a href="https://github.com/apache/pulsar/pull/11003">PR-11003</a></h3><p><strong>Issue</strong>: Previously, data might be lost if there were no durable subscriptions on topics.</p><p><strong>Resolution</strong>: Leveraged the topic compaction cursor to retain data.</p><h2>Proxy</h2><h3>Pulsar proxy correctly shuts down outbound connections. <a href="https://github.com/apache/pulsar/pull/11848">PR-11848</a></h3><p><strong>Issue</strong>: Previously, there was a memory leak of outgoing TCP connections in the Pulsar proxy because the <code>ProxyConnectionPool</code> instances were created outside the <code>PulsarClientImpl</code> instance and not closed when the client was closed.</p><p><strong>Resolution</strong>: Shut down the <code>ConnectionPool</code> correctly.</p><h2>Function</h2><h3>Pulsar Functions support Protobuf schema. <a href="https://github.com/apache/pulsar/pull/11709">PR-11709</a></h3><p><strong>Issue</strong>: Previously, the exception <code>GeneratedMessageV3 is not assignable</code> was thrown when using a Protobuf schema.</p><p><strong>Resolution</strong>: Added the relevant dependencies to the Pulsar instance.</p><h2>Client</h2><h3>Partitioned-topic consumers clean up resources after a failure. <a href="https://github.com/apache/pulsar/pull/11754">PR-11754</a></h3><p><strong>Issue</strong>: Previously, partitioned-topic consumers did not clean up the resources when failing to create consumers. If this failure occurred with non-recoverable errors, it triggered a memory leak, which made applications unstable.</p><p><strong>Resolution</strong>: Closed and cleaned timer task references.</p><h3>Race conditions do not occur on multi-topic consumers. <a href="https://github.com/apache/pulsar/pull/11764">PR-11764</a></h3><p><strong>Issue</strong>: Previously, there was a race condition between 2 threads when one of the individual consumers was in a &quot;paused&quot; state and the shared queue was full. </p><p><strong>Resolution</strong>: Validated the state of the shared queue after marking the consumer as &quot;paused&quot;. The consumer is not blocked if the other thread has emptied the queue in the meantime. </p><h3>Consumers are not blocked on <code>batchReceive</code>. <a href="https://github.com/apache/pulsar/pull/11691">PR-11691</a></h3><p><strong>Issue</strong>: Previously, consumers were blocked when <code>Consumer.batchReceive()</code> was called concurrently by different threads due to a race condition in <code>ConsumerBase.java</code>.</p><p><strong>Resolution</strong>: Put <code>pinnedInternalExecutor</code> in <code>ConsumerBase</code> to allow batch timer, <code>ConsumerImpl</code>, and <code>MultiTopicsConsumerImpl</code> to submit work in a single thread.</p><h3>Python client correctly enables custom logging. <a href="https://github.com/apache/pulsar/pull/11882">PR-11882</a></h3><p><strong>Issue</strong>: Previously, deadlock might happen when custom logging was enabled in the Python client.</p><p><strong>Resolution</strong>: Detached the worker thread and reduced log level.</p><h1>What is Next?</h1><p>If you are interested in learning more about Pulsar 2.8.1, you can <a href="https://pulsar.apache.org/en/download/">download</a> and try it out now! </p><p>The first-ever Pulsar Virtual Summit Europe 2021 will take place in October. <a href="https://hopin.com/events/pulsar-summit-europe-2021">Register now</a> and help us make it an even bigger success by spreading the word on social media!</p><p>For more information about the Apache Pulsar project and the progress, visit
the <a href="https://pulsar.apache.org">Pulsar website</a>, follow the project on Twitter <a href="https://twitter.com/apache_pulsar">@apache_pulsar</a>, and join <a href="https://apache-pulsar.herokuapp.com/">Pulsar Slack</a>!</p>]]></content>
        <author>
            <name>Hang Chen, Anonymitaet</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Announcing Pulsar Summit Asia 2021: CFP Is Open!]]></title>
        <id>/2021/08/18/asia-cfp</id>
        <link href="https://pulsar.apache.com/blog/2021/08/18/asia-cfp"/>
        <updated>2021-08-18T00:00:00.000Z</updated>
        <summary type="html"><![CDATA[We’re proud to announce the Pulsar Summit Asia 2021!]]></summary>
        <content type="html"><![CDATA[<p>We’re proud to announce the Pulsar Summit Asia 2021!</p><p>2021 has been a remarkable year for the Apache Pulsar community. <a href="https://streamnative.io/en/blog/community/2021-06-14-pulsar-hits-its-400th-contributor-and-passes-kafka-in-monthly-active-contributors">Both the technology and community are growing rapidly this year</a>, and <a href="https://www.na2021.pulsar-summit.org">Pulsar Virtual Summit North America 2021</a> was a big success with 33 break-out sessions and more than 550 registrations.</p><p>Last year, <a href="https://pulsar-summit.org/en/event/asia-2020">Pulsar Summit Asia</a> featured more than 40 interactive sessions by tech leads, open-source developers, software engineers, and software architects from Tencent Group, BIGO, Kingsoft Cloud, Splunk, Yahoo! JAPAN, Nutanix, Dada Group, TIBCO, Huawei Cloud, and more. The conference garnered nearly 1,000 attendees around the globe mostly from Asia, including attendees from top tech, fintech and media companies.</p><p>Cumulatively, the Pulsar Summits drew more than 100 speakers, thousands of attendees, and hundreds of companies from diverse industries. It is a unique opportunity to network and learn about Pulsar project updates, ecosystem developments, best practices, and adoption stories.</p><p><strong>This year, the Pulsar Summit Asia will be hosted on November 20-21, 2021 by StreamNative. You can join us offline in Beijing for one day of Pulsar Training and one day of keynotes and breakout sessions. All the talks will be streamed live online.</strong></p><h1>CFP Details</h1><p>Join us and speak at the Pulsar Summit Asia 2021!
We are looking for Pulsar stories that are innovative, informative, or thought-provoking. Here are some suggestions:</p><ul><li>Your Pulsar use case / success story</li><li>A technical deep dive</li><li>Pulsar best practices</li><li>Pulsar ecosystem updates</li></ul><p>To speak at the summit, please <a href="https://sessionize.com/pulsar-summit-asia-2021/">submit an abstract</a> about your presentation. Remember to keep your proposal short, relevant and engaging.</p><h1>First-time Speakers Welcomed!</h1><p>First time submitting? Don&#x27;t feel intimidated. We strongly encourage first-time speakers to submit talks for the Pulsar Summit Asia 2021. If your submission is similar to a previous talk in the past Pulsar Summits, please include information on how this version will be different. We hope to see some exciting updates on the topic.</p><p>We welcome submissions from around the globe. Our hybrid conference model has taken time differences into consideration. After your talk is accepted, we will schedule the sessions and send you the presentation options. </p><h1>Speaker Benefits</h1><p>As a speaker, you will receive: </p><ul><li>The chance to demonstrate your experience and deep knowledge in the rapidly growing event streaming space.</li><li>Your name, title, company, and bio will be featured on the Pulsar Summit Asia 2021 website.</li><li>Your session will be added to the Pulsar Summit YouTube Channel and promoted on Twitter,  LinkedIn, and WeChat.</li><li>A professionally produced video of your presentation.
Exclusive Pulsar swag only available to the speakers.</li></ul><h1>Important Dates</h1><ul><li>CFP opens: August 18th, 2021 </li><li>CFP closes: September 8th, 2021 </li><li>Speaker notifications: September 22th, 2021</li><li>Schedule announcement: October 13th, 2021 </li></ul><p>Submissions are open until September 8th. If you want some advice or feedback on your proposal, or have any questions about the summit, please do not hesitate to contact us at <a href="mailto:organizers@pulsar-summit.org.">organizers@pulsar-summit.org.</a> We are happy to help!</p><h1>Sponsor Pulsar Summit Asia</h1><p>Pulsar Summit is a conference for the community and sponsorship is needed. Sponsoring this event provides a great opportunity for your organization to further engage with the Apache Pulsar community. Contact us at <a href="mailto:organizers@pulsar-summit.org">organizers@pulsar-summit.org</a> to learn more.</p><p>Help us make Pulsar Summit Asia 2021 a big success by spreading the word and submitting your proposal! Follow Pulsar Summit on <a href="https://twitter.com/PulsarSummit">Twitter</a> to receive the latest updates of the conference.</p>]]></content>
        <author>
            <name>Dianjin</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Apache Pulsar 2.7.3]]></title>
        <id>/2021/08/11/Apache-Pulsar-2-7-3</id>
        <link href="https://pulsar.apache.com/blog/2021/08/11/Apache-Pulsar-2-7-3"/>
        <updated>2021-08-11T00:00:00.000Z</updated>
        <summary type="html"><![CDATA[The Apache Pulsar community releases version 2.7.3! 34 contributors provided improvements and bug fixes that delivered 79 commits.]]></summary>
        <content type="html"><![CDATA[<p>The Apache Pulsar community releases version 2.7.3! 34 contributors provided improvements and bug fixes that delivered 79 commits.</p><h2>Highlights</h2><ul><li><p>Cursor reads adhere to the dispatch byte rate limiter setting and no longer cause unexpected results. <a href="https://github.com/apache/pulsar/pull/11249">PR-11249</a></p></li><li><p>The ledger rollover scheduled task runs as expected. <a href="https://github.com/apache/pulsar/pull/11226">PR-11226</a></p></li></ul><p>This blog walks through the most noteworthy changes. For the complete list including all enhancements and bug fixes, check out the <a href="https://pulsar.apache.org/release-notes/#273-mdash-2021-07-27-a-id273a">Pulsar 2.7.3 Release Notes</a>.</p><h1>Notable bug fixes and enhancements</h1><h2>Broker</h2><h3>Cursor reads adhere to the dispatch byte rate limiter setting. <a href="https://github.com/apache/pulsar/pull/9826">PR-9826</a></h3><ul><li><p><strong>Issue</strong>: When using byte rates, the dispatch rates were not respected (regardless
of being a namespace or topic policy). </p></li><li><p><strong>Resolution</strong>: Fixed behavior of dispatch byte rate limiter setting. Cursor reads adhere to the setting and no longer cause unexpected results. </p></li></ul><h3>The ledger rollover scheduled task runs as expected. <a href="https://github.com/apache/pulsar/pull/11226">PR-11226</a></h3><ul><li><p><strong>Issue</strong>: Previously, the ledger rollover scheduled task was executed before reaching the ledger maximum rollover time, which caused the ledger not to roll over in time. </p></li><li><p><strong>Resolution</strong>: Fixed the timing of the ledger rollover schedule, so the task runs only after the ledger is created successfully. </p></li></ul><h3>The topic-level retention policy works correctly when restarting a broker. <a href="https://github.com/apache/pulsar/pull/11136">PR-11136</a></h3><ul><li><p><strong>Issue</strong>: Previously, when setting a topic-level retention policy for a topic and then restarting the broker, the topic-level retention policy did not work.</p></li><li><p><strong>Resolution</strong>: Fixed behavior of the policy so it replays all policy messages after initiating <code>policyCacheInitMap</code> and added a retention policy check test when restarting the broker.</p></li></ul><h3>The lastMessageId API call no longer causes a memory leak. <a href="https://github.com/apache/pulsar/pull/10977">PR-10977</a></h3><ul><li><p><strong>Issue</strong>: Previously, there was a memory leak when calling the <code>lastMessageId</code> API, which caused the broker process to be stopped by Kubernetes. </p></li><li><p><strong>Resolution</strong>: Added the missing entry.release() call to PersistentTopic.getLastMessageId to ensure the broker does not run out of memory. </p></li></ul><h3>ZooKeeper reads are cached by brokers. <a href="https://github.com/apache/pulsar/pull/10594">PR-10594</a></h3><ul><li><p><strong>Issue</strong>: When performing the admin operation to get the namespace of a tenant, ZooKeeper reads were issued on the ZooKeeper client and not getting cached by the brokers.</p></li><li><p><strong>Resolution</strong>: Fixed ZooKeeper caching when fetching a list of namespaces for a tenant.</p></li></ul><h3>Monitoring threads that call <code>LeaderService.isLeader()</code> are no longer blocked. <a href="https://github.com/apache/pulsar/pull/10512">PR-10512</a></h3><ul><li><strong>Issue</strong>:  When <code>LeaderService</code> changed leadership status, it was locked with a <code>synchronized</code> block, which also blocked other threads calling <code>LeaderService.isLeader()</code>. </li><li><strong>Resolution</strong>: Fixed the deadlock condition on the monitoring thread so it is not blocked by <code>LeaderService.isLeader() by modifying </code>ClusterServiceCoordinator<code>and</code>WorkerStatsManager<code>to check if it is a leader from</code>MembershipManager`. </li></ul><h3><code>hasMessageAvailable</code> can read messages successfully. <a href="https://github.com/apache/pulsar/pull/10414">PR-10414</a></h3><ul><li><p><strong>Issue</strong>: When <code>hasMessageAvailableAsync</code> returned <code>true</code>, it could not read messages because messages were filtered by <code>acknowledgmentsGroupingTracker</code>. </p></li><li><p><strong>Resolution</strong>: Fixed the race conditions by modifying <code>acknowledgmentsGroupingTracker</code> to filter duplicate messages, and then cleanup the messages when the connection is open.</p></li></ul><h2>Proxy</h2><h3>Proxy supports creating partitioned topics automatically. <a href="https://github.com/apache/pulsar/pull/8048">PR-8048</a></h3><ul><li><p><strong>Issue</strong>: Proxies were not creating partitions because they were using the current ZooKeeper metadata.</p></li><li><p><strong>Resolution</strong>: Changed the proxy to handle <code>PartitionMetadataRequest</code> by selecting and fetching from an available broker instead of using current ZooKeeper metadata.</p></li></ul><h2>Pulsar admin</h2><h3>Flag added to indicate whether or not to create a metadata path on replicated clusters. <a href="https://github.com/apache/pulsar/pull/11140">PR-11140</a></h3><ul><li><p><strong>Issue</strong>: When creating a partitioned topic in a replicated namespace, it did not
create a metadata path <code>/managed-ledgers</code> on replicated clusters.</p></li><li><p><strong>Resolution</strong>: Added a flag (createLocalTopicOnly) to indicate whether or not to create a metadata path for a partitioned topic in replicated clusters.</p></li></ul><h3>A topic policy can no longer be set for a non-existent topic. <a href="https://github.com/apache/pulsar/pull/11131">PR-11131</a></h3><ul><li><p><strong>Issue</strong>: Due to a redirect loop in a topic policy, you can set a policy for a non-existing topic or a partition of a partitioned topic. </p></li><li><p><strong>Resolution</strong>: The fix added an authoritative flag for a topic policy to avoid a redirect loop. You can not set a topic policy for a non-existent topic or a partition of a partitioned topic. If you set a topic policy for a partition of a 0-partition topic, it redirects to the broker. </p></li></ul><h3>Discovery service no longer hard codes the topic domain as persistent. <a href="https://github.com/apache/pulsar/pull/10806">PR-10806</a></h3><ul><li><p><strong>Issue</strong>: When using the lookup discovery service for a partitioned non-persistent topic, it returned zero rather than the number of partitions. The Pulsar client tried to connect to the topic as if it were a normal topic.</p></li><li><p><strong>Resolution</strong>: Implemented <code>topicName.getDomain().value()</code> rather than hard coding <code>persistent.</code> Now you can use the discovery service for a partitioned, non-persistent topic successfully.</p></li></ul><h3>Other connectors can now use the Kinesis <code>Backoff</code> class. <a href="https://github.com/apache/pulsar/pull/10744">PR-10744</a></h3><ul><li><p><strong>Issue</strong>: The Kinesis sink connector <code>Backoff</code> class in the Pulsar client implementation project in combination  with the dependency <code>org.apache.pulsar:pulsar-client-original</code> increased the connector size. </p></li><li><p><strong>Resolution</strong>: Added a new class <code>Backoff</code> in the function io-core project so that the Kinesis sink connector and other connectors can use the class.</p></li></ul><h2>Client</h2><h3>A <code>FLOW</code> request with zero permits can not be sent. <a href="https://github.com/apache/pulsar/pull/10506">PR-10506</a></h3><ul><li><strong>Issue</strong>: When a broker received a <code>FLOW</code> request with zero permits, an exception was thrown and then the connection was closed. This triggered frequent reconnections and caused duplicate or out-of-order messages. </li><li><strong>Resolution</strong>: Added a validation that verifies the permits of a <code>FLOW</code> request before sending it. If the permit is zero, the <code>FLOW</code> request can not be sent.</li></ul><h2>Function and connector</h2><h3>The Kinesis sink connector acknowledges successful messages. <a href="https://github.com/apache/pulsar/pull/10769">PR-10769</a></h3><ul><li><strong>Issue</strong>: The Kinesis sink connector did not acknowledge messages after they were sent successfully. </li><li><strong>Resolution</strong>: Added acknowledgement for the Kinesis sink connector once a message is sent successfully. </li></ul><h2>Docker</h2><h3>Function name length cannot exceed 52 characters when using Kubernetes runtime. <a href="https://github.com/apache/pulsar/pull/10531">PR-10531</a></h3><ul><li><strong>Issue</strong>: When using Kubernetes runtime, if a function was submitted with a valid length (less than 55 characters), a StatefulSet was created but it was unable to spawn pods. </li><li><strong>Resolution</strong>: Changed the maximum length of a function name from 55 to 53 characters for Kubernetes runtime. With this fix, the length of a function name can not exceed 52 characters. </li></ul><h2>Dependency</h2><h3><code>pulsar-admin</code> connection to proxy is stable when TLS is enabled. <a href="https://github.com/apache/pulsar/pull/10907">PR-10907</a></h3><ul><li><strong>Issue</strong>: <code>pulsar-admin</code> was unstable over the TLS connection because of the Jetty bug in SSL buffering introduced in Jetty 9.4.39. It caused large function jar uploads to fail frequently.</li><li><strong>Resolution</strong>: Upgraded Jetty to 9.4.42.v20210604, so that <code>pulsar-admin</code> connection to proxy is stable when TLS is enabled.</li></ul><h1>What is Next?</h1><p>If you are interested in learning more about Pulsar 2.7.3, you can <a href="https://pulsar.apache.org/en/versions/">download 2.7.3</a> and try it out now! </p><p>The first-ever Pulsar Virtual Summit Europe 2021 will take place in October. <a href="https://hopin.com/events/pulsar-summit-europe-2021">Register now</a> and help us make it an even bigger success by spreading the word on social!</p><p>For more information about the Apache Pulsar project and the progress, visit
the <a href="https://pulsar.apache.org">Pulsar website</a>, follow the project on Twitter <a href="https://twitter.com/apache_pulsar">@apache_pulsar</a>, and join <a href="https://apache-pulsar.herokuapp.com/">Pulsar Slack</a>!</p>]]></content>
        <author>
            <name>Bo Cong, Anonymitaet</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Apache Pulsar 2.8.0]]></title>
        <id>/2021/06/12/Apache-Pulsar-2-8-0</id>
        <link href="https://pulsar.apache.com/blog/2021/06/12/Apache-Pulsar-2-8-0"/>
        <updated>2021-06-12T00:00:00.000Z</updated>
        <summary type="html"><![CDATA[We are very glad to see the Apache Pulsar community has successfully released the 2.8.0 version, which includes a number of exciting upgrades and enhancements. This blog provides a deep dive into the updates from the 2.8.0 release as well as a detailed look at the major Pulsar developments that have helped it evolve into the unified messaging and streaming platform it is today.]]></summary>
        <content type="html"><![CDATA[<p>We are very glad to see the Apache Pulsar community has successfully released the 2.8.0 version, which includes a number of exciting upgrades and enhancements. This blog provides a deep dive into the updates from the 2.8.0 release as well as a detailed look at the major Pulsar developments that have helped it evolve into the unified messaging and streaming platform it is today.</p><p>Note: The Pulsar community typically releases a major release every 3 months, but it has been 6 months since the release of 2.7.0. We spent more time on 2.8.0 in order to make the transaction API generally available to the Pulsar community. </p><h1>Release 2.8 Overview</h1><p>The key features and updates in this release are:</p><ul><li>Exclusive Producer</li><li>Package Management API</li><li>Simplified Client Memory Limit Settings</li><li>Broker Entry Metadata</li><li>New Protobuf Code Generator</li><li>Transactions</li></ul><h2>Exclusive Producer</h2><p>By default, the Pulsar producer API provides a “multi-writer” semantic to append messages to a topic. However, there are several use cases that require exclusive access for a single writer, such as ensuring a linear non-interleaved history of messages or providing a mechanism for leader election.</p><p>This new feature allows applications to require exclusive producer access in order to achieve a “single-writer” situation. It guarantees that there should be 1 single writer in any combination of errors. If the producer loses its exclusive access, no more messages from it can be published on the topic.</p><p>One use case for this feature is the metadata controller in Pulsar Functions. In order to write a single linear history of all the functions metadata updates, the metadata controller requires to elect one leader and that all the “decisions” made by this leader be written on the metadata topic. By leveraging the exclusive producer feature, Pulsar guarantees that the metadata topic contains different segments of updates, one per each successive leader, and there is no interleaving across different leaders. See “<a href="https://github.com/apache/pulsar/wiki/PIP-68%3A-Exclusive-Producer">PIP-68: Exclusive Producer</a>” for more details.</p><h2>Package Management API</h2><p>Since its introduction in version 2.0, the Functions API has become hugely popular among Pulsar users. While it offers many benefits, there are a number of ways to improve the user experience. For example, today, if a function is deployed multiple times, the function package ends up being uploaded multiple times. Also, there is no version management in Pulsar for Functions and IO connectors. The newly introduced package management API provides an easier way to manage the packages for Functions and IO connectors and significantly simplifies the upgrade and rollback processes. Read “<a href="http://pulsar.apache.org/docs/en/admin-api-packages/">Package Management API</a>” for more details.</p><h2>Simplified Client Memory Limit Settings</h2><p>Prior to 2.8, there are multiple settings in producers and consumers that allow controlling the sizes of the internal message queues. These settings ultimately control the amount of memory the Pulsar client uses. However, there are few issues with this approach that make it complicated to select an overall configuration that controls the total usage of memory. </p><p>For example, the settings are based on the “number of messages”, so the expected message size must be adjusted per producer or consumer. If an application has a large (or unknown) number of producers or consumers, it’s very difficult to select an appropriate value for queue sizes. The same is true for topics that have many partitions.</p><p>In 2.8, we introduced a new API to set the memory limit. This single <code>memoryLimit</code> setting specifies a maximum amount of memory on a given Pulsar client. The producers and consumers compete for the memory assigned. It ensures the memory used by the Pulsar client will not go beyond the set limit. Read “<a href="https://github.com/apache/pulsar/wiki/PIP-74%3A-Pulsar-client-memory-limits">PIP-74: Pulsar client memory limits</a>” for more details.</p><h2>Broker Entry Metadata</h2><p>Pulsar messages define a very comprehensive set of metadata properties. However, to add a new property, the <code>MessageMetadata</code> definition in Pulsar protocol must change to inform both broker and client of the newly introduced property. </p><p>But in certain cases, this metadata property might need to be added from the broker side, or need to be retrieved by the broker at a very low cost. To prevent deserializing these properties from the message metadata, we introduced “Broker Entry Metadata” in 2.8.0 to provide a lightweight approach to add additional metadata properties without serializing and deserializing the protobuf-encoded <code>MessageMetadata</code>. </p><p>This feature unblocks a new set of capabilities for Pulsar. For example, we can leverage broker entry metadata to generate broker publish time for the messages appended to the Pulsar topic. The other example is to generate a monotonically increasing sequence-id for messages produced to a Pulsar topic. We use this feature in Kafka-on-Pulsar to implement Kafka offset.</p><h2>New Protobuf Code Generator</h2><p>Pulsar uses Google Protobuf in order to perform serialization and deserialization of the commands that are exchanged between clients and brokers. Because of the overhead involved with the regular Protobuf implementation, we have been using a modified version of Protobuf 2.4.1. The modifications were done to ensure a more efficient serialization code that used thread local cache for the objects used in the process.</p><p>This approach introduced a few issues. For example, the patch to the Protobuf code generator is only based on Protobuf version 2.4.1 and cannot be upgraded to the newer Protobuf versions. In 2.8, we switched the patched Protobuf 2.4.1 to Splunk LightProto as the code generator. The new code generator generates the fastest possible Java code for Protobuf SerDe, is 100% compatible with proto2 definition and wire protocol, and provides zero-copy deserialization using Netty ByteBuf.</p><h2>Transactions</h2><p>Prior to Pulsar 2.8, Pulsar only supported exactly-once semantics on single topic through Idempotent Producer. While powerful, Idempotent producer only solves a narrow scope of challenges for exactly-once semantics. For example, there is no <code>atomicity</code> when a producer attempts to produce messages to multiple topics. A publish error can occur when the broker serving one of the topics crashes. If the producer doesn’t retry publishing the message again, it results in some messages being persisted once and others being lost. If the producer retries, it results in some messages being persisted multiple times.</p><p>In order to address the remaining challenges described above, we’ve strengthened the Pulsar’s delivery semantics by introducing a Pulsar Transaction API to support atomic writes and acknowledgements across multiple topics. The addition of the Transaction API to Apache Pulsar completes our vision of making Pulsar a complete unified messaging and streaming platform.</p><p>Pulsar PMC member, Penghui Li, goes over this functionality in great detail in his recent blog, Exactly-once Semantics with Transactions in Pulsar. You can read it to learn more about the <a href="https://streamnative.io/en/blog/release/2021-06-14-exactly-once-semantics-with-transactions-in-pulsar">exactly-once semantics support in Pulsar</a>.</p><h1>Building a Unified Messaging and Streaming Platform with Apache Pulsar</h1><h2>The Evolution of Apache Pulsar</h2><p>Apache Pulsar is widely adopted by hundreds of companies across the globe, including Splunk, Tencent, Verizon, and Yahoo! JAPAN, just to name a few. Born as a cloud-native distributed messaging system, Apache Pulsar has evolved into a complete messaging and streaming platform for publishing and subscribing, storing, and processing streams of data at scale and in real-time. </p><p>Back in 2012 the Yahoo! team was looking for a global, geo-replicated infrastructure that could manage all of Yahoo!’s messaging data. After vetting the messaging and streaming landscape it became clear that existing technologies were not able to serve the need for an event-driven organization. As a result, the team at Yahoo! set out to build its own.</p><p>At the time, there were generally two types of systems to handle in-motion data: message queues that handled mission-critical business events in real-time, and streaming systems that handled scalable data pipelines at scale. Companies had to limit their capabilities to one or the other, or they had to adopt multiple different technologies. If they chose multiple technologies, they would end up with a complex infrastructure that often resulted in data segregation and data silos, with one silo for message queues used to build application services and the other silo for streaming systems used to build data services. The figure below illustrates what this can look like. </p><p><img src="/img/280-1.png"/></p><p>However, with the diversity of data that companies need to process beyond operational data (like log data, click events, etc), coupled with the increase in the number of downstream systems that need access to combined business data and operational data, the system would need to support message queueing and streaming. </p><p>Beyond that, companies need an infrastructure platform that would allow them to build all of their applications on top of it, and then have those applications handle in-motion data (messaging and streaming data) by default. This way real-time data infrastructure could be significantly simplified, as illustrated in the diagram below.</p><p><img src="/img/280-2.png"/></p><p>With that vision, the Yahoo! team started working on building a unified messaging and streaming platform for in-motion data. Below is an overview of the key milestones on the Pulsar journey, from inception to today.</p><h2>Step 1: A scalable storage for streams of data</h2><p>The journey of Pulsar began with Apache BookKeeper. Apache BookKeeper implements a log-like abstraction for continuous streams and provides the ability to run it at internet-scale with simple write-read log APIs. A log provides a great abstraction for building distributed systems, such as distributed databases and pub-sub messaging. The write APIs are in the form of appends to the log. And the read APIs are in the form of continuous read from a starting offset defined by the readers. The implementation of BookKeeper created the foundation - a scalable log-backed messaging and streaming system. </p><h2>Step 2: A multi-layered architecture that separates compute from storage.</h2><p>On top of the scalable log storage, a stateless serving layer was introduced which runs stateless brokers for publishing and consuming messages. This multi-layered architecture separates serving/compute from storage, allowing Pulsar to manage serving and storage in separate layers.</p><p>This architecture also ensures instant scalability and higher availability. Both of these factors are extremely important and make Pulsar well-suited for building mission-critical services, such as billing platforms for financial use cases, transaction processing systems for e-commerce and retailers, and real-time risk control systems for financial institutions.</p><h2>Step 3: Unified messaging model and API</h2><p>In a modern data architecture, the real-time use cases can typically be categorized into two categories: queueing and streaming. Queueing is typically used for building core business application services while streaming is typically used for building real-time data services such as data pipelines.</p><p>To provide one platform able to serve both application and data services required a unified messaging model that integrates queuing and streaming semantics. The Pulsar topics become the source of truth for consumption. Messages can be stored only once on topics, but can be consumed in different ways via different subscriptions. Such unification significantly reduces the complexity of managing and developing messaging and streaming applications.</p><h2>Step 4: Schema API</h2><p>Next, a new Pulsar schema registry and a new type-safe producer &amp; consumer API were added. The built-in schema registry enables message producers and consumers on Pulsar topics to coordinate on the structure of the topic’s data through the Pulsar broker itself, without needing an external coordination mechanism. With data schemas, every single piece of data traveling through Pulsar is completely discoverable, enabling you to build systems that can easily adapt as the data changes.</p><p>Furthermore, the schema registry keeps track of data compatibility between versions of the schema. As the new schemas are uploaded the registry ensures that new schema versions are able to be read by old consumers. This ensures that Producers cannot break Consumers.</p><h2>Step 5: Functions and IO API</h2><p>The next step was to build APIs that made it easy to get data in and out of Pulsar and process it. The goal was to make it easy to build event-driven applications and real-time data pipelines with Apache Pulsar, so you can then process those events when they arrive, no matter where they originated from. </p><p>The Pulsar IO API allows you to build real-time streaming data pipelines by plugging various source connectors to get data from external systems into Pulsar and sink connectors to get data from Pulsar into external systems. Today, Pulsar provides several built-in connectors that you can use. </p><p>Additionally, StreamNative Hub (a registry of Pulsar connectors) provides dozens of connectors integrated with popular data systems. If the IO API is for building streaming data pipelines, the Functions API is for building event-driven applications and real-time stream processors. </p><p>The serverless function concepts were adopted into stream processing and then built the Functions API as a lightweight serverless library that you can write any event processing logic using any language you like. The underlying motivation was to enable your engineering team to write stream processing logic without the operational complexity of running and maintaining yet another cluster.</p><h2>Step 6: Infinite storage for Pulsar via Tiered Storage</h2><p>As adoption of Apache Pulsar continued and the amount of data stored in Pulsar increased, users eventually hit a “retention cliff”, at which point it became significantly more expensive to store, manage, and retrieve data in Apache BookKeeper. To work around this, operators and application developers typically use an external store like AWS S3 as a sink for long-term storage. This means you lose most of the benefits of Pulsar’s immutable stream and ordering semantics, and instead end up having to manage two different systems with different access patterns.</p><p>The introduction of Tiered Storage allows Pulsar to offload the majority of the data to a remote cloud-native storage. This cheaper form of storage readily scales with the volume of data. More importantly, with the addition of Tiered Storage, Pulsar provides the batch storage capabilities needed to support batch processing when integrating with a unified batch and stream processor like Flink. The unified batch and stream processing capabilities integrated with Pulsar enable companies to query real-time streams with historical context quickly and easily, unlocking a unique competitive advantage.</p><h2>Step 7: Protocol Handler</h2><p>After introducing tiered storage, Pulsar evolved from a Pub/Sub messaging system into a scalable stream data system that can ingest, store, and process streams of data. However, existing applications written using other messaging protocols such as Kafka, AMQP, MQTT, etc had to be rewritten to adopt Pulsar’s messaging protocol.</p><p>The Protocol Handler API  further reduces the overhead of adopting Pulsar for building messaging and streaming applications, and allows developers to extend Pulsar capabilities to other messaging domains by leveraging all the benefits provided by Pulsar architecture. This resulted in major collaborations between Pulsar and other industry leaders to develop popular protocol handlers including:</p><ul><li><a href="https://hub.streamnative.io/protocol-handlers/kop/0.2.0">Kafka-on-Pulsar (KoP)</a>, which was <a href="https://streamnative.io/en/blog/tech/2020-03-24-bring-native-kafka-protocol-support-to-apache-pulsar">launched in March 2020</a> by OVHCloud and StreamNative. </li><li><a href="https://hub.streamnative.io/protocol-handlers/aop/0.1.0">AMQP-on-Pulsar (AoP)</a>, which was <a href="https://streamnative.io/en/blog/tech/2020-06-15-announcing-aop-on-pulsar">announced in June 2020</a> by China Mobile and StreamNative.</li><li><a href="https://hub.streamnative.io/protocol-handlers/mop/0.2.0">MQTT-on-Pulsar (MoP)</a>, which was <a href="https://streamnative.io/en/blog/tech/2020-09-28-announcing-mqtt-on-pulsar">announced in August 2020</a> by StreamNative.</li><li><a href="https://github.com/streamnative/rop">RocketMQ-on-Pulsar (RoP)</a>, which was launched in May 2021 by Tencent Cloud and StreamNative.</li></ul><h2>Step 8: Transaction API for exactly-once stream processing</h2><p>More recently, transactions were added to Apache Pulsar to enable exactly-once semantics for stream processing. This is a fundamental feature that provides a strong guarantee for streaming data transformations, making it easy to build scalable, fault-tolerant, stateful messaging and streaming applications that process streams of data.</p><p>Furthermore, the transaction API capabilities are not limited to a given language client. Pulsar’s support for transactional messaging and streaming is primarily a protocol-level capability that can be presented in any language. Such protocol-level capability can be leveraged in all kinds of applications. </p><h1>Building an ecosystem for unified messaging and streaming</h1><p>In addition to contributing to the Pulsar technology, the community is also working to build a robust ecosystem to support it. Pulsar’s ability to support a rich ecosystem of pub-sub libraries, connectors, functions, protocol handlers, and integrations with popular query engines will enable Pulsar adopters to streamline workflows and achieve new use cases.</p><h1>What is Next?</h1><p>If you are interested in learning more about Pulsar 2.8.0, you can <a href="https://pulsar.apache.org/en/versions/">download 2.8.0</a> and try it out today! </p><p>If you want to learn more about how companies have adopted Pulsar, you can <a href="https://hopin.com/events/pulsar-summit-north-america-2021">sign up</a> for Pulsar Summit NA 2021!</p><p>For more information about the Apache Pulsar project and the progress, please visit the official website at <a href="https://pulsar.apache.org">https://pulsar.apache.org</a> and follow the project on Twitter <a href="https://twitter.com/apache_pulsar">@apache_pulsar</a>.</p>]]></content>
        <author>
            <name>Matteo Merli, Sijie Guo</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Apache Pulsar 2.7.2]]></title>
        <id>/2021/05/13/Apache-Pulsar-2-7-2</id>
        <link href="https://pulsar.apache.com/blog/2021/05/13/Apache-Pulsar-2-7-2"/>
        <updated>2021-05-13T00:00:00.000Z</updated>
        <summary type="html"><![CDATA[We are very glad to see the Apache Pulsar community has successfully released the 2.7.2 version.]]></summary>
        <content type="html"><![CDATA[<p>We are very glad to see the Apache Pulsar community has successfully released the 2.7.2 version.
This is a minor release that introduces stability fixes and a few new features without breaking changes.</p><h3>News and noteworthy</h3><p>Here is a selection of the most awesome and major enhancements added to Pulsar 2.7.2.</p><ul><li>Improvement in stability in the Kinesis connector <a href="https://github.com/apache/pulsar/pull/10420">#10420</a>.</li><li>Improvement in passing ENV variables to the bookie (PULSAR_EXTRA_OPTS) <a href="https://github.com/apache/pulsar/pull/10397">#10397</a>.</li><li>Allow the C++ client to be built in Windows and add CI for verification <a href="https://github.com/apache/pulsar/pull/10387">#10387</a>.</li><li>Allow activating every BookKeeper client features in the broker <a href="https://github.com/apache/pulsar/pull/9232">#9232</a>.</li><li>Improvement in Pulsar proxy.</li><li>Upgrade core networking libraries: Jetty and Netty.</li></ul><p><a href="https://github.com/apache/pulsar/pulls?page=1&amp;q=is%3Apr+label%3Arelease%2F2.7.2%5D">Here</a> you can find the list of all the improvements and bug fixes.</p><h3>Contributors for 2.7.2 release</h3><p>We would like to thank all the contributors for this release.
Same to other sustainable open source projects, Apache Pulsar is great because it is supported by a vibrant community.</p><p>Code contributors (names taken from GitHub API):
Ali Ahmed, Andrey Yegorov, Binbin Guo, David Kjerrumgaard, Deon van der Vyver, Devin Bost, Enrico Olivelli, Guangning E, Kevin Wilson,
Lari Hotari, Marvin Cai, Masahiro Sakamoto, Matteo Merli, Michael Marshall, Rajan Dhabalia, Shen Liu, Ting Yuan, Vincent Royer,
Yong Zhang, Yunze Xu, Zhanpeng Wu, Zike Yang, baomingyu, CongBo, dockerzhang, feynmanlin, hangc0276, li jinquan, limingnihao,
linlinnn, mlyahmed, PengHui Li, Ran.</p><p>Documentation contributors:
Anonymitaet (Yu Liu), Jennifer Huang</p><p>Also, we want to thank everyone who spent his time reporting issues and sharing the story about using Pulsar.</p><p>Looking forward to your contributions to <a href="https://github.com/apache/pulsar">Apache Pulsar</a>.</p>]]></content>
        <author>
            <name>Enrico Olivelli</name>
            <uri>https://twitter.com/eolivelli</uri>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Apache Pulsar 2.7.0]]></title>
        <id>/2020/12/24/Apache-Pulsar-2-7-0</id>
        <link href="https://pulsar.apache.com/blog/2020/12/24/Apache-Pulsar-2-7-0"/>
        <updated>2020-12-24T00:00:00.000Z</updated>
        <summary type="html"><![CDATA[We are very glad to see the Apache Pulsar community has successfully released the wonderful 2.7.0 version after accumulated hard work. It is a great milestone for this fast-growing project and the whole Pulsar community. This is the result of a huge effort from the community, with over 450 commits and a long list of new features, improvements, and bug fixes.]]></summary>
        <content type="html"><![CDATA[<p>We are very glad to see the Apache Pulsar community has successfully released the wonderful 2.7.0 version after accumulated hard work. It is a great milestone for this fast-growing project and the whole Pulsar community. This is the result of a huge effort from the community, with over 450 commits and a long list of new features, improvements, and bug fixes.</p><p>Here is a selection of the most interesting and major features added to Pulsar 2.7.0.</p><h2>Major features</h2><h3>Transaction support</h3><p>Transactional semantics enable event streaming applications to consume, process, and produce messages in one atomic operation. With transactions, Pulsar achieves the exactly-once semantics for a single partition and multiple partitions as well. This enables new use cases with Pulsar where a client (either as a producer or consumer) can work with messages across multiple topics and partitions and ensure those messages will all be processed as a single unit. This will strengthen the message delivery semantics of Apache Pulsar and processing guarantees for Pulsar Functions.</p><p>Currently, Pulsar transactions are in developer preview. The community will work further to enhance the feature to be used in the production environment soon.</p><p>To enable transactions in Pulsar, you need to configure the parameter in the <code>broker.conf</code> file.</p><pre><code>
transactionCoordinatorEnabled=true

</code></pre><p>Initialize transaction coordinator metadata, so the transaction coordinators can leverage advantages of the partitioned topic, such as load balance.</p><pre><code>
bin/pulsar initialize-transaction-coordinator-metadata -cs 127.0.0.1:2181 -c standalone

</code></pre><p>From the client-side, you can also enable the transactions for the Pulsar client.</p><pre><code class="language-java">
PulsarClient pulsarClient = PulsarClient.builder()
        .serviceUrl(&quot;pulsar://localhost:6650&quot;)
        .enableTransaction(true)
        .build();

</code></pre><p>Here is an example to demonstrate the Pulsar transactions.</p><pre><code class="language-java">
// Open a transaction
Transaction txn = pulsarClient
        .newTransaction()
        .withTransactionTimeout(5, TimeUnit.MINUTES)
        .build()
        .get();

//  Publish messages with the transaction
producer.newMessage(txn).value(&quot;Hello Pulsar Transaction&quot;.getBytes()).send();

// Consume and acknowledge messages with the transaction
Message&lt;byte[]&gt; message = consumer.receive();
consumer.acknowledgeAsync(message.getMessageId(), txn);

// Commit the transaction
txn.commit()

</code></pre><p>For more details about the Pulsar transactions, refer to <a href="http://pulsar.apache.org/docs/en/transactions/">here</a>. For more details about the design of Pulsar transactions, refer to <a href="https://github.com/apache/pulsar/wiki/PIP-31%3A-Transaction-Support">here</a>.</p><h3>Topic level policy</h3><p>Pulsar 2.7.0 introduces the system topic which can maintain all policy change events to achieve the topic level policy. All policies at the namespace level are now also available at the topic level, so users can set different policies at the topic level flexibly without using lots of metadata service resources. The topic level policy enables users to manage topics more flexibly and adds no burden to ZooKeeper.</p><p>To enable topic level policy in Pulsar, you need to configure the parameter in the <code>broker.conf</code> file.</p><pre><code>
systemTopicEnabled=true
topicLevelPoliciesEnabled=true

</code></pre><p>After topic level policy is enabled, you can use Pulsar Admin to update the policy of a topic. Here is an example for setting the data retention for a specific topic.</p><pre><code>
bin/pulsar-admin topics set-retention -s 10G -t 7d persistent://public/default/my-topic

</code></pre><p>For more details about the system topic and topic level policy, refer to <a href="https://github.com/apache/pulsar/wiki/PIP-39%3A-Namespace-Change-Events">here</a></p><h3>Support Azure BlobStore offloader</h3><p>In Pulsar 2.7.0, we add support for Azure BlobStore offloader, which allows users to offload topic data into Azure BlobStore. You can configure the Azure BlobStore offloader driver in the configuration <code>broker.conf</code> file.</p><pre><code>
managedLedgerOffloadDriver=azureblob

</code></pre><p>For more details, refer to <a href="https://github.com/apache/pulsar/pull/8436">here</a>.</p><h3>Native protobuf schema support</h3><p>Pulsar 2.7.0 introduces a native protobuf schema support, which can provide more ability for protobuf users who want to integrate with Pulsar. Here is an example to show how to use native protobuf schema in Java client:</p><pre><code class="language-java">
Consumer&lt;PBMessage&gt; consumer = client.newConsumer(Schema.PROTOBUFNATIVE(PBMessage.class))
.topic(topic)
.subscriptionName(&quot;my-subscription-name&quot;)
.subscribe();

</code></pre><p>For more details, refer to <a href="https://github.com/apache/pulsar/pull/8372">here</a>.</p><h3>Resource limitation</h3><p>In Pulsar, tenant, namespace, and topic are the core resources of a cluster. Pulsar 2.7.0 enables you to limit the maximum tenants of a cluster, the maximum namespaces per tenant, the maximum topics per namespace, and the maximum subscriptions per topic.</p><p>You can configure the resource limitations in the <code>broker.conf</code> file.</p><pre><code>
maxTenants=0
maxNamespacesPerTenant=0
maxTopicsPerNamespace=0
maxSubscriptionsPerTopic=0

</code></pre><p>This provides Pulsar administrators with great convenience in resource management.</p><h3>Support e2e encryption for Pulsar Functions</h3><p>Pulsar 2.7.0 enables you to add End-to-End (e2e) encryption for Pulsar Functions. You can use the public and private key pair that the application configured to perform encryption. Only consumers with a valid key can decrypt encrypted messages.</p><p>To enable End-to-End encryption on Functions Worker, you can set it by specifying <code>--producer-config</code> in the command line terminal. For more information, refer to <a href="http://pulsar.apache.org/docs/en/security-encryption/">Pulsar Encryption</a>.</p><p>For more details, you can see <a href="https://github.com/apache/pulsar/pull/8432">here</a></p><h3>Function rebalance</h3><p>Before 2.7.0, there was no mechanism for rebalancing functions scheduler on workers. The workload for functions m become skewed. Pulsar 2.7.0 supports manual trigger functions rebalance and automatic periodic functions rebalance.</p><p>For more details, refer to <a href="https://github.com/apache/pulsar/pull/7388">https://github.com/apache/pulsar/pull/7388</a>  and <a href="https://github.com/apache/pulsar/pull/7449">https://github.com/apache/pulsar/pull/7449</a>.</p><h2>More information</h2><ul><li>To download Apache Pulsar 2.7.0, click <a href="https://pulsar.apache.org/en/download/">here</a>.</li><li>For more information about Apache Pulsar 2.7.0, see <a href="https://pulsar.apache.org/release-notes/#2.7.0">2.7.0 release notes</a> and <a href="https://github.com/apache/pulsar/pulls?q=milestone%3A2.7.0+-label%3Arelease%2F2.6.2+-label%3Arelease%2F2.6.1+">2.7.0 PR list</a>.</li></ul><p>If you have any questions or suggestions, contact us with mailing lists or slack.</p><ul><li><a href="mailto:users@pulsar.apache.org">users@pulsar.apache.org</a></li><li><a href="mailto:dev@pulsar.apache.org">dev@pulsar.apache.org</a></li><li>Pulsar slack channel: <a href="https://apache-pulsar.slack.com/">https://apache-pulsar.slack.com/</a></li><li>Self-registration at <a href="https://apache-pulsar.herokuapp.com/">https://apache-pulsar.herokuapp.com/</a></li></ul><p>Looking forward to your contributions to <a href="https://github.com/apache/pulsar">Apache Pulsar</a>.</p>]]></content>
        <author>
            <name>Penghui Li</name>
            <uri>https://twitter.com/lipenghui6</uri>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Apache Pulsar 2.6.2]]></title>
        <id>/2020/11/09/Apache-Pulsar-2-6-2</id>
        <link href="https://pulsar.apache.com/blog/2020/11/09/Apache-Pulsar-2-6-2"/>
        <updated>2020-11-09T00:00:00.000Z</updated>
        <summary type="html"><![CDATA[We are excited to see that the Apache Pulsar community has successfully released the 2.6.2 version after a lot of hard work. It is a great milestone for this fast-growing project and the Pulsar community. 2.6.2 is the result of a big effort from the community, with over 154 commits and a long list of improvements and bug fixes.]]></summary>
        <content type="html"><![CDATA[<p>We are excited to see that the Apache Pulsar community has successfully released the 2.6.2 version after a lot of hard work. It is a great milestone for this fast-growing project and the Pulsar community. 2.6.2 is the result of a big effort from the community, with over 154 commits and a long list of improvements and bug fixes.</p><p>Here are some highlights and major features added in Pulsar 2.6.2.</p><h2>Broker</h2><h3>Catch <code>throwable</code> when starting Pulsar</h3><p>Before 2.6.2, Pulsar catched exceptions only when <code>BrokerStarter.start()</code> failed. Some errors such as <code>NoSuchMethodError</code> or <code>NoClassDefFoundError</code> could not be caught, and Pulsar was in abnormal status yet no error log was found in the log file.</p><p>In 2.6.2, we modify exceptions to use <code>throwable</code> to avoid this issue.</p><p>For more information about implementation, see <a href="https://github.com/apache/pulsar/pull/7221">PR-7221</a>.</p><h3>Handle SubscriptionBusyException in resetCursor API</h3><p>In <code>PersistentSubscription.resetCursor</code> method, <code>SubscriptionFencedException</code> is thrown in several places, but it is not handled in <code>PersistentTopicBase</code>, so error messages are not clear.</p><p>In 2.6.2, we export <code>SubscriptionBusyException</code> in <code>PersistentTopicBase</code> for <code>resetCursor</code>, so error messages in the REST API are clear. </p><p>For more information about implementation, see <a href="https://github.com/apache/pulsar/pull/7335">PR-7335</a>.</p><h3>Update Jersey to 2.31</h3><p>Before 2.6.1, Pulsar used the Jersey 2.27, which has security concerns. In Pulsar 2.6.2, we update the Jersey version to the latest stable version(2.31) to enhance security.</p><p>For more information about implementation, see <a href="https://github.com/apache/pulsar/pull/7515">PR-7515</a>.</p><h3>Stop to dispatch when consumers using the Key_Shared subscription stuck</h3><p>Consumers using the <code>Key_Shared</code> subscription would encounter disorder messages occasionally. The following are steps to reproduce the situation:</p><ol><li>Connect Consumer1 to Key_Shared subscription <code>sub</code> and stop to receive</li></ol><ul><li>receiverQueueSize: 500</li></ul><ol start="2"><li>Connect Producer and publish 500 messages with key <code>(i % 10)</code></li><li>Connect Consumer2 to same subscription and start to receive</li></ol><ul><li>receiverQueueSize: 1</li><li>since <a href="https://github.com/apache/pulsar/pull/7106">https://github.com/apache/pulsar/pull/7106</a>, Consumer2 can&#x27;t receive (expected)</li></ul><ol start="4"><li>Producer publish more 500 messages with same key generation algorithm</li><li>After that, Consumer1 start to receive</li><li>Check Consumer2 message ordering</li></ol><ul><li>sometimes message ordering was broken in same key</li></ul><p>In 2.6.2, when consumers use the Key_Shared subscription, Pulsar stops dispatching messages to consumers that are stuck on delivery to guarantee message order. </p><p>For more information about implementation, see <a href="https://github.com/apache/pulsar/pull/7553">PR-7553</a>.</p><h3>Reestablish namespace bundle ownership from false negative releasing and false positive acquiring</h3><p>In acquiring/releasing namespace bundle ownership, ZooKeeper might be disconnected before or after these operations are persisted in the ZooKeeper cluster. It leads to inconsistency between the local ownership cache and ZooKeeper cluster.</p><p>In 2.6.2, we fix the issue with the following:</p><ul><li>In ownership releasing, do not retain ownership in failure.</li><li>In ownership checking, querying and acquiring, reestablish the lost ownership in false negative releasing and false positive acquiring.</li></ul><p>For more information about implementation, see <a href="https://github.com/apache/pulsar/pull/7773">PR-7773</a>.</p><h3>Enable users to configure the executor pool size</h3><p>Before 2.6.2, the executor pool size in Pulsar was set to <code>20</code> when starting Pulsar services. Users could not configure the executor pool size.</p><pre><code>
private final ScheduledExecutorService executor = Executors.newScheduledThreadPool(20,
           new DefaultThreadFactory(&quot;pulsar&quot;));

</code></pre><p>In 2.6.2, users can configure the executor pool size in the <code>broker.conf</code> file based on their needs.</p><p>For more information about implementation, see <a href="https://github.com/apache/pulsar/pull/7782">PR-7782</a>.</p><h3>Add replicated check for <code>checkInactiveSubscriptions</code></h3><p>After the replicated subscription is deleted by <code>checkInactiveSubscriptions</code>, replicated subscriptions are created with <code>receiveSubscriptionUpdated</code>. In this case, the position becomes the latest position.</p><pre><code>
topic.createSubscription(update.getSubscriptionName(),
        InitialPosition.Latest, true /* replicateSubscriptionState */);

</code></pre><p>In 2.6.2, the replicated subscription is excluded from automatic deletion by fixing the <code>PersistentTopic</code>.</p><p>For more information about implementation, see <a href="https://github.com/apache/pulsar/pull/8066">PR-8066</a>.</p><h3>Upgrade jetty-util version to 9.4.31</h3><p>Pulsar client depends on jetty-util. Jetty-util versions earlier than 9.4.30 contain known vulnerabilities.</p><p>In 2.6.2, we upgrade the jetty-util version to <code>9.4.31</code> to enhance security.</p><p>For more information about implementation, see <a href="https://github.com/apache/pulsar/pull/8035">PR-8035</a>.</p><h3>Add command to delete a cluster&#x27;s metadata from ZooKeeper</h3><p>When we share the same ZooKeeper and BookKeeper cluster among multiple broker clusters, if a cluster was removed, its metadata in ZooKeeper were also removed.</p><p>In 2.6.2, we fix the issue in the following ways:</p><ul><li>Add a <code>PulsarClusterMetadataTeardown</code> class to delete the relative nodes from ZooKeeper;</li><li>Wrap the class to <code>bin/pulsar</code> script.</li></ul><p>For more information about implementation, see <a href="https://github.com/apache/pulsar/pull/8169">PR-8169</a>.</p><h3>Replace EventLoop with ThreadPoolExecutor to improve performance instead of EventLoop</h3><p>In 2.6.2, we replace EventLoop with a native JDK thread pool(ThreadPoolExecutor) to improve performance.</p><p>The following is the test result with pulsar perf.</p><p>Before 2.6.1:</p><pre><code>
Aggregated throughput stats --- 11715556 records received --- 68813.420 msg/s --- 537.605 Mbit/s

</code></pre><p>In 2.6.2：</p><pre><code>
Aggregated throughput stats --- 18392800 records received --- 133314.602 msg/s --- 1041.520 Mbit/s

</code></pre><p>For more information about implementation, see <a href="https://github.com/apache/pulsar/pull/8208">PR-8208</a>.</p><h3>Fix deadlock that occurred during topic ownership check</h3><p>Some broker servers had deadlocks while splitting namespace bundles. When checking the thread dump of the broker, some threads were blocked in <code>NamespaceService#getBundle()</code>.</p><pre><code>
&quot;pulsar-ordered-OrderedExecutor-7-0&quot; #34 prio=5 os_prio=0 tid=0x00007eeeab05a800 nid=0x81a5 waiting on condition [0x00007eeeafbd2000]
  java.lang.Thread.State: WAITING (parking)
       at sun.misc.Unsafe.park(Native Method)
       - parking to wait for  &lt;0x00007f17fa965418&gt; (a java.util.concurrent.CompletableFuture$Signaller)
       at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
       at org.apache.pulsar.common.naming.NamespaceBundleFactory.getBundles(NamespaceBundleFactory.java:155)
...

</code></pre><p>The reason for the issue is that the <code>getBundle()</code> method leads to deadlock in <code>NamespaceService#isTopicOwned()</code>. To fix the issue, we remove the <code>getBundle()</code> method. When <code>isTopicOwned()</code> returns <code>false</code>, the bundle metadata is cached and can be got asynchronously. When the client reconnects the next time, Pulsar returns the correct bundle metadata from the cache.</p><p>For more information about implementation, see <a href="https://github.com/apache/pulsar/pull/8406">PR-8406</a>.</p><h2>Proxy</h2><h3>Enable users to configure <code>advertisedAddress</code> in proxy</h3><p>Before 2.6.2, users could not configure <code>advertisedAddress</code> on the proxy side. In 2.6.2, users can configure <code>advertisedAddress</code> in proxy just as they do in Pulsar broker.</p><p>For more information about implementation, see <a href="https://github.com/apache/pulsar/pull/7542">PR-7542</a>.</p><h3>Add proxy plugin interface to support user defined additional servlet</h3><p>To enable users to access the broker flexibly, Pulsar provides plugins similar to broker protocol and broker interceptor. However, users could not access the proxy before 2.6.2.</p><p>To enable users to customize data requests in proxy, we add the protocol plugin for proxy in 2.6.2.</p><p>For more information about implementation, see <a href="https://github.com/apache/pulsar/pull/8067">PR-8067</a>.</p><h3>Fix the null exception when starting the proxy service</h3><p>When enabling the broker TLS and broker client authentication with OAuth2 plugin,
the proxy service exits with an unexpected null exception.</p><p>The reason is that when initializing the flow, authentication is called, so the token client is not initialized before using.</p><p>In 2.6.2, we fix the null exception when starting the proxy service.</p><p>For more information about implementation, see <a href="https://github.com/apache/pulsar/pull/8019">PR-8019</a>.</p><h2>Java Client</h2><h3>Support input-stream for trustStore cert</h3><p>In 2.6.1, Pulsar supports dynamic cert loading by using input stream for TLS cert and key file. The feature is mainly used by container. However, container also requires dynamic loading for truststore certs and users cannot store trust-store cert into file-system. </p><p>In 2.6.2, Pulsar supports loading truststore cert dynamically using input stream.</p><p>For more information about implementation, see <a href="https://github.com/apache/pulsar/pull/7442">PR-7442</a>.</p><h3>Avoid subscribing the same topic</h3><p>The current key of <code>MultiTopicsConsumerImpl.topics</code> is the topic name passed by the user. The <code>topicNameValid</code> method checks if the name is valid and <code>topics</code> doesn&#x27;t contain the key.</p><p>However, if a multi-topic consumer subscribes a partition of a subscribed partitioned topic,  <code>subscribeAsync</code> succeeds and a new <code>ConsumerImpl</code> of the same partition is created, which is redundant.</p><p>Also, if a multi-topic consumer subscribes <code>public/default/topic</code> or <code>persistent://public/default/topic</code>, while the initial subscribed topic is <code>topic</code>, the redundant consumers would be created.</p><p>In 2.6.2, we fix the issue in the following ways to avoid subscribing the same topic again:</p><ul><li>Use the full topic name as key for <code>MultiTopicsConsumerImpl.topics</code>.</li><li>Check that both the full topic name and the full partitioned topic name do not exist in <code>MultiTopicsConsumerImpl.topics</code> when <code>subscribeAsync</code> is called.</li><li>Throw a different exception to a different topic is invalid and the topic is already subscribed</li></ul><p>For more information about implementation, see <a href="https://github.com/apache/pulsar/pull/7823">PR-7823</a>.</p><h2>CPP Client</h2><h3>Wait for all seek operations complete</h3><p>When a partitioned consumer calls <code>seek</code>, it waits for only one partition&#x27;s seek operation completion because each internal consumer calls callback(result) to complete the same promise.</p><p>In 2.6.2, we use the following methods to avoid this problem:</p><ul><li>Add a <code>MultiResultCallback</code> implementation, the callback completes only when all N events complete successfully or one of N events fails.</li><li>Use <code>MultiResultCallback</code> to wrap callback from <code>PartitionedConsumerImpl::seekAsync</code>.</li></ul><p>For more information about implementation, see <a href="https://github.com/apache/pulsar/pull/7216">PR-7216</a>.</p><h3>Make <code>clear()</code> thread-safe</h3><p>Before 2.6.2, the <code>clear()</code> methods of <code>BatchAcknowledgementTracker</code> and <code>UnAckedMessageTrackerEnabled</code> are not thread-safe.</p><p>In 2.6.2, we acquire a mutex in these <code>clear()</code> methods to make it thread-safe.</p><p>For more information about implementation, see <a href="https://github.com/apache/pulsar/pull/7862">PR-7862</a>.</p><h3>Add Snappy library to Docker images for building C++ packages</h3><p>The program crashes when Snappy compression is enabled on the C++ client packaged as RPM/DEB. This is because Snappy library is not included in the Docker image for building the RPM/DEB package.</p><p>In 2.6.2, we add the Snappy library to the docker images to avoid the issue.</p><p>For more information about implementation, see <a href="https://github.com/apache/pulsar/pull/8086">PR-8086</a>.</p><h3>Support key based batching</h3><p>Support key based batching for the C++ client. In addition, currently, the implementation of <code>BatchMessageContainer</code> is coupling to <code>ProducerImpl</code> tightly. The batch message container registers a timer to the producer&#x27;s executor and the timeout callback is also the producer&#x27;s method. Even its <code>add</code> method could call <code>sendMessage</code> to send a batch to the producer&#x27;s pending queue. These should be the producer&#x27;s work.</p><p>In 2.6.2, we implement the feature in the following ways:</p><ul><li>Add a <code>MessageAndCallbackBatch</code> to store a <code>MessageImpl</code> of serialized single messages and a callback list.</li><li>Add a <code>BatchMessageContainerBase</code> to provide interface methods and methods like update/clear message number/bytes, create <code>OpSendMsg</code>.</li><li>Let <code>ProducerImpl</code> manage the batch timer and determine whether to create <code>OpSendMsg</code> from <code>BatchMessageContainerBase</code> and send it.</li><li>Make <code>BatchMessageContainer</code> inherit <code>BatchMessageContainerBase</code>, it only manages a <code>MessageAndCallbackBatch</code>.</li><li>Add a <code>BatchMessageKeyBasedContainer</code> that inherits <code>BatchMessageContainerBase</code>, it manages a map of message key and <code>MessageAndCallbackBatch</code>.</li><li>Add a producer config to change batching type.</li></ul><p>For more information about implementation, see <a href="https://github.com/apache/pulsar/pull/7996">PR-7996</a>.</p><h2>Functions</h2><h3>Enable Kubernetes runtime to customize function instance class path</h3><p>Before 2.6.2, the function worker&#x27;s classpath is used to configure the function instance (runner)&#x27;s classpath. When the broker (function worker) uses an image that is different from the function instance (runner) for Kubernetes runtime, the classpath is wrong and the function instance could not load the instance classes.</p><p>In 2.6.2, we add a function instance classpath entry to the Kubernetes runtime config, and construct the function launch command accordingly.</p><p>For more information about implementation, see <a href="https://github.com/apache/pulsar/pull/7844">PR-7844</a>.</p><h3>Set <code>dryrun</code> of Kubernetes Runtime to null</h3><p>Before 2.6.2, we upgraded the <code>client-java</code> of Kubernetes to <code>0.9.2</code> to enhance security. However, during the creation of statefulsets, secrets, and services, the value of <code>dryrun</code> was set to <code>true</code>, which was not accepted by Kubernetes. Only <code>All</code> is allowed in Kubernetes. </p><p>In 2.6.2, we set the <code>dryrun</code> of Kubernetes Runtime to null.</p><p>For more information about implementation, see <a href="https://github.com/apache/pulsar/pull/8064">PR-8064</a>.</p><h2>Pulsar SQL</h2><h3>Upgrade Presto version to 332</h3><p>Upgrade Presto version to 332. Resolve different packages between prestosql and prestodb. Although the latest version is 334, versions higher than 333 require Java 11.</p><p>For more information about implementation, see <a href="https://github.com/apache/pulsar/pull/7194">PR-7194</a>.</p><h2>pulsar-admin</h2><h3>Add CLI command to get the last message ID</h3><p>Add <code>last-message-id</code> command in CLI, so users can get the last message ID with this command.</p><p>For more information about implementation, see <a href="https://github.com/apache/pulsar/pull/8082">PR-8082</a>.</p><h3>Support deleting schema ledgers when deleting topics</h3><p>Users could not delete schema of topics with the <code>PersistentTopics#deleteTopic</code> and <code>PersistentTopics#deletePartitionedTopic</code> in REST APIs. After topics were deleted, the schema ledgers still existed with adding an empty schema ledger.</p><p>In 2.6.2, we implement the feature in the following ways:</p><ul><li>Add a <code>deleteSchema</code> query param to REST APIs of deleting topics/partitioned topics;</li><li>Add a map to record the created ledgers in <code>BookkeeperSchemaStorage</code>;</li><li>Expose <code>deleteSchema</code> param in pulsar-admin APIs;</li><li>Delete schema ledgers when deleting the cluster with <code>-a</code> option.</li></ul><p>For more information about implementation, see <a href="https://github.com/apache/pulsar/pull/8167">PR-8167</a>.</p><h3>Support deleting all data associated with a cluster</h3><p>When multiple broker clusters shared the same bookie cluster, if users wanted to remove a broker cluster, the associated ledgers in bookies were not deleted as expected.</p><p>In 2.6.2, we add a <code>cluster delete</code> command to enable users to delete all the data associated with the cluster.</p><p>For more information about implementation, see <a href="https://github.com/apache/pulsar/pull/8133">PR-8133</a>.</p><h2>Pulsar Perf</h2><h3>Enable users to configure ioThread number in pulsar-perf</h3><p>In pulsar-perf, the default Pulsar client ioThread number is <code>Runtime.getRuntime().availableProcessors()</code> and users could not configure it in the command line. When running a pulsar-perf producer, it may cause messages to enqueue competition and lead to high latency.</p><p>In 2.6.2, we implement the feature in the following ways:</p><ol><li>Enable users to configure the ioThread number in the command line;</li><li>Change the default ioThead number from <code>Runtime.getRuntime().availableProcessors()</code> to <code>1</code></li></ol><p>For more information about implementation, see <a href="https://github.com/apache/pulsar/pull/8090">PR-8090</a>.</p><h2>More information</h2><ul><li>To download Apache Pulsar 2.6.2, click <a href="https://pulsar.apache.org/en/download/">download</a>.</li><li>For more information about Apache Pulsar 2.6.2, see <!-- -->[2.6.2 release notes]<!-- -->(<a href="https://pulsar.apache.org/release-notes/#2.6.2">https://pulsar.apache.org/release-notes/#2.6.2</a> and <a href="https://github.com/apache/pulsar/pulls?q=is%3Apr+label%3Arelease%2F2.6.2+is%3Aclosed">2.6.2 PR list</a>.</li></ul><p>If you have any questions or suggestions, contact us with mailing lists or slack.</p><ul><li><a href="mailto:users@pulsar.apache.org">users@pulsar.apache.org</a></li><li><a href="mailto:dev@pulsar.apache.org">dev@pulsar.apache.org</a></li><li>Pulsar slack channel: <a href="https://apache-pulsar.slack.com/">https://apache-pulsar.slack.com/</a></li><li>Self-registration at <a href="https://apache-pulsar.herokuapp.com/">https://apache-pulsar.herokuapp.com/</a></li></ul><p>Looking forward to your contributions to <a href="https://github.com/apache/pulsar">Pulsar</a>.</p>]]></content>
        <author>
            <name>Xiaolong Ran</name>
            <uri>https://twitter.com/wolf4j1</uri>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Pulsar Summit Asia 2020 Schedule is Now Online]]></title>
        <id>/2020/11/04/pulsar-summit-asia-schedule</id>
        <link href="https://pulsar.apache.com/blog/2020/11/04/pulsar-summit-asia-schedule"/>
        <updated>2020-11-04T00:00:00.000Z</updated>
        <summary type="html"><![CDATA[The Pulsar Summit is a global conference dedicated to sharing best practices, project updates, and insights across the Apache Pulsar community. Pulsar’s inaugural global summit, the Pulsar Summit Virtual Conference 2020, took place in June 2020 and featured more than 30 sessions from top Pulsar experts, developers and thought-leaders from companies such as Salesforce, Verizon Media, and Splunk, and the conference attracted 600+ attendees.]]></summary>
        <content type="html"><![CDATA[<p>The Pulsar Summit is a global conference dedicated to sharing best practices, project updates, and insights across the Apache Pulsar community. Pulsar’s inaugural global summit, the <a href="https://pulsar-summit.org/en/event/virtual-conference-2020">Pulsar Summit Virtual Conference 2020</a>, took place in June 2020 and featured more than 30 sessions from top Pulsar experts, developers and thought-leaders from companies such as Salesforce, Verizon Media, and Splunk, and the conference attracted 600+ attendees. </p><p>The rapid adoption of Apache Pulsar over the past few years has led to a high demand for Pulsar events. Today, StreamNative, a cloud-native event streaming company powered by Apache Pulsar, and also the host of <a href="https://pulsar-summit.org/en/event/asia-2020">Pulsar Summit Asia 2020</a>, announced more details on the upcoming event. Taking place on November 28th &amp; 29th, the two-day event will feature more than 30 live sessions by tech leads, open-source developers, software engineers, and software architects from <strong>Splunk, Yahoo! JAPAN, TIBCO, China Mobile, Tencent, Dada Group, KingSoft Cloud, Tuya Smart, and PingCAP</strong>, and will include sessions on Pulsar use cases, its ecosystem, operations, and technology deep dives. </p><p>See below for some of our featured sessions, which include both English and Mandarin tracks:</p><ul><li><a href="https://pulsar-summit.org/en/event/asia-2020/sessions/how-splunk-is-using-pulsar-io">How Splunk is using Pulsar IO （English）</a> - In this talk, Jerry Peng, Principal Software Engineer at Splunk will share insights on Splunk’s evaluation and decision to adopt the Pulsar IO framework, details on how Splunk&#x27;s DSP product leverages the Pulsar IO framework, and insights on batch sources, a feature that was recently added to Pulsar IO.</li><li><a href="https://pulsar-summit.org/en/event/asia-2020/sessions/apache%E2%80%93pulsar%E2%80%93at%E2%80%93yahoo%E2%80%93japan%E2%80%93adoption%E2%80%93operational%E2%80%93experiences%E2%80%93and%E2%80%93future">Apache Pulsar at Yahoo! JAPAN - Adoption, Operational Insights and the Future（English）</a> - In this talk, Nozomi Kurihara, Manager of the Messaging Platform team in Yahoo!Japan Corporation will share practical use cases of Apache Pulsar on production and insights on how to operate Apache Pulsar for large scale data streams.</li><li><a href="https://pulsar-summit.org/en/event/asia-2020/sessions/running-apache-pulsar-on-tencent-cloud-new-challenges-discussion-practice">Running Apache Pulsar on Tencent Cloud: New Challenges, Discussion, Practice (Mandarin)</a> - In this talk, Lin Lin, senior engineer of Tencent Cloud will address how Pulsar helps solve challenges with message queues on Tencent Cloud, such as dynamic expansion and contraction, and large numbers of partitions.</li><li><a href="https://pulsar-summit.org/en/event/asia-2020/sessions/how-bigo-builds-real-time-message-system-with-apache-pulsar-and-flink">How BIGO built a Real-Time Message System with Apache Pulsar and Flink (Mandarin) </a> - In this talk, Hang Chen, Leader of the Messaging Platform team from BIGO will share how BIGO leveraged Apache Pulsar to build a real-time message system and how they tune Pulsar for production.</li><li><a href="https://pulsar-summit.org/en/event/asia-2020/sessions/a-daredevil-story-apache-pulsar-in-zhaopin-com">A Daredevil&#x27; Story: Apache Pulsar in Zhaopin.com (Mandarin)</a> - In this talk, Shunli Gao, Senior Engineer at Zhaopin will share details on the development and future prospects of Apache Pulsar at Zhaopin.</li><li><a href="https://pulsar-summit.org/en/event/asia-2020/sessions/transactional-event-streaming-with-apache-pulsar">Transactional Event Streaming with Apache Pulsar (Mandarin)</a> - In this talk, Bo Cong, software engineer at StreamNative will share how Pulsar transaction works and how it is supported by Pulsar Functions.</li><li><a href="https://pulsar-summit.org/en/event/asia-2020/sessions/benchmarking-pulsar-vs-kafka-on-aws-process-results">Benchmarking Pulsar vs. Kafka on AWS: Process &amp; Results (Mandarin) </a> - In this talk, Penghui Li, the Apache Pulsar PMC member and software engineer at StreamNative will share the results of a benchmark test comparing Pulsar and Kafka that was run on AWS. The test ran Pulsar and Kafka under the same hardware environments on the write throughput, tailing read throughput, catchup read throughput, publish latency, and end-to-end latency of these two systems.</li></ul><p>More featured talks coming soon!</p><p>The number and diversity of the sessions demonstrate the accelerated adoption of Pulsar in PoC and production environments, as well as the rapid development in functionalities and diverse ecosystems. To learn more about how companies leverage Pulsar for <strong>messaging and event streaming, serverless computing, real-time analytics, event-driven applications, and mission-critical deployment management in production</strong>, <a href="https://hopin.to/events/pulsar-summit-asia-2020">RSVP</a> today!</p><p>We would like to say special thanks to the speakers for sharing their Pulsar expertise and experience with the community.</p><h1>About Apache Pulsar <a href="https://pulsar.apache.org">Apache Pulsar</a> is a cloud-native, distributed messaging and streaming platform that manages hundreds of billions of events per day. Pulsar was originally developed at Yahoo! as the unified messaging platform connecting critical Yahoo applications such as Yahoo Finance, Yahoo Mail, and Flickr to data.</h1><p>Today, Pulsar is used for real-time event streaming use cases, including data pipelines, microservices, and stream processing. Its cloud-native architecture and built-in multi-tenancy differentiate it from its predecessors and uniquely position it as an enterprise-ready, event streaming platform. Pulsar&#x27;s multi-layer architecture enables stability, reliability, scalability, and high performance, simplifies management and reduces costs. Its built-in multi-tenancy and geo-replication ensure that companies are able to build applications with disaster recovery. </p><h1>About StreamNative <a href="https://streamnative.io">StreamNative</a>, founded by the original developers of Apache Pulsar and Apache BookKeeper, enables organizations to build the next generation of messaging and event streaming applications. Leveraging Apache Pulsar and BookKeeper, we optimize for scalability and resiliency while reducing the overhead management and complexity required by incumbent technologies. We do this by offering Pulsar and StreamNative’s ‘products as a service’. StreamNative is building a world-class team that is passionate about building amazing products and committed to customer success.</h1>]]></content>
        <author>
            <name>Carolyn King, Dianjin Wang</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Pulsar Summit Asia 2020 CFP is now open]]></title>
        <id>/2020/09/01/pulsar-summit-asia-2020-cfp</id>
        <link href="https://pulsar.apache.com/blog/2020/09/01/pulsar-summit-asia-2020-cfp"/>
        <updated>2020-09-01T00:00:00.000Z</updated>
        <summary type="html"><![CDATA[The Pulsar Summit is an annual conference dedicated to the Apache Pulsar community. The summit brings together an international audience of CTOs/CIOs, developers, data architects, data scientists, Apache Pulsar committers/contributors, and the messaging and streaming community. Together, they share experiences, ideas, and insights on Pulsar and its growing community, and receive hands-on training sessions led by Pulsar experts.]]></summary>
        <content type="html"><![CDATA[<p>The Pulsar Summit is an annual conference dedicated to the Apache Pulsar community. The summit brings together an international audience of CTOs/CIOs, developers, data architects, data scientists, Apache Pulsar committers/contributors, and the messaging and streaming community. Together, they share experiences, ideas, and insights on Pulsar and its growing community, and receive hands-on training sessions led by Pulsar experts.</p><p>After a very successful Pulsar Summit Virtual Conference in June, we have decided to present our Pulsar Summit Asia 2020 in the same way on November 28-29, 2020. The two-day conference will be free to attend! Are you interested in presenting? Suggested topics include Pulsar use cases, operations, technology deep dive, and ecosystem. CFP and registration are now open!</p><p><img src="/img/pulsar-summit-asia-2020.png"/></p><h2>Speak at Pulsar Summit</h2><p>The opportunity to speak at the second global Pulsar Summit is a great chance to participate in the rapidly growing Apache Pulsar community. Join us for the opportunity to be on stage with top Pulsar thought-leaders, including Apache Pulsar PMC members Sijie Guo and Jia Zhai from <a href="https://streamnative.io/">StreamNative</a>, Penghui Li from Zhaopin.com, Nozomi Kurihara from <a href="https://about.yahoo.co.jp/">Yahoo Japan Corporation</a>, and other community leaders such as Dezhi Liu from <a href="https://www.tencent.com/en-us">Tencent</a>, Vincent Xie from <a href="https://www.bestpay.com.cn/">Orange Finance</a>. Proposals for speaker presentations are currently being accepted. Suggested topics include Pulsar use cases, operations, technology deep dive, and ecosystem. Submissions are open until <strong>October 14, 2020</strong>.</p><p>If you have questions about submitting a proposal, or want some feedback or advice in general, please do not hesitate to reach out to <a href="mailto:organizers@pulsar-summit.org">organizers@pulsar-summit.org</a>. We are happy to help out! Details are available on the <a href="https://pulsar-summit.org/en/event/asia-2020/cfp">CFP website</a>.</p><h2>Dates to remember</h2><ul><li>CFP opens: September 1, 2020</li><li>CFP closes: October 21, 2020 - 23:59 (CST: China Standard Time/UTC+8 time zone)</li><li>CFP notification: October 28, 2020</li><li>Schedule announcement: November 4, 2020</li></ul><h2>Speaker benefits</h2><p>When your speaking proposal is approved, you will enjoy the following benefits:</p><ul><li>The opportunity to expand your network and raise your profile in the Apache Pulsar community.</li><li>The chance to demonstrate your experience and deep knowledge in the rapidly growing event streaming space.</li><li>Your name, title, company, and bio will be featured on the Pulsar Summit Asia 2020 website.</li><li>Your session will be added to the Pulsar Summit YouTube Channel and promoted on Twitter and LinkedIn.</li><li>A professionally produced video of your presentation.</li></ul><h2>Speaker requirements</h2><p>In addition to your talk, we ask that you actively participate in promoting the event via your personal and company channels. These include posting on your Twitter, LinkedIn, WeChat, Weibo, blog and other channels. We would also like to work directly with your marketing team on co-marketing opportunities. These include, but are not limited to, posting to your company’s Twitter, LinkedIn, WeChat and other developer communities and sending a dedicated Pulsar Summit email to your company’s email list. Contact us at <a href="mailto:organizers@pulsar-summit.org">organizers@pulsar-summit.org</a> with any questions. </p><h2>Registration</h2><p>If you are interested in attending Pulsar Summit Asia 2020, please sign in Hopin and <a href="https://hopin.to/events/pulsar-summit-asia-2020">checkout our event</a>. Your ideas are very important to us, and we will prepare the content accordingly. </p><p>After you checkout the event in Hopin, you will be notified with the event update at the first time when announcing.</p><h2>Sponsor Pulsar Summit</h2><p>Pulsar Summit is a community run conference and your support is needed. Sponsoring this event will provide a great opportunity for your organization to further engage with the Apache Pulsar community. <a href="mailto:partners@pulsar-summit.org">Contact us</a> to learn more.</p><p>Help us make #PulsarSummit 2020 a big success by spreading the word and submitting your proposal! Follow us on Twitter (<a href="https://twitter.com/PulsarSummit">@pulsarsummit</a>) to receive the latest updates of the conference!</p><p>Hope to see you at Pulsar Summit Asia 2020!</p><h2>About Apache Pulsar</h2><p>Apache Pulsar is a cloud-native, distributed messaging and streaming platform that manages hundreds of billions of events per day. Pulsar was originally developed and deployed inside Yahoo as the consolidated messaging platform connecting critical Yahoo applications such as Yahoo Finance, Yahoo Mail, and Flickr, to data. Pulsar was contributed to open source by Yahoo in 2016 and became a top-level Apache Software Foundation project in 2018.</p><h2>About StreamNative</h2><p>StreamNative is the organizer of Pulsar Summit Asia 2020. StreamNative is enabling organizations to build the next generation of messaging and event streaming applications. Leveraging Apache Pulsar and BookKeeper, we optimize for scalability and resiliency while reducing the overhead management and complexity required by incumbent technologies. We do this by offering Pulsar and StreamNative’s &quot;products as a service&quot;. StreamNative is building a world-class team that is passionate about building amazing products and committed to customer success.</p>]]></content>
        <author>
            <name>Jennifer Huang</name>
            <uri>https://twitter.com/Jennife06125739</uri>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Apache Pulsar Celebrates 300 Contributors]]></title>
        <id>/2020/08/24/Pulsar-300-contributors</id>
        <link href="https://pulsar.apache.com/blog/2020/08/24/Pulsar-300-contributors"/>
        <updated>2020-08-24T00:00:00.000Z</updated>
        <summary type="html"><![CDATA[Dear Pulsar community,]]></summary>
        <content type="html"><![CDATA[<p>Dear Pulsar community,</p><p>Over the last few years, the shift to real-time streaming technologies has bolstered the adoption of Pulsar and there has been a major increase in both the interest and adoption of Pulsar in 2020 alone. With Pulsar being sought out by companies developing messaging and event-streaming applications — from Fortune 100 companies to forward-thinking start-ups — the community is growing quickly. </p><p>This community growth has contributed to a new milestone for Pulsar - our <a href="https://github.com/apache/pulsar/graphs/contributors">300th contributor</a> to the Pulsar repository. This milestone is even more exciting given that we added 100 contributors in the last 8 months alone!</p><p>As many of you know, Apache Pulsar is a cloud-native messaging and event streaming platform that has experienced rapid growth since it was committed to open source in 2016. Pulsar graduated as a Top-Level Project (TLP) in September 2018, has launched 92 releases, attracted 5100+ commits from 300 contributors, received 6.5k+ stars, 1.6k+ forks, and 2.2k+ Slack users. </p><p>The influx of developers joining the Pulsar community is in large part due to the high market demand for next-generation messaging technologies, big-data insights, and real-time streaming. Top developers and industry leaders are joining the Pulsar community for the opportunity to help shape the future of this technology. </p><h2>Community Events</h2><p>To meet the high demand for education and training in the Pulsar community, the community has launched some key initiatives this year. We host weekly TGIP(Thank God It&#x27;s Pulsar) training, which features Pulsar thought-leaders and Pulsar PMC Members. To meet global demand, we currently host two different weekly trainings. One <a href="https://www.youtube.com/watch?v=Vc_a2ppRzlI&amp;list=PLqRma1oIkcWhWAhKgImEeRiQi5vMlqTc-">TGIP training</a> runs on Pacific Time, and the other <a href="https://github.com/streamnative/tgip-cn">TGIP-CN training</a> runs on Beijing Time. </p><p>We also host monthly <a href="https://www.youtube.com/watch?v=mncXc_T6JkU&amp;list=PLqRma1oIkcWhfmUuJrMM5YIG8hjju62Ev">webinars</a> to bring together Pulsar and messaging community thought-leaders to share best practices, insights and product news. Thank <a href="https://twitter.com/merlimat">Matteo Merli</a>, <a href="https://twitter.com/addisonjh">Addison Higham</a>, Joe Francis, <a href="https://twitter.com/ShivjiJha">Shivji Kumar Jha</a>, <a href="https://twitter.com/DevinBost">Devin Bost</a>, <a href="https://twitter.com/PierreZ">Pierre Zemb</a>, <a href="https://twitter.com/jessetanderson">Jesse Anderson</a>, <a href="https://twitter.com/sijieg">Sijie Guo</a> and other speakers for contributing so much valuable knowledge.</p><p>This year also marked our first global summit, held in June 2020. Hosted by StreamNative and Splunk, the first-ever <a href="https://pulsar-summit.org/">Pulsar Summit Virtual Conference</a> featured 30+ talks from 20+ organizations. Thank all speakers for sharing your stories about Pulsar, and thank you to all of the attendees for joining the event.</p><p>We are excited to announce that we will be hosting Pulsar Summit Asia 2020 on November 28 and 29, and the call for presentations for this event will be coming soon.</p><h2>Pulsar Adoption</h2><p>In addition to the growth in contributors, we are excited to see accelerated adoption of Pulsar in PoC and production environments. Pulsar is helping companies globally to unlock the power of real-time data and to grow their businesses with efficiency and simplicity. </p><p>Key adoption stories illustrate Pulsar&#x27;s ability to handle mission-critical applications. These include <a href="https://streamnative.io/success-stories/tencent">Tencent’s adoption</a> of Pulsar for its transactional billing system, which processes more than 10 billion transactions and 10+ TBs of data daily. <a href="https://www.youtube.com/watch?v=FXQvsHz_S1A">Verizon Media is another success story</a>, having operated Pulsar in production for more than 5 years, managing millions of write requests/second, and supporting the business across six global data centers. Most recently Splunk, which had used Kafka in production environments for years, <a href="https://www.youtube.com/watch?v=_q8s3_0-BRQ">adopted Pulsar for their new data processor</a>. </p><p>For more insights on Pulsar adoption, you can find a list for companies using or contributing to Apache Pulsar on <a href="http://pulsar.apache.org/en/powered-by/">Pulsar Powered by page</a>. </p><h2>Ecosystem Development</h2><p>Committed community partners have also contributed to key project advancements. Below, we look at two recent product launches.</p><h3>OVHCloud Helps Companies Move from Kafka to Pulsar</h3><p>In March 2020, <a href="https://streamnative.io/blog/tech/2020-03-24-bring-native-kafka-protocol-support-to-apache-pulsar">OVHCloud and StreamNative launched Kafka-on-Pulsar (KoP)</a>, the result of the two companies working closely in partnership. <a href="https://github.com/streamnative/kop">KoP</a> enables Kafka users to migrate their existing Kafka applications and services to Pulsar without modifying the code. Although only recently released, KoP has already been adopted by several organizations and is being used in production environments. Moreover, KoP&#x27;s availability is helping to expand Pulsar&#x27;s adoption.</p><h3>China Mobile Helps Companies Move from RabbitMQ to Pulsar</h3><p>In June 2020, <a href="https://streamnative.io/blog/tech/2020-06-15-announcing-aop-on-pulsar">China Mobile and StreamNative announced the launch of another major platform upgrade, AMQP-on-Pulsar (AoP)</a>. Similar to KoP, <a href="https://github.com/streamnative/aop">AoP</a> allows organizations currently using RabbitMQ (or other AMQP message brokers) to migrate existing applications and services to Pulsar without code modification. Again, this is a key initiative that will help drive the adoption and usage of Pulsar.</p><p>You can find a number of other connections and integrations, such as MQTT-on-Pulsar for building IoT applications, in the <a href="https://hub.streamnative.io/">StreamNative Hub</a>.</p><p>These events and initiatives illustrate the Pulsar community&#x27;s firm commitment to education and ecosystem development. More importantly, they demonstrate the momentum and growth we can expect in the future.</p><h2>Special Thanks</h2><p>We would like to thank the Pulsar community, contributors and committers, who have helped to drive development, growth and adoption for Pulsar. We would especially like to recognize our distinguished contributors and committers (including but not limited to): </p><ul><li><a href="https://github.com/merlimat">Matteo Merli</a> from <a href="https://www.splunk.com/">Splunk</a></li><li><a href="https://github.com/rdhabalia">Rajan Dhabalia</a> from <a href="https://www.verizonmedia.com/">Verizon Media</a></li><li><a href="https://github.com/sijie">Sijie Guo</a> from <a href="https://streamnative.io/">StreamNative</a></li><li><a href="https://github.com/srkukarni">Sanjeev Kulkarni</a> from <a href="https://www.splunk.com/">Splunk</a></li><li><a href="https://github.com/jerrypeng">Boyang Jerry Peng</a> from <a href="https://www.splunk.com/">Splunk</a></li><li><a href="https://github.com/ivankelly">Ivan Brendan Kelly</a> from <a href="https://www.splunk.com/">Splunk</a></li><li><a href="https://github.com/codelipenghui">Penghui Li</a> from <a href="http://www.zhaopin.com/">Zhaopin.com</a></li><li><a href="https://github.com/jiazhai">Jia Zhai</a> from <a href="https://streamnative.io/">StreamNative</a></li></ul><p>To view other contributors, see <a href="https://github.com/apache/pulsar/graphs/contributors">Pulsar contributor list</a>.</p><h2>Get Involved</h2><p>We invite you to join this fast-growing community. Together, we will continue to develop technology to meet today’s most innovative messaging and event-streaming use cases and to help companies unlock the value of real-time data. </p><p>Whether it is joining our <a href="https://apache-pulsar.slack.com/">Pulsar Slack channel</a>, sharing your Pulsar story via a sponsored <a href="https://www.youtube.com/watch?v=mncXc_T6JkU&amp;list=PLqRma1oIkcWhfmUuJrMM5YIG8hjju62Ev">webinar</a> or case study, joining a <a href="https://github.com/streamnative/tgip">TGIP</a>/<a href="https://github.com/streamnative/tgip-cn">TGIP-CN</a>, or attending or speaking at the next Pulsar Summit, we look forward to connecting with you. </p><p>You can also subscribe our mailing lists: <a href="mailto:users-subscribe@pulsar.apache.org">users@pulsar.apache.org</a> and <a href="mailto:dev-subscribe@pulsar.apache.org">dev@pulsar.apache.org</a>.</p>]]></content>
        <author>
            <name>Jennifer Huang</name>
            <uri>https://twitter.com/Jennife06125739</uri>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Apache Pulsar 2.6.1]]></title>
        <id>/2020/08/21/Apache-Pulsar-2-6-1</id>
        <link href="https://pulsar.apache.com/blog/2020/08/21/Apache-Pulsar-2-6-1"/>
        <updated>2020-08-21T00:00:00.000Z</updated>
        <summary type="html"><![CDATA[We are excited to see that the Apache Pulsar community has successfully released 2.6.1 version after a lot of hard work. It is a great milestone for this fast-growing project and the Pulsar community. 2.6.1 is the result of a big effort from the community, with over 100 commits and a long list of improvements and bug fixes.]]></summary>
        <content type="html"><![CDATA[<p>We are excited to see that the Apache Pulsar community has successfully released 2.6.1 version after a lot of hard work. It is a great milestone for this fast-growing project and the Pulsar community. 2.6.1 is the result of a big effort from the community, with over 100 commits and a long list of improvements and bug fixes.</p><p>Here are some highlights and major features added in Pulsar 2.6.1.</p><h2>Broker</h2><h3>Limit the batch size to the minimum of the <code>maxNumberOfMessages</code> and <code>maxSizeOfMessages</code></h3><ol><li><p>Batch size is not limited to the minimum of the <code>maxNumberOfMessages</code> and <code>maxSizeOfMessages</code> from the BatchReceive policy.</p></li><li><p>When the batch size is greater than the <code>receiveQ</code> of the consumer (for example, the batch size is 3000 and a receiveQ is 500), the following issue occurs:</p><p>In a multi-topic (pattern) consumer, the client stops receiving any messages. The client gets paused and never resumed when setting a timeout in the batch policy. Only one batch is fetched and the client is never resumed.</p></li></ol><p>For more information about implementation, see <a href="https://github.com/apache/pulsar/pull/6865">PR-6865</a>.</p><h3>Fix hash range conflict issue in Key_Shared subscription with sticky hash range</h3><p>In <code>Key_Shared</code> subscription where the <code>stickyHashRange</code> is used, consumers are not allowed to use interleaving hashes.</p><p>The pull request fixes the hash range conflict issue in <code>Key_Shared</code> with sticky hash range.</p><p>For more information about implementation, see <a href="https://github.com/apache/pulsar/pull/7231">PR-7231</a>.</p><h3>Fix get lookup permission error</h3><p>If the <code>canProduce</code> or <code>canConsume</code> method throws an exception, the <code>canLookup</code> method just throws the exception and does not check other permissions. The code snippet is as follows: </p><pre><code class="language-java">
try {
    return canLookupAsync(topicName, role, authenticationData)
            .get(conf.getZooKeeperOperationTimeoutSeconds(), SECONDS);
}

</code></pre><p>PR-7234 invokes <code>canLookupAsync</code>. When Pulsar AuthorizationService checks lookup permission, if the user has the <code>canProducer</code> or <code>canConsumer</code> role, the user performs <code>canLookup</code> operations.</p><p>For more information about implementation, see <a href="https://github.com/apache/pulsar/pull/7234">PR-7234</a>.</p><h3>Avoid introducing null read position for the managed cursor</h3><p>Avoid introducing null read position for the managed cursor. The most doubtful thing is the <code>getNextValidPosition</code> method in the <code>ManagedLedgerImpl</code>. If a given position is greater than the position added last time, it returns a <code>null</code> value, and the read position is also <code>null</code>.</p><p>In this PR, we add a log and print the stack trace to find the root cause and fallback to the next position if the <code>null</code> occurs at the next valid position.</p><p>For more information about implementation, see <a href="https://github.com/apache/pulsar/pull/7264">PR-7264</a>.</p><h3>Fix error in creation of non-durable cursor</h3><p>An NPE occurs when we fail to create a non-durable cursor and continue to create the subscription instance. </p><pre><code class="language-java">
try {
    cursor = ledger.newNonDurableCursor(startPosition, subscriptionName);
} catch (ManagedLedgerException e) {
    subscriptionFuture.completeExceptionally(e);
}

return new PersistentSubscription(this, subscriptionName, cursor, false);

</code></pre><p>Additionally, the NPE leads to the topic usage count increasing to 1. When deleting a topic, the topic cannot be deleted even if you use the force flag.</p><p>For more information about implementation, see <a href="https://github.com/apache/pulsar/pull/7355">PR-7355</a>.</p><h3>Avoid an NPE occurs in the <code>ManagedLedgerImpl.isOffloadedNeedsDelete</code> method</h3><p>When the default value of the <code>offload-deletion-lag</code> is set to <code>null</code>, an NPE occurs. To fix the bug, null check is added in the <code>ManagedLedgerImpl.isOffloadedNeedsDelete</code> method.</p><p>For more information about implementation, see <a href="https://github.com/apache/pulsar/pull/7389">PR-7389</a>.</p><h3>Fix producer stuck issue due to NPE when creating a new ledger</h3><p>NPE occurs when creating a ledger if the network address is unresolvable. If NPE occurs before adding the timeout task, the timeout mechanism does not work. The unresolvable network address is common in the Kubernetes environment. It happens when a bookie pod or a worker node restarts.</p><p>This pull request fixes from the following perspectives:</p><ol><li>Catch the NPE when creating a new ledger.</li><li>When the timeout task is triggered, it always executes the callback. It is totally fine because we already have the logic to ensure the callback is triggered only once.</li><li>Add a mechanism to detect that the <code>CreatingLedger</code> state is not moving.</li></ol><p>For more information about implementation, see <a href="https://github.com/apache/pulsar/pull/7401">PR-7401</a>.</p><h3>Fix NPE when using advertisedListeners</h3><p>The broker failed to acquire ownership for the namespace bundle when using <code>advertisedListeners=internal:pulsar://node1:6650,external:pulsar://node1.external:6650</code> with external listener name. Correct <code>BrokerServiceUrlTls</code> when TLS is not enabled.</p><p>For more information about implementation, see <a href="https://github.com/apache/pulsar/pull/7620">PR-7620</a>.</p><h3>Fix the issue that the deduplication cursor cannot be deleted after message deduplication is disabled</h3><p>When enabling the message deduplication in the <code>broker.conf</code> file, disabling it and then restarting the broker, the deduplication cursor is not deleted.</p><p>This PR fixes the issue, so when you disable message deduplication, you can delete the deduplication cursor.</p><p>For more information about implementation, see <a href="https://github.com/apache/pulsar/pull/7656">PR-7656</a>.</p><h3>Fix the issue that GetLastEntry() reads entry <code>-1</code></h3><p>Previously, the code does not include a return statement. If the entry is set to <code>-1</code>, after sending code, the response reads the entry and sends a second response, as shown in the following example.</p><pre><code>
16:34:25.779 [pulsar-io-54-7:org.apache.bookkeeper.client.LedgerHandle@748] ERROR org.apache.bookkeeper.client.LedgerHandle - IncorrectParameterException on ledgerId:0 firstEntry:-1 lastEntry:-1
16:34:25.779 [pulsar-client-io-82-1:org.apache.pulsar.client.impl.ConsumerImpl@1986] INFO  org.apache.pulsar.client.impl.ConsumerImpl - [persistent://external-repl-prop/pulsar-function-admin/assignment][c-use-fw-localhost-0-function-assignment-initialize-reader-b21f7607c9] Successfully getLastMessageId 0:-1
16:34:25.779 [pulsar-client-io-82-1:org.apache.pulsar.client.impl.ClientCnx@602] WARN  org.apache.pulsar.client.impl.ClientCnx - [id: 0xc78f4a0e, L:/127.0.0.1:55657 - R:localhost/127.0.0.1:55615] Received error from server: Failed to get batch size for entry org.apache.bookkeeper.mledger.ManagedLedgerException: Incorrect parameter input
16:34:25.779 [pulsar-client-io-82-1:org.apache.pulsar.client.impl.ClientCnx@612] WARN  org.apache.pulsar.client.impl.ClientCnx - [id: 0xc78f4a0e, L:/127.0.0.1:55657 - R:localhost/127.0.0.1:55615] Received unknown request id from server: 10

</code></pre><p>PR-7495 adds a return statement to code, so GetLastEntry() reads the last entry, instead of <code>-1</code>.  </p><p>For more information about implementation, see <a href="https://github.com/apache/pulsar/pull/7495">PR-7495</a>.</p><h3>Fix the error of updating partitions for non-persistent topic</h3><p>When updating partitions on a non-persistent topic, Error 409 is returned. The pull request fixes partitions errors for non-persistent topics.</p><p>For more information about implementation, see <a href="https://github.com/apache/pulsar/pull/7459">PR-7459</a>.</p><h2>ZooKeeper</h2><h3>Use hostname for bookie rack awareness mapping</h3><p>In <a href="https://github.com/apache/pulsar/pull/5607">PR-5607</a>, the <code>useHostName()</code> is added with <code>return false</code>. The rack-aware policy passes the Bookie&#x27;s hostname into an IP address and then uses that IP address to figure out to which rack the bookie belongs.</p><p>Then two issues occur: </p><ol><li>The IP does not match the hostname which is recorded in the <code>/bookies</code> z-node</li><li>If there is an error in parsing the bookie hostname (eg: transient DNS error), an NPE is triggered and the BK client never realizes that this bookie is available in the cluster.</li></ol><p>The exception is thrown at Line 77(as shown in the following code snippet), since <code>getAddress()</code> returns a <code>null</code> given that the address is parsed.  </p><pre><code class="language-java">
74        if (dnsResolver.useHostName()) {
75            names.add(addr.getHostName());
76        } else {
77            names.add(addr.getAddress().getHostAddress());
78        }

</code></pre><p>The default implementation for the <code>DnsResolver.useHostName()</code> returns <code>true</code>.</p><p>For more information about implementation, see <a href="https://github.com/apache/pulsar/pull/7361">PR-7361</a>.</p><h2>Java Client</h2><h3>Fix the issue that the HTTP header used in Athenz authentication can not be renamed</h3><p>The authentication plugin for Athenz allows users to change the name of the HTTP header for sending an authentication token to a broker server with a parameter named <code>roleHeader</code>. The change uses the value of the <code>roleHeader</code> parameter on the <code>AuthenticationAthenz</code> side, and uses it directly as the header name.</p><p>For more information about implementation, see <a href="https://github.com/apache/pulsar/pull/7311">PR-7311</a>.</p><h3>Fix the issue that batch ack set is recycled multiple times</h3><p>The batch ack sets are recycled multiple times, due to race condition in group ack flush and cumulative Ack. So we add a recycled state check for the ack set in PR-7409, and fix the recycle issue.</p><p>For more information about implementation, see <a href="https://github.com/apache/pulsar/pull/7409">PR-7409</a>.</p><h3>Add authentication client with OAuth2 support</h3><p>Pulsar supports authenticating clients using OAuth 2.0 access tokens. You can use tokens to identify a Pulsar client and associate with some &quot;principal&quot; (or &quot;role&quot;) that is permitted to do some actions, for example, publish messages to a topic or consume messages from a topic. </p><p>This module is to support Pulsar Client Authentication Plugin for OAuth 2.0 directly. The client communicates with the Oauth 2.0 server, gets an <code>access token</code> from the Oauth 2.0 server, and passes the <code>access token</code> to Pulsar broker to do the authentication.</p><p>So, the broker can use <code>org.apache.pulsar.broker.authentication.AuthenticationProviderToken</code>,
and the user can add their own <code>AuthenticationProvider</code> to work with this module.</p><p>For more information about implementation, see <a href="https://github.com/apache/pulsar/pull/7420">PR-7420</a>.</p><h3>Not subscribe to the topic when the consumer is closed</h3><p>Fix race condition on the closed consumer while reconnecting to the broker.</p><p>The race condition happens when the consumer reconnects to the broker. The connection of the consumer is set to <code>null</code> when the consumer reconnects to the broker. If the consumer is not connected to broker at this time, the client does not send the consumer command to the broker. So, when the consumer reconnects to the broker, the consumer sends the subscribe command again. </p><p>This pull request adds a state check when the <code>connectionOpened()</code> of the consumer opens. If the consumer is in closing or closed state, the consumer does not send the subscribe command.</p><p>For more information about implementation, see <a href="https://github.com/apache/pulsar/pull/7589">PR-7589</a>.</p><h3>OAuth2 authentication plugin uses AsyncHttpClient</h3><p>Previously, the OAuth2 client authentication plugin used Apache HTTP client lib to make requests, Apache HTTP client is used to validate hostname. As suggested in <a href="https://github.com/apache/pulsar/issues/7612">#7612</a>, we get rid of the dependency of using Apache HTTP client.</p><p>In PR-7615, OAuth2 client authentication plugin uses AsyncHttpClient, which is used in client and broker. For more information about implementation, see <a href="https://github.com/apache/pulsar/pull/7615">PR-7615</a>.</p><h2>CPP Client</h2><h3>CPP Oauth2 authentication client</h3><p>Pulsar supports authenticating clients using OAuth 2.0 access tokens. You can use tokens to identify a Pulsar client and associate with some &quot;principal&quot; (or &quot;role&quot;) that is permitted to do some actions (eg: publish messages to a topic or consume messages from a topic). This change tries to support it in cpp client.</p><p>For more information about implementation, see <a href="https://github.com/apache/pulsar/pull/7467">PR-7467</a>.</p><h3>Fix partition index error in close callback</h3><p>In partitioned producer/consumer&#x27;s close callback, the partition index is always <code>0</code>. The <code>ProducerImpl/ConsumerImpl</code> internal partition index field should be passed to <code>PartitionedProducerImpl/PartitionedConsumerImpl</code> close callback.</p><p>For more information about implementation, see <a href="https://github.com/apache/pulsar/pull/7282">PR-7282</a>.</p><h3>Fix segment crashes caused by race condition of timer in CPP client</h3><p>Segment crashes occur in a race condition:</p><pre><code>- The close operation calls the `keepAliveTimer_.reset()`.
- The `keepAliveTimer` is called by `startConsumerStatsTimer` and `handleKeepAliveTimeout` methods. Actually, the `keepAliveTimer` should not be called by those two methods.
</code></pre><p>This pull request fixes those issues.</p><p>For more information about implementation, see <a href="https://github.com/apache/pulsar/pull/7572">PR-7572</a>.</p><h3>Add support to read credentials from file</h3><p>Support reading credentials from a file to make it align with the Java client.</p><p>For more information about implementation, see <a href="https://github.com/apache/pulsar/pull/7606">PR-7606</a>.</p><h3>Fix multi-topic consumer segfault on connection error</h3><p>The multi-topic consumer triggers a segfault when an error occurs in creating a consumer. This is due to the calls to close the partial consumers with a null callback.</p><p>For more information about implementation, see <a href="https://github.com/apache/pulsar/pull/7588">PR-7588</a>.</p><h2>Functions</h2><h3>Use fully qualified hostname as default to advertise worker</h3><p>There is a difference in getting hostnames between <code>Java 8</code> and <code>Java 11</code>. In Java 8, <code>InetAddress.getLocalHost().getHostName()</code> returns the fully qualified hostname; in Java 11, it returns a simple hostname. In this case, we should rather use the <code>getCanonicalHostName()</code>, which returns the fully qualified hostname. This is the same method to get the advertised address for workers as well.</p><p>For more information about implementation, see <a href="https://github.com/apache/pulsar/pull/7360">PR-7360</a>.</p><h3>Fix the function BC issue introduced in release 2.6.0</h3><p>A backwards compatibility breakage is introduced in <a href="https://github.com/apache/pulsar/pull/5985">PR-5985</a>. When the running function workers are separated from brokers, updating workers and brokers independently from release 2.5.0 to 2.6.0 results in the following error:</p><pre><code class="language-text">
java.lang.NullPointerException: null\n\tat java.net.URI$Parser.parse(URI.java:3104) ~[?:?]
java.net.URI.&lt;init&gt;(URI.java:600) ~[?:?]\n\tat java.net.URI.create(URI.java:881) ~[?:?]
org.apache.pulsar.functions.worker.WorkerUtils.initializeDlogNamespace(WorkerUtils.java:160) ~[org.apache.pulsar-pulsar-functions-worker-2.7.0-SNAPSHOT.jar:2.7.0-SNAPSHOT]
org.apache.pulsar.functions.worker.Worker.initialize(Worker.java:155) ~[org.apache.pulsar-pulsar-functions-worker-2.7.0-SNAPSHOT.jar:2.7.0-SNAPSHOT] 
org.apache.pulsar.functions.worker.Worker.start(Worker.java:69) ~[org.apache.pulsar-pulsar-functions-worker-2.7.0-SNAPSHOT.jar:2.7.0-SNAPSHOT] 
org.apache.pulsar.functions.worker.FunctionWorkerStarter.main(FunctionWorkerStarter.java:67) [org.apache.pulsar-pulsar-functions-worker-2.7.0-SNAPSHOT.jar:2.7.0-SNAPSHOT]

</code></pre><p>This is because the broker 2.5.0 supports &quot;bookkeeperMetadataServiceUri&quot; and the admin client returns a <code>null</code> field, thus causing the NPE.</p><p>For more information about implementation, see <a href="https://github.com/apache/pulsar/pull/7528">PR-7528</a>.</p><h2>pulsar-perf</h2><h3>Support <code>tlsAllowInsecureConnection</code> in pulsar-perf produce/consume/read performance tests</h3><p>Add <code>tlsAllowInsecureConnection</code> config to the CLI tool <strong>pulsar-perf</strong>, to support produce/consume/read performance tests to clusters with insecure TLS connections.</p><p>For more information about implementation, see <a href="https://github.com/apache/pulsar/pull/7300">PR-7300</a>.</p><h2>More information</h2><ul><li>To download Apache Pulsar 2.6.1, click <a href="https://pulsar.apache.org/en/download/">download</a>.</li><li>For more information about Apache Pulsar 2.6.1, see <a href="https://pulsar.apache.org/release-notes/#2.6.1">2.6.1 release notes</a> and <a href="https://github.com/apache/pulsar/pulls?q=is%3Apr+label%3Arelease%2F2.6.1+is%3Aclosed">2.6.1 PR list</a>.</li></ul><p>If you have any questions or suggestions, contact us with mailing lists or slack.</p><ul><li><a href="mailto:users@pulsar.apache.org">users@pulsar.apache.org</a></li><li><a href="mailto:dev@pulsar.apache.org">dev@pulsar.apache.org</a></li><li>Pulsar slack channel: <a href="https://apache-pulsar.slack.com/">https://apache-pulsar.slack.com/</a></li><li>Self-registration at <a href="https://apache-pulsar.herokuapp.com/">https://apache-pulsar.herokuapp.com/</a></li></ul><p>Looking forward to your contributions to <a href="https://github.com/apache/pulsar">Pulsar</a>.</p>]]></content>
        <author>
            <name>XiaoLong Ran</name>
            <uri>https://twitter.com/wolf4j1</uri>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Apache Pulsar 2.6.0]]></title>
        <id>/2020/06/18/Apache-Pulsar-2-6-0</id>
        <link href="https://pulsar.apache.com/blog/2020/06/18/Apache-Pulsar-2-6-0"/>
        <updated>2020-06-18T00:00:00.000Z</updated>
        <summary type="html"><![CDATA[We are very glad to see the Apache Pulsar community has successfully released the wonderful 2.6.0 version after accumulated hard work. It is a great milestone for this fast-growing project and the whole Pulsar community. This is the result of a huge effort from the community, with over 450 commits and a long list of new features, improvements, and bug fixes.]]></summary>
        <content type="html"><![CDATA[<p>We are very glad to see the Apache Pulsar community has successfully released the wonderful 2.6.0 version after accumulated hard work. It is a great milestone for this fast-growing project and the whole Pulsar community. This is the result of a huge effort from the community, with over 450 commits and a long list of new features, improvements, and bug fixes.</p><p>Here is a selection of some of the most interesting and major features added to Pulsar 2.6.0.</p><h2>Core Pulsar</h2><h3>[PIP-37]<!-- --> Large message size support</h3><p>This PIP adds support for producing and consuming large size messages by splitting the large message into multiple chunks. This is a very powerful feature for sending and consuming very large messages.</p><p>Currently, this feature only works for the non-shared subscription and it has client-side changes. You need to upgrade the Pulsar client version to 2.6.0. You can enable the message trunk at the producer side as below.</p><pre><code class="language-java">
client.newProducer()
    .topic(&quot;my-topic&quot;)
    .enableChunking(true)
    .create();

</code></pre><p>For more information about PIP-37, see <a href="https://github.com/apache/pulsar/wiki/PIP-37:-Large-message-size-handling-in-Pulsar">here</a>. <br/> For more information about implementation details, see <a href="https://github.com/apache/pulsar/pull/4400">PR-4440</a>.</p><h3>[PIP-39]<!-- --> Namespace change events (system topic)</h3><p>This PIP introduces the system topic to store namespace change events. Previously, Pulsar only allowed you to set the namespace policy, all topics under the namespace followed the namespace policy. Many users want to set the policy for topics. The main reason for not using the same way as namespace level policy is to avoid introducing more workload on the ZooKeeper. </p><p>The original intention of the system topic is to be able to store topic policy in a topic rather than ZooKeeper. So this is the first step to achieve topic level policy. And we can easily add support for the topic level policy with this feature.</p><p>For more information about PIP-39, see <a href="https://github.com/apache/pulsar/wiki/PIP-39%3A-Namespace-Change-Events">here</a>.<br/> For more information about implementation details, see  <a href="https://github.com/apache/pulsar/pull/4955">PR-4955</a>.</p><h3>[PIP-45]<!-- --> Pluggable metadata interface</h3><p>We have been advancing to enable Pulsar to use other metastore services rather than ZooKeeper. This PIP converts <code>ManagedLedger</code> to use the <code>MetadataStore</code> interface. This facilitates the metadata server plug-in process. Through the <code>MetadataStore</code> interface, it is easy to add other metadata servers into Pulsar such as <a href="https://github.com/etcd-io/etcd">etcd</a>.</p><p>For more information about PIP-45, see <a href="https://github.com/apache/pulsar/wiki/PIP-45%3A-Pluggable-metadata-interface">here</a>. <br/> For more information about implementation details, see <a href="https://github.com/apache/pulsar/pull/5358">PR-5358</a>.</p><h3>[PIP-54]<!-- --> Support acknowledgment at the batch index level</h3><p>Previously, the broker only tracked the acknowledged state in the batch message level. If a subset of the batch messages was acknowledged, the consumer could still get the acknowledged message of that batch message while the batch message redelivery happened. </p><p>This PIP adds support for acknowledging the local batch index of a batch. This feature is not enabled by default. You can enable it in the <code>broker.conf</code> as below.</p><pre><code>
acknowledgmentAtBatchIndexLevelEnabled=true

</code></pre><p>For more information about PIP-54, see <a href="https://github.com/apache/pulsar/wiki/PIP-54:-Support-acknowledgment-at-batch-index-level">here</a>. <br/> For more information about implementation details, see <a href="https://github.com/apache/pulsar/pull/6052">PR-6052</a>.</p><h3>[PIP-58]<!-- --> Support consumers setting custom message retry delay</h3><p>For many online business systems, various exceptions usually occur in business logic processing, so the message needs to be re-consumed, but users hope that this delay time can be controlled flexibly. Previously, processing methods were usually to send messages to special retry topics, because production can specify any delay, so consumers subscribe to the business topic and retry topic at the same time. Now you can set a retry delay for each message as below.</p><pre><code class="language-java">
Consumer&lt;byte[]&gt; consumer = pulsarClient.newConsumer(Schema.BYTES)
    .enableRetry(true)
    .receiverQueueSize(100)
    .deadLetterPolicy(DeadLetterPolicy.builder()
        .maxRedeliverCount(maxRedeliveryCount)
        .retryLetterTopic(&quot;persistent://my-property/my-ns/my-subscription-custom-Retry&quot;)
        .build())
    .subscribe();

consumer.reconsumeLater(message, 10, TimeUnit.SECONDS);

</code></pre><p>For more information about PIP-58, see <a href="https://github.com/apache/pulsar/wiki/PIP-58-%3A-Support-Consumers--Set-Custom-Retry-Delay">here</a>. <br/> For more information about implementation details, see <a href="https://github.com/apache/pulsar/pull/6449">PR-6449</a>.</p><h3>[PIP-60]<!-- --> Support SNI routing to support various proxy servers</h3><p>Previously, Pulsar did not provide support to use other proxies, such as Apache Traffic Server (ATS), HAProxy, Nginx, and Envoy, which are more scalable and secured. Most of these proxy servers support SNI routing which can route traffic to a destination without having to terminate the SSL connection. This PIP adds SNI routing and makes changes to the Pulsar client.</p><p>For more information about PIP-60, see <a href="https://github.com/apache/pulsar/wiki/PIP-60:-Support-Proxy-server-with-SNI-routing">here</a>. <br/> For more information about implementation details, see  <a href="https://github.com/apache/pulsar/pull/6566">PR-6566</a>.</p><h3>[PIP-61]<!-- --> Advertise multiple addresses</h3><p>This PIP allows the broker to expose multiple advertised listeners and to support the separation of internal and external network traffic. You can specify multiple advertised listeners in <code>broker.conf</code> as below.</p><pre><code>
advertisedListeners=internal:pulsar://192.168.1.11:6660,external:pulsar://110.95.234.50:6650

</code></pre><p>From the client side, you can specify the listener name for the client as below.</p><pre><code class="language-java">
PulsarClient.builder()
    .serviceUrl(url)
    .listenerName(&quot;internal&quot;)
    .build();

</code></pre><p>For more information about PIP-61, see <a href="https://github.com/apache/pulsar/wiki/PIP-61%3A-Advertised-multiple-addresses">here</a>. <br/> For more information about implementation details, see <a href="https://github.com/apache/pulsar/pull/6903">PR-6903</a>.</p><h3>[PIP-65]<!-- --> Adapt Pulsar IO sources to support <code>BatchSources</code></h3><p>This PIP introduces <code>BatchSource</code> as a new interface for writing batch-based connectors. It also introduces <code>BatchSourceTriggerer</code> as an interface to trigger the data collection of a <code>BatchSource</code>. It then provides system implementation in <code>BatchSourceExecutor</code>.</p><p>For more information about PIP-65, see <a href="https://github.com/apache/pulsar/wiki/PIP-65%3A-Adapting-Pulsar-IO-Sources-to-support-Batch-Sources">here</a>. <br/> For more information about implementation details, see <a href="https://github.com/apache/pulsar/pull/7090">PR-7090</a>.</p><h3>[Load balancer]<!-- --> Add <code>ThresholdShedder</code> strategy for the load balancer</h3><p>The <code>ThresholdShedder</code> strategy is more flexible than <code>LoadSheddingStrategy</code> for Pulsar. The <code>ThresholdShedder</code> calculates the average resource usage of the brokers, and individual broker resource usage compares with the average value. If it is greater than the average value plus threshold, the overload shedder is triggered. You can enable it in <code>broker.conf</code> as below.</p><pre><code>
loadBalancerLoadSheddingStrategy=org.apache.pulsar.broker.loadbalance.impl.ThresholdShedder

</code></pre><p>You can customize more parameters for the <code>ThresholdShedder</code> if needed as below.</p><pre><code>
# The broker resource usage threshold.
# When the broker resource usage is greater than the pulsar cluster average resource usage,
# the threshold shedder will be triggered to offload bundles from the broker.
# It only takes effect in ThresholdShedder strategy.
loadBalancerBrokerThresholdShedderPercentage=10

# When calculating new resource usage, the history usage accounts for.
# It only takes effect in ThresholdShedder strategy.
loadBalancerHistoryResourcePercentage=0.9

# The BandWithIn usage weight when calculating new resource usage.
# It only takes effect in ThresholdShedder strategy.
loadBalancerBandwithInResourceWeight=1.0

# The BandWithOut usage weight when calculating new resource usage.
# It only takes effect in ThresholdShedder strategy.
loadBalancerBandwithOutResourceWeight=1.0

# The CPU usage weight when calculating new resource usage.
# It only takes effect in ThresholdShedder strategy.
loadBalancerCPUResourceWeight=1.0

# The heap memory usage weight when calculating new resource usage.
# It only takes effect in ThresholdShedder strategy.
loadBalancerMemoryResourceWeight=1.0

# The direct memory usage weight when calculating new resource usage.
# It only takes effect in ThresholdShedder strategy.
loadBalancerDirectMemoryResourceWeight=1.0

# Bundle unload minimum throughput threshold (MB), avoiding bundle unload frequently.
# It only takes effect in ThresholdShedder strategy.
loadBalancerBundleUnloadMinThroughputThreshold=10

</code></pre><p>For more information about implementation details, see <a href="https://github.com/apache/pulsar/pull/6772">PR-6772</a>.</p><h3>[Key Shared]<!-- --> Add consistent hashing in the Key_Shared distribution</h3><p>Previously, the implementation of the Key_Shared subscription used a mechanism to divide their hash space across the available consumers. This was based on dividing the currently assigned hash ranges when a new consumer joined or left. Pulsar 2.6.0 introduces a new consistent hash distribution for the Key_Shared subscription. You can enable the consistent hash distribution in <code>broker.conf</code> and the auto split approach is still selected by default.</p><pre><code>
# On KeyShared subscriptions, with default AUTO_SPLIT mode, use splitting ranges or
# consistent hashing to reassign keys to new consumers
subscriptionKeySharedUseConsistentHashing=false

# On KeyShared subscriptions, number of points in the consistent-hashing ring.
# The higher the number, the more equal the assignment of keys to consumers
subscriptionKeySharedConsistentHashingReplicaPoints=100

</code></pre><p>We plan to use consistent hash distribution by default in the subsequent versions.
For more information about implementation details, see  <a href="https://github.com/apache/pulsar/pull/6791">PR-6791</a>.</p><h3>[Key Shared]<!-- --> Fix ordering issue in KeyShared dispatcher when adding consumers</h3><p>This is a great fix for the Key_Shared subscription. Previously, ordering was broken in a KeyShared dispatcher if a new consumer c2 came in and an existing consumer c1 went out. This was because messages with keys previously assigned to c1 may route to c2, which might break the message ordering dispatch guarantee in the Key_Shared subscription. This PR introduces new consumers joining in a &quot;paused&quot; state until the previous messages are acknowledged to ensure the messages are dispatched orderly. </p><p>If you still want the relaxed ordering, you can set up at the consumer side as below.</p><pre><code class="language-java">
pulsarClient.newConsumer()
    .keySharedPolicy(KeySharedPolicy.autoSplitHashRange().setAllowOutOfOrderDelivery(true))
    .subscribe();

</code></pre><p>For more information about implementation details, see <a href="https://github.com/apache/pulsar/pull/7106">PR-7106</a> and <a href="https://github.com/apache/pulsar/pull/7108">PR-7108</a>.</p><h3>[Key Shared]<!-- --> Add support for key hash range reading</h3><p>This PR supports sticky key hash range reader. A broker only dispatches messages whose hash of the message key contains by a specified key hash range. Besides, multiple key hash ranges can be specified on a reader.</p><pre><code class="language-java">
pulsarClient.newReader()
    .topic(topic)
    .startMessageId(MessageId.earliest)
    .keyHashRange(Range.of(0, 10000), Range.of(20001, 30000))
    .create();

</code></pre><p>For more information about implementation details, see  <a href="https://github.com/apache/pulsar/pull/5928">PR-5928</a>.</p><h3>Use pure-java Air-Compressor instead of JNI based libraries</h3><p>Previously, JNI based libraries were used to perform data compression. While these libraries do have an overhead in terms of size and affect the JNI overhead which is typically measurable when compressing many small payloads. This PR replaces compression libraries for LZ4, ZStd, and Snappy with <a href="https://github.com/airlift/aircompressor">AirCompressor</a>, which is a pure Java compression library used by Presto.</p><p>For more information about implementation details, see  <a href="https://github.com/apache/pulsar/pull/5390">PR-5390</a>.</p><h3>Support multiple Pulsar clusters using the same BookKeeper cluster</h3><p>This PR allows multiple pulsar clusters to use the specified BookKeeper cluster by pointing BookKeeper client to the ZooKeeper connection string of BookKeeper cluster. This PR adds a configuration (<code>bookkeeperMetadataServiceUri</code>) to discover BookKeeper cluster metadata store and uses metadata service URI to initialize BookKeeper clients.</p><pre><code>
# Metadata service uri that bookkeeper is used for loading corresponding metadata driver
# and resolving its metadata service location.
# This value can be fetched using `bookkeeper shell whatisinstanceid` command in BookKeeper cluster.
# For example: zk+hierarchical://localhost:2181/ledgers
# The metadata service uri list can also be semicolon separated values like below:
# zk+hierarchical://zk1:2181;zk2:2181;zk3:2181/ledgers
bookkeeperMetadataServiceUri=

</code></pre><p>For more information about implementation details, see <a href="https://github.com/apache/pulsar/pull/5985">PR-5985</a>.</p><h3>Support deleting inactive topics when subscriptions are caught up</h3><p>Previously, Pulsar supported deleting inactive topics which do not have active producers and subscriptions. This PR supports deleting inactive topics when all subscriptions of the topic are caught up and when there are no active producers or consumers. This PR exposes inactive topic delete mode in <code>broker.conf</code>. In the future, we can support a namespace level configuration for the inactive topic delete mode.</p><pre><code>
# Set the inactive topic delete mode. Default is delete_when_no_subscriptions
# &#x27;delete_when_no_subscriptions&#x27; mode only delete the topic which has no subscriptions and no active producers
# &#x27;delete_when_subscriptions_caught_up&#x27; mode only delete the topic that all subscriptions has no backlogs(caught up)
# and no active producers/consumers
brokerDeleteInactiveTopicsMode=delete_when_no_subscriptions

</code></pre><p>For more information about implementation details, see <a href="https://github.com/apache/pulsar/pull/6077">PR-6077</a>.</p><h3>Add a flag to skip broker shutdown on transient OOM</h3><p>A high dispatch rate on one of the topics may cause a broker to go OOM temporarily. It is a transient error and the broker can recover within a few seconds as soon as some memory gets released. However, in 2.4 release (<a href="https://github.com/apache/pulsar/pull/4196">#4196</a>), the “restarted broker on OOM” feature can cause huge instability in a cluster, where a topic moves from one broker to another and restarts multiple brokers and disrupts other topics as well. So this PR provides a dynamic flag to skip broker shutdown on OOM to avoid instability in a cluster.</p><p>For more information about implementation details, see <a href="https://github.com/apache/pulsar/pull/6634">PR-6634</a>.</p><h3>Make ZooKeeper cache expiry time configurable</h3><p>Previously, ZooKeeper cache expiry time was hardcoded and it needed to be configurable to refresh the value based on various requirements, for example, refreshing the value quickly in case of zk-watch miss, avoiding frequent cache refresh to avoid zk-read or avoiding issue due to zk read timeout, and so on. Now you can configure ZooKeeper cache expiry time in <code>broker.conf</code> as below.</p><pre><code>
# ZooKeeper cache expiry time in seconds
zooKeeperCacheExpirySeconds=300

</code></pre><p>For more information about implementation details, see <a href="https://github.com/apache/pulsar/pull/6668">PR-6668</a>.</p><h3>Optimize consumer fetch messages in case of batch message</h3><p>When a consumer sends a fetch request to a broker server, it contains a fetch message number telling the server how many messages should be pushed to a consumer client. However, the broker server stores data in BookKeeper or broker cache according to entry rather than a single message if the producer produces messages using the batch feature. There is a gap to map the number of messages to the number of entries when dealing with consumer fetch requests. This PR adds a variable <code>avgMessagesPerEntry</code> to record average messages stored in one entry. It updates when a broker server pushes messages to a consumer. When dealing with consumer fetch requests, it maps fetch request number to entry number. Additionally, this PR exposes the <code>avgMessagePerEntry</code> static value to consumer stat metric json.</p><p>You can enable <code>preciseDispatcherFlowControl</code> in <code> broker.conf</code> as below.</p><pre><code>
# Precise dispatcher flow control according to history message number of each entry
preciseDispatcherFlowControl=false

</code></pre><p>For more information about implementation details, see  <a href="https://github.com/apache/pulsar/pull/6719">PR-6719</a></p><h3>Introduce precise topic publish rate limiting</h3><p>Previously, Pulsar supported the publish rate limiting but it is not a precise control. Now, for some use cases that need precise control, you can enable it in <code>broker.conf</code> as below.</p><pre><code>
preciseTopicPublishRateLimiterEnable=true

</code></pre><p>For more information about implementation details, see  <a href="https://github.com/apache/pulsar/pull/7078">PR-7078</a>.</p><h3>Expose check delay of new entries in <code>broker.conf</code></h3><p>Previously, the check delay of new entries was 10 ms and could not be changed by users. Currently, for consumption latency sensitive scenarios, you can set the value of check delay of new entries to a smaller value or 0 in <code>broker.conf</code> as below. Using a smaller value may degrade consumption throughput. </p><pre><code>
managedLedgerNewEntriesCheckDelayInMillis=10

</code></pre><p>For more information about implementation details, see  <a href="https://github.com/apache/pulsar/pull/7154">PR-7154</a>.</p><h3>[Schema]<!-- -->  Supports <code>null</code> key and <code>null</code> value in KeyValue schema</h3><p>For more information about implementation details, see  <a href="https://github.com/apache/pulsar/pull/7139">PR-7139</a>.</p><h3>Support triggering ledger rollover when <code>maxLedgerRolloverTimeMinutes</code> is met</h3><p>This PR implements a monitoring thread to check if the current topic ledger meets the constraint of <code>managedLedgerMaxLedgerRolloverTimeMinutes</code> and triggers a rollover to make the configuration take effect. Another important idea is that if you trigger a rollover, you can close the current ledger so that you can release the storage of the current ledger. For some less commonly used topics, the current ledger data is likely to be expired and the current rollover logic is only triggered when adding a new entry. Obviously, this results in a waste of disk space. The monitoring thread is scheduled at a fixed time interval and the interval is set to <code>managedLedgerMaxLedgerRolloverTimeMinutes</code>. Each inspection makes two judgments at the same time, for example, <code>currentLedgerEntries &gt; 0</code> and <code>currentLedgerIsFull()</code>. When the number of current entries is equal to 0, it does not trigger a new rollover and you can use this to reduce the ledger creation.</p><p>For more information about implementation details, see  <a href="https://github.com/apache/pulsar/pull/7111">PR-7116</a>.</p><h2>Proxy</h2><h3>Add REST API to get connection and topic stats</h3><p>Previously, Pulsar proxy did not have useful stats to get internal information about the proxy. It is better to have internal-stats of proxy to get information, such as live connections, topic stats (with higher logging level), and so on. This PR adds REST API to get stats for connection and topics served by proxy.</p><p>For more information about implementation details, see <a href="https://github.com/apache/pulsar/pull/6473">PR-6473</a>.</p><h2>Admin</h2><h3>Support getting a message by message ID in pulsar-admin</h3><p>This PR adds a new command <code>get-message-by-id</code> to the pulsar-admin. It allows users to check a single message by providing ledger ID and entry ID. </p><p>For more information about implementation details, see <a href="https://github.com/apache/pulsar/pull/6331">PR-6331</a>.</p><h3>Support deleting subscriptions forcefully</h3><p>This PR adds the method <code>deleteForcefully</code> to support force deleting subscriptions. </p><p>For more information about implementation details, see <a href="https://github.com/apache/pulsar/pull/6383">PR-6383</a>.</p><h2>Functions</h2><h3>Built-in functions</h3><p>This PR implements the possibility of creating built-in functions in the same way as adding built-in connectors.</p><p>For more information about implementation details, see <a href="https://github.com/apache/pulsar/pull/6895">PR-6895</a>.</p><h3>Add Go Function heartbeat (and gRPC service) for production usage</h3><p>For more information about implementation details, see <a href="https://github.com/apache/pulsar/pull/6031">PR-6031</a>.</p><h3>Add custom property options to functions</h3><p>This PR allows users to set custom system properties while submitting functions. This can be used to pass credentials via a system property.</p><p>For more information about implementation details, see <a href="https://github.com/apache/pulsar/pull/6348">PR-6348</a>.</p><h3>Separate TLS configurations of function worker and broker</h3><p>For more information about implementation details, see <a href="https://github.com/apache/pulsar/pull/6602">PR-6602</a>.</p><h3>Add the ability to build consumers in functions and sources</h3><p>Previously, function and source context give their writers an ability to create publishers but not consumers. This PR fixes this issue.</p><p>For more information about implementation details, see <a href="https://github.com/apache/pulsar/pull/6954">PR-6954</a>.</p><h2>Pulsar SQL</h2><h3>Support KeyValue schema</h3><p>Previously, Pulsar SQL could not read the KeyValue schema data.</p><p>This PR adds KeyValue schema support for Pulsar SQL. It adds the prefix <code>key.</code> for the key field name and <code>value.</code> for the value field name.</p><p>For more information about implementation details, see <a href="https://github.com/apache/pulsar/pull/6325">PR-6325</a>.</p><h3>Support multiple Avro schema versions</h3><p>Previously, if you have multiple Avro schema versions for a topic, using the Pulsar SQL to query data from this topic will introduce some problems. With this change, You can evolve the schema of the topic and keep transitive backward compatibility of all schemas of the topic if you want to query data from this topic. </p><p>For more information about implementation details, see <a href="https://github.com/apache/pulsar/pull/4847">PR-4847</a>.</p><h2>Java client</h2><h3>Support waiting for inflight messages while closing a producer</h3><p>Previously, when you closed a producer, the pulsar-client immediately failed inflight messages even if it persisted successfully at the broker. Most of the time, users want to wait for those inflight messages rather than fail them. While the pulsar-client library did not provide a way to wait for inflight messages before closing the producer. This PR supports closing API with a flag where you can control waiting for inflight messages. With this change, you can close a producer by waiting for inflight messages and the pulsar-client does not fail those messages immediately.
Previously, when you closed a producer, the pulsar-client immediately failed inflight messages even if it persisted successfully at the broker. Most of the time, users want to wait for those inflight messages rather than fail them. While the pulsar-client library did not provide a way to wait for inflight messages before closing the producer. This PR supports closing API with a flag where you can control waiting for inflight messages. With this change, you can close a producer by waiting for inflight messages and the pulsar-client does not fail those messages immediately.</p><p>For more information about implementation details, see <a href="https://github.com/apache/pulsar/pull/6648">PR-6648</a>.</p><h3>Support loading TLS certs/key dynamically from input stream</h3><p>Previously, the pulsar-client provided TLS authentication support and the default TLS provider <code>AuthenticationTls</code> expected file path of cert and key files. However, there were use cases where it was difficult for user applications to store certs/key files locally for TLS authentication. This PR adds stream support in <code>AuthenticationTls</code> to provide X509Certs and PrivateKey which also perform auto-refresh when streaming changes in a given provider.</p><p>For more information about implementation details, see <a href="https://github.com/apache/pulsar/pull/6760">PR-6760</a>.</p><h3>Support returning sequence ID when throwing an exception for async send messages</h3><p>Previously, when sending messages asynchronously failed, an exception was thrown, but did not know which message was abnormal, and users did not know which messages needed to be retried. This PR makes changes supported on the client side. When throwing an exception, the sequenceId <code>org.apache.pulsar.client.api.PulsarClientException</code> is set.</p><p>For more information about implementation details, see <a href="https://github.com/apache/pulsar/pull/6825">PR-6825</a>.</p><h2>More information</h2><ul><li>To download Apache Pulsar 2.6.0, click <a href="https://pulsar.apache.org/en/download/">here</a>.</li><li>For more information about Apache Pulsar 2.6.0, see <a href="https://pulsar.apache.org/release-notes/#2.6.0">2.6.0 release notes</a> and <a href="https://github.com/apache/pulsar/pulls?q=milestone%3A2.6.0+-label%3Arelease%2F2.5.2+-label%3Arelease%2F2.5.1+">2.6.0 PR list</a>.</li></ul><p>If you have any questions or suggestions, contact us with mailing lists or slack.</p><ul><li><a href="mailto:users@pulsar.apache.org">users@pulsar.apache.org</a></li><li><a href="mailto:dev@pulsar.apache.org">dev@pulsar.apache.org</a></li><li>Pulsar slack channel: <a href="https://apache-pulsar.slack.com/">https://apache-pulsar.slack.com/</a></li><li>Self-registration at <a href="https://apache-pulsar.herokuapp.com/">https://apache-pulsar.herokuapp.com/</a></li></ul><p>Looking forward to your contributions to <a href="https://github.com/apache/pulsar">Pulsar</a>.</p>]]></content>
        <author>
            <name>Penghui Li</name>
            <uri>https://twitter.com/lipenghui6</uri>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Apache Pulsar 2.5.2]]></title>
        <id>/2020/05/19/Apache-Pulsar-2-5-2</id>
        <link href="https://pulsar.apache.com/blog/2020/05/19/Apache-Pulsar-2-5-2"/>
        <updated>2020-05-19T00:00:00.000Z</updated>
        <summary type="html"><![CDATA[We are proud to publish Apache Pulsar 2.5.2. This is the result of a huge effort from the community, with over 56 commits, general improvements and bug fixes.]]></summary>
        <content type="html"><![CDATA[<p>We are proud to publish Apache Pulsar 2.5.2. This is the result of a huge effort from the community, with over 56 commits, general improvements and bug fixes.</p><p>For detailed changes related to 2.5.2 release, refer to the <b><a href="/release-notes/#2.5.2">release notes</a></b> and the <b><a href="https://github.com/apache/pulsar/pulls?q=is:pr%20label:release/2.5.2%20is:closed">PR list for Pulsar 2.5.2</a></b>.</p><p>The following highlights some improved features and fixed bugs in this release.</p><h2>Implement AutoTopicCreation by namespace level override</h2><p>Introduce a new namespace policy <code>autoTopicCreationOverride</code>, which enables an override of broker <code>autoTopicCreation</code> settings on the namespace level. You can disable <code>autoTopicCreation</code> for the broker while allowing it on a specific namespace.</p><h2>Add customized deletionLag and threshold for offloading policies per namespace</h2><p>Support configuring <code>deletionLag</code> and threshold in the offloading policy on the namespace level to remove data from the offloaded tiered storage.</p><h2>Invalidate managed ledgers ZooKeeper cache instead of reloading on watcher triggered</h2><p>The ZooKeeper children cache is reloaded for z-nodes when topics are frequently created or deleted. This creates additional load on the ZooKeeper and the broker, slows down brokers and makes them less stable. In this release, <code>ZooKeeperManagedLedgerCache</code> is introduced to invalidate instead of reloading the ZooKeeper cache, when topics are created or deleted. This helps reduce pressures on the ZooKeeper.</p><h2>Respect retention policy when there is no traffic</h2><p>In previous releases, retention is checked when the ledger rollover happens. So if the traffic is stopped, the ledgers are not cleaned up even if all the messages are already acknowledged. In Pulsar 2.5.2, <code>retentionCheckIntervalInSeconds</code> is introduced to check if consumed ledgers need to be trimmed between intervals. If the value is set to 0 or a negative number, the system does not check the consumed ledgers.</p><h2>Bump Netty version to 4.1.48.Final</h2><p>The ZlibDecoders in Netty 4.1.x (before 4.1.46) allow for unbounded memory allocation while decoding a ZlibEncoded byte stream. An attacker could send a large ZlibEncoded byte stream to the Netty server, forcing the server to allocate all of its free memory to a single decoder. The bug is fixed in Netty <code>4.1.48.Final</code> .</p><h2>Increase timeout for loading topics</h2><p>Loading replicated topics is quite an expensive operation and involves global ZooKeeper lookups and the start of many sub-processes. In Pulsar 2.5.2, we increase the timeout for loading topics which have many replicated clusters to 60 seconds.</p><h2>Fix incorrect cursor state for cursor without consumers</h2><p>If consumers of a subscription are closed, the cursor is set to inactive. But the cursor is set to active during <code>PulsarStats.updateStats()</code> when the backlog size is less than <code>backloggedCursorThresholdEntries</code>. In Pulsar 2.5.2, we move the <code>checkBackloggedCursors()</code> from <code>ManagedLedger</code> to <code>Topic</code> and check the consumer list to fix this bug.</p><h2>Change non-durable cursor to active to improve performance</h2><p>In non-durable subscription mode, the cursor is not active, which leads to the written entries not being put into cache. This would degrade the reading performance. In Pulsar 2.5.2, we set the <code>NonDurableCursorImpl</code> to active and remove three override methods <code>setActive()</code>, <code>isActive()</code>, <code>setInactive()</code> to improve the reading performance.</p><h2>Add keystore configurations to TLS</h2><p>In Pulsar 2.5.2, we add keystore configurations to the TLS to allow users to define their own CA certificates while the internal communication uses an internal CA certificate. This change keeps the original TLS settings untouched, and adds new configurations in needed paths.</p><h2>Close producer when the topic does not exists</h2><p>In previous releases, when we create a producer for a non-existent topic, the <code>ProducerImpl</code> object is hanging in the dump. This leads to OOM in micro-service which by mistake tries to produce consistently to a non-existent topic. In Pulsar 2.5.2, we fix the bug in the following two aspects:</p><ul><li>Fix the exception handle for a non-existent topic.</li><li>Change state to <code>Close</code> when the producer gets the <code>TopicDoesNotExists</code> exception.</li></ul><h2>Fix <code>topicPublishRateLimiter</code> not effective after restarting broker</h2><p>In previous releases, when a publishing rate is configured on the namespace, it can limit the publishing rate. But when the broker is restarted, the limit expires. In Pulsar 2.5.2, this bug is fixed.</p><h2>Expose pulsar_out_bytes_total and pulsar_out_messages_total for namespace/subscription/consumer</h2><p>Add pulsar_out_bytes_total and pulsar_out_messages_total for the namespace, subscription, and consumer. This helps to avoid missing the rate to be computed in Prometheus or missing change of rates within the scraping interval.</p><h2>Fix <code>ttlDurationDefaultInSeconds</code> policy</h2><p>The TTL for namespaces should be retrieved from the broker configuration if it is not configured at namespace policies. In previous releases, the code only returns the value stored in namespace policies directly without judging if the TTL is configured or not. In Pulsar 2.5.2, we add a condition to test if TTL is configured at namespace policies. If not, the broker retrieves value stored in broker configuration and returns it as the output.</p><h2>Fix long field parse in GenricJsonRecord</h2><p>For messages sent in JSON schema, the long field is decoded as int if its value is smaller than <code>Integer.MAX_VALUE</code>. Otherwise, the long field is decoded as a string. Pulsar 2.5.2 introduces a field type check in GenericJsonRecord to fix this bug.</p><h2>Fix the leak of cursor reset if message encode fails in Avro schema</h2><p>If the Avro encode for a message fails after a few bytes are written, the cursor in the stream is not reset. The following <code>flush()</code>, which normally resets the cursor, is skipped if there is an exception. In Pulsar 2.5.2, we introduced a <code>flush()</code> in the finally block to fix this bug.</p><h2>Update topic partitions automatically</h2><p>In Pulsar 2.5.2, the C++ client supports previously-created producers and consumers to automatically update partitions when the partitions for a topic are updated.</p><ul><li>Add a <code>boost::asio::deadline_timer</code> to <code>PartitionedConsumerImpl</code> and <code>PartitionedProducerImpl</code> to register a lookup task to detect partition changes periodically.</li><li>Add an unsigned int configuration parameter to indicate the period of detecting partition changes.</li><li>Unlock the <code>mutex_</code> in <code>PartitionedConsumerImpl::receive</code> after <code>state_</code> were checked.</li></ul><h2>Fix default message ID in sent callback</h2><p>In previous releases, the <code>MessageId</code> in the callback is always the default value (<code>-1, -1, -1, -1</code>). In Pulsar 2.5.2, we remove the useless field <code>messageId</code> of <code>BatchMessageContainer::MessageContainer</code> and add the <code>const MessageId&amp;</code> argument to <code>batchMessageCallBack</code>. Therefore, we can get the correct message ID in the callback if the message is sent successfully.</p><h2>Fix message ID error if messages are sent to partitioned topics</h2><p>If messages are sent to a partitioned topic, the <code>partition</code> field of the message ID is always set to -1 because the <code>SendReceipt</code> command only contains the ledger ID and the entry ID. In Pulsar 2.5.2, we fix this bug by adding a <code>partition</code> field to <code>ProducerImpl</code> and setting the <code>partition</code> field of the message ID with it in the <code>ackReceived</code> method.</p><h2>Support Async mode for Pulsar Functions</h2><p>In previous releases, Pulsar Functions does not support the Async mode, such as the user passed in a Function in the following format:</p><pre><code>
Function&lt;I, CompletableFuture&lt;O&gt;&gt;

</code></pre><p>This kind of function is useful if the Pulsar Functions use RPCs to call external systems. Therefore, in Pulsar 2.5.2, we introduce Async mode support for Pulsar Functions.</p><h2>Fix localrunner netty dependency issue</h2><p>In Pulsar 2.5.2, we add a Log4j2 configuration file for pulsar-functions-local-runner to log to console by default. This helps troubleshoot the problem that Netty libraries are missing and the class is not found, when pulling in pulsar-functions-local-runner as a dependency and attempting to run Pulsar Functions locally.</p><h2>Fix SerDe validation of Pulsar Functions update</h2><p>In previous releases, the <code>outputSchemaType</code> field is improperly used to validate parameters for Pulsar Function updates. In fact, the <code>outputSerdeClassName</code> parameter should be used. In Pulsar 2.5.2, we fix this bug.</p><h2>Avoid pre-fetching too much data when offloading data to HDFS</h2><p>If too much data is pre-fetched when data is offloaded to HDFS, it may cause severe OOM. In Pulsar 2.5.2, the <code>managedLedgerOffloadPrefetchRounds</code> is introduced, which is used to set the maximum pre-fetch rounds for ledger reading for offloading data.</p><h2>JDBC sink handles null fields in schema</h2><p>JDBC sink does not handle <code>null</code> fields. The schema registered in Pulsar allows for it and the table schema in MySQL has a column of the same name. When messages are sent to the JDBC sink without that field, an exception is thrown. In Pulsar 2.5.2, the JDBC sink uses the <code>setColumnNull</code> method to properly reflect the null field value in the database row.</p><h2>Reference</h2><p>To download Apache Pulsar 2.5.2, click <a href="https://pulsar.apache.org/en/download/">here</a>.</p><p>If you have any questions or suggestions, contact us with mailing lists or slack.</p><ul><li><a href="mailto:users@pulsar.apache.org">users@pulsar.apache.org</a></li><li><a href="mailto:dev@pulsar.apache.org">dev@pulsar.apache.org</a></li><li>Pulsar slack channel: <a href="https://apache-pulsar.slack.com/">https://apache-pulsar.slack.com/</a></li><li>Self-registration at <a href="https://apache-pulsar.herokuapp.com/">https://apache-pulsar.herokuapp.com/</a></li></ul><p>Looking forward to your contributions to <a href="https://github.com/apache/pulsar">Pulsar</a>.</p>]]></content>
        <author>
            <name>Jia Zhai</name>
            <uri>https://twitter.com/Jia_Zhai</uri>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Apache Pulsar 2.5.1]]></title>
        <id>/2020/04/23/Apache-Pulsar-2-5-1</id>
        <link href="https://pulsar.apache.com/blog/2020/04/23/Apache-Pulsar-2-5-1"/>
        <updated>2020-04-23T00:00:00.000Z</updated>
        <summary type="html"><![CDATA[We are proud to publish Apache Pulsar 2.5.1. This is the result of a huge effort from the community, with over 130 commits and a long list of new features, general improvements and bug fixes.]]></summary>
        <content type="html"><![CDATA[<p>We are proud to publish Apache Pulsar 2.5.1. This is the result of a huge effort from the community, with over 130 commits and a long list of new features, general improvements and bug fixes.</p><p>For detailed changes related to 2.5.1 release, refer to the <b><a href="/release-notes/#2.5.1">release notes</a></b> and the <b><a href="https://github.com/apache/pulsar/pulls?q=is:pr%20label:release/2.5.1%20is:closed">PR list for Pulsar 2.5.1</a></b>.</p><p>The following justs highlights a tiny subset of new features.</p><h2>Refresh authentication credentials</h2><p>In Pulsar 2.5.1, two more methods are introduced in the single <code>AuthenticationState</code> interface credentials holder. This helps enhance the Pulsar authentication framework to support credentials that expire over time and need to be refreshed by forcing clients to re-authenticate.</p><p>Existing authentication plugins are unaffected. If a new plugin wants to support expiration, it just overrides the <code>isExpired()</code> method. The Pulsar broker ensures to periodically check the expiration status for the AuthenticationState of every <code>ServerCnx</code> object. You can also use the <code>authenticationRefreshCheckSeconds</code> setting to control the frequency of the expiration check.</p><h2>Upgrade Avro to 1.9.1</h2><p>The library used to handle logical datetime values has been changed from Joda-Time to JSR-310. For keeping forward compatibility, Pulsar java client uses Joda-Time conversion for logical datetime. To use JSR-310 conversion, you can enable it in the schema definition.</p><pre><code class="language-java">
AvroSchema.of(SchemaDefinition.builder()
.withJSR310ConversionEnabled(true)
.build()

</code></pre><p>:::note</p><p>By default, Avro 1.9.1 enables the JSR310 datetimes, which might introduce some regression problems if users use source codes generated by Avro compiler 1.8.x and the source codes contain datetimes fields. It is recommended to use Avro 1.9.x compiler to recompile.</p><p>:::</p><p>And, Avro may remove the Joda time support in the future. This may also be deleted in Pulsar in the future.</p><h2>Support unloading all partitions of a partitioned topic</h2><p>Before Pulsar 2.5.1, Pulsar supports unloading a non-partitioned topic or a partition of a partitioned topic. If there is a partitioned topic with too many partitions, users need to get all partitions and unload them one by one. In Pulsar 2.5.1, we support unloading all partitions of a partitioned topic.</p><h2>Supports evenly distributing topics count when splitting bundle</h2><p>In Pulsar 2.5.1, we introduce an option(<code>-balance-topic-count</code>) for bundle split. When setting this option to true, the given bundle is split into two parts and each part has the same amount of topics. In addition, we bring in a new Load Manager implementation named <code>org.apache.pulsar.broker.loadbalance.impl.BalanceTopicCountModularLoadManager</code>. The new Load Manager implementation splits the bundle with balance topics count.
You can enable this feature in the broker.conf:</p><pre><code>
defaultNamespaceBundleSplitAlgorithm=topic_count_equally_divide

</code></pre><p>If you use the Pulsar Admin to split a bundle, you can use following command to split bundle based on topics count:</p><pre><code>
bin/pulsar-admin namespaces split-bundle -b 0x00000000_0xffffffff --split-algorithm-name topic_count_equally_divide public/default

</code></pre><h2>Support KeyValue schema for Pulsar SQL</h2><p>Before Pulsar 2.5.1, Pulsar SQL cannot read the keyValue schema data. In Pulsar 2.5.1, we add the prefix <code>key.</code> for the key field name, add the prefix <code>value.</code> for the value field name. Therefore, Pulsar SQL can read the keyValue schema data.</p><h2>Update Netty version to <code>4.1.45.Final</code></h2><p>Netty 4.1.43 has a bug, which prevents it from using Linux native Epoll transport. This makes Pulsar brokers fail over to NioEventLoopGroup even when running on Linux. The bug is fixed in Netty  <code>4.1.45.Final</code> .</p><h2>Improve Key_Shared subscription message dispatching performance</h2><p>In Pulsar 2.5.1, to improve Key_Shared subscription message dispatching performance, we make the following operations for saving CPU usage which can improve non-batched message dispatch performance:</p><ul><li>Reduce making hash for the message key.</li><li>Reduce the number of finding consumers for message keys..</li></ul><h2>Add Joda time logical type conversion</h2><p>In Pulsar 2.5.1, Avro is upgraded to 1.9.x and the default time conversion is changed to JSR-310. For forwarding compatibility, we add the Joda time conversion in Pulsar 2.5.1 and enable it by default</p><h2>Support deleting inactive topic when subscriptions caught up</h2><p>Before Pulsar 2.5.1, Pulsar supported deleting inactive topics that have no active producers or subscriptions. In Pulsar 2.5.1, we expose inactive topic delete mode in <code>broker.conf</code> to delete inactive topics that have no active producers or consumers but all subscriptions of the topic are caught up. You can enable this feature in the broker.conf:</p><pre><code>
brokerDeleteInactiveTopicsMode=delete_when_subscriptions_caught_up

</code></pre><h2>Introduce maxMessagePublishBufferSizeInMB configuration to avoid broker OOM</h2><p>Before Pulsar 2.5.1, if a broker has a smaller direct memory (e.g. 2G) and runs pulsar-perf to write messages, the broker becomes unstable. Because the broker reads messages from the channel automatically and the ByteBuf cannot be released until the entry is written to Bookie successfully or the timeout expires.
In Pulsar 2.5.1, we introduce the <code>maxMessagePublishBufferSizeInMB</code> configuration to avoid broker OOM (Out of Memory). If the processing message size exceeds this value, the broker stops reading data from the connection. When the available size is greater than half of the maxMessagePublishBufferSizeInMB,  the broker starts automatically reading data from the connection. You can set up the publish buffer size in broker.conf:</p><pre><code>
# Max memory size for broker handling messages sending from producers.
# If the processing message size exceed this value, broker will stop read data
# from the connection. The processing messages means messages are sends to broker
# but broker have not send response to client, usually waiting to write to bookies.
# It&#x27;s shared across all the topics running in the same broker.
# Use -1 to disable the memory limitation. Default is 1/2 of direct memory.
maxMessagePublishBufferSizeInMB=

</code></pre><h2>Support BouncyCastle FIPS provider</h2><p>In Pulsar 2.5.1, Pulsar supports BC-FIPS (BouncyCastle FIPS) provider. Before Pulsar 2.5.1, Pulsar only supported BouncyCastle (BC) provider, and BC JARs are tied strongly into both the broker and the client code. Users fail to change from the BC provider to the BC-FIPS provider. This feature splits the BC dependency out into a separate module. Therefore, users can freely switch between the BC provider and the BC-FIPS provider.</p><h2>Allow tenant Admin to manage subscription permission</h2><p>In previous releases, we have added support to grant subscriber-permission to manage subscription based APIs. However, grant-subscription-permission API requires super-user access and it creates too much dependency on system-admin when many tenants want to grant subscription permission.
In Pulsar 2.5.1, through the Restful API or the Pulsar Admin, we allow each tenant Admin to manage subscription permission in order to reduce administrative efforts for super users.</p><h2>Allow to enable/disable delayed delivery for messages on namespace</h2><p>In Pulsar 2.5.1, we add the <code>set-delayed-delivery</code> and  <code>set-delayed-delivery-time</code>  policies for the namespace. Therefore, Pulsar 2.5.1 allows to enable or disable delayed delayed delivery for messages on namespace.</p><h2>Support offloader at namespace level</h2><p>In previous releases, the offload operation only had the cluster-level configuration. Users cannot set the offload configuration at the namespace level. In Pulsar 2.5.1, we support using the Pulsar Admin to set the offloader at the namespace level. </p><h2>Disallow sub auto creation by Admin when disabling topic auto creation</h2><p>In previous releases, when Auto topic creation is disabled in KoP, non-partitioned topics are created with Flink Pulsar Source. To fix this bug, in Pulsar 2.5.1, we change the admin code to disable sub auto creation by the Admin when Auto topic creation is disabled.</p><h2>Support Python 3.8 for Pulsar client</h2><p>In pulsar 2.5.1, we add <code>3.8 cp38-cp38</code> to support Python 3.8 for the Pulsar client. Therefore, users can install the Pulsar client on Python 3.8 .</p><h2>Provide another <code>libpulsarwithdeps.a</code> in Debian/RPM cpp client library</h2><p>Pulsar 2.5.1 mainly provides 2 additional pulsar c++ client libraries in Debian/RPM:</p><ul><li>pulsarSharedNossl (libpulsarnossl.so): it is similar to pulsarShared(libpulsar.so), and has no SSL statically linked.</li><li>pulsarStaticWithDeps(libpulsarwithdeps.a): it is similar to pulsarStatic(libpulsar.a), and is archived in the dependencies libraries of <code>libboost_regex</code>, <code>libboost_system</code>, <code>libcurl</code>, <code>libprotobuf</code>, <code>libzstd</code> and <code>libz</code> statically.</li></ul><h2>Reference</h2><p>To download Apache Pulsar 2.5.1, click <a href="https://pulsar.apache.org/en/download/">here</a>.
If you have any questions or suggestions, contact us with mailing lists or slack.</p><ul><li><a href="mailto:users@pulsar.apache.org">users@pulsar.apache.org</a></li><li><a href="mailto:dev@pulsar.apache.org">dev@pulsar.apache.org</a></li><li>Pulsar slack channel: <a href="https://apache-pulsar.slack.com/">https://apache-pulsar.slack.com/</a></li><li>Self-registration at <a href="https://apache-pulsar.herokuapp.com/">https://apache-pulsar.herokuapp.com/</a>
Looking forward to your contributions to <a href="https://github.com/apache/pulsar">Pulsar</a>.</li></ul>]]></content>
        <author>
            <name>Guangning E</name>
            <uri>https://twitter.com/tuteng3</uri>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Announcing: The Apache Pulsar 2020 User Survey Report]]></title>
        <id>/2020/03/17/announcing-the-apache-pulsar-2020-user-survey-report</id>
        <link href="https://pulsar.apache.com/blog/2020/03/17/announcing-the-apache-pulsar-2020-user-survey-report"/>
        <updated>2020-03-17T00:00:00.000Z</updated>
        <summary type="html"><![CDATA[For the first time ever, the Apache Pulsar PMC team is publishing a user survey report.]]></summary>
        <content type="html"><![CDATA[<p>For the first time ever, the Apache Pulsar PMC team is publishing a user survey report.
<strong>The 2020 Apache Pulsar User Survey Report</strong> reveals Pulsar’s accelerating rate of global
adoption, details how organizations are leveraging Pulsar to build real-time streaming
applications, and highlights key features on Pulsar’s product roadmap.</p><p><img src="/img/pulsar-user-ban.jpg"/></p><p>Pulsar adoption has largely been driven by the market’s increased demand for real-time,
data-enabled technologies. While companies have tried to leverage monolithic messaging
systems to build-out real-time offerings, they’ve hit major roadblocks. Ultimately, these
technologies are not equipped to provide the scale or reliability that mission-critical
applications require.</p><p>As a result, companies have sought-out Apache Pulsar for its cloud-native, distributed
messaging and streaming platform capabilities. From asynchronous applications to core
business applications to ETL, companies are increasingly leveraging Pulsar to develop
real-time applications.</p><p>Pulsar has received global adoption from major technology companies such as Verizon Media,
Narvar, Overstock, Nutanix, Yahoo! JAPAN, Tencent, OVHCloud, and Clever Cloud, who rely on
its ability to deliver on performance, scalability, and resiliency. As the Pulsar project
and community garner increasing attention, we’re excited to share the <strong>2020 Apache Pulsar User Survey Report</strong>.</p><p><img src="/img/pulsar-adoption.png"/></p><p>In the 2020 Apache Pulsar User Survey Report, we hear from 165 users and learn how their
companies are leveraging Pulsar’s cloud-native, multi-layer design architecture, built-in
multi-tenancy, and multi-cluster replication, to build scalable real-time offerings. This
report details insights and use cases on how organizations are deploying Pulsar today.</p><p>The report also reveals Pulsar’s top-used features, its most popular applications, and how
it is delivering scalable, reliable, real-time streaming solutions for organizations. In
this quotation from Qiang Fei, Tech Lead for Tencent, we see how <a href="https://streamnative.io/whitepaper/case-studay-apache-pulsar-tencent-billing/">one organization is leveraging Pulsar to improve their offering</a>:</p><blockquote><p>Pulsar provides us with a highly consistent and highly reliable distributed message queue that
fits well in our financial use cases. Multi-tenant and storage separation architecture design
greatly reduces our operational and maintenance overhead. We have used Pulsar on a very large
scale in our organization and we are impressed that Pulsar is able to provide high consistency
while supporting high concurrent client connections.</p><ul><li>Qiang Fei, Tech Lead at Tencent</li></ul></blockquote><p>From its built-in multi-tenancy, which reduces architectural complexity and enables organizations
to scale, to its multi-datacenter replication, which allows Pulsar to handle data center failures,
we see how Pulsar has evolved into a robust and differentiated messaging and streaming platform.
The report also reveals some of the community-driven features on Pulsar’s product roadmap for 2020
and beyond. To find out more, <a href="https://streamnative.io/whitepaper/oss-apache-pulsar-user-survey-report-2020/">download the report today</a>.</p><p>Join us for the first-ever Apache Pulsar Summit on August 26, 2020, in San Francisco, CA.
More details on the Summit to come!</p>]]></content>
        <author>
            <name>Sijie Guo</name>
            <uri>https://twitter.com/sijieg</uri>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Pulsar milestone celebration—200 contributors!]]></title>
        <id>/2019/12/20/pulsar-milestone-200-contributors</id>
        <link href="https://pulsar.apache.com/blog/2019/12/20/pulsar-milestone-200-contributors"/>
        <updated>2019-12-20T00:00:00.000Z</updated>
        <summary type="html"><![CDATA[Dear Apache Pulsar enthusiast,]]></summary>
        <content type="html"><![CDATA[<p>Dear Apache Pulsar enthusiast,</p><p>As we know, when assessing the health of an open-source community, it is tempting to focus on various quantitative metrics, for example, activity, size (contributors), demographics, diversity, and so on, among which the number of contributors is a key metric for measuring the health and popularity of a project and a way to inform the trends. </p><p>And today, we are very proud to see that <strong>Apache Pulsar has attracted its 200th contributor!</strong> It is an important milestone for our community growth.</p><p>Over the years, there’s been an upward trend that more organizations embracing real-time data and stream processing, and Pulsar is the key component of that shift. As an open-source distributed pub-sub messaging system originally created at Yahoo! and graduated as a Top-Level Project (TLP) in September 2018, Pulsar has launched 79 releases, attracted 4100+ commits from 200 contributors, and received 4.6k+ stars, 1.2k+ forks, and 1.3k+ Slack users up to now.</p><p><img src="/img/p-200.png"/></p><p>This achievement is worth celebrating, and at the same time, we would like to <strong>express sincere gratitude to you</strong> for making what Pulsar is today and shape what Pulsar will be tomorrow.</p><p>Pulsar aims to empower the next generation of event streaming systems by delivering a unified solution that connects, stores and processes real-time event streams. Going forward, we will be continuously dedicated to making Pulsar as a highly flexible, scalable and reliable product and creating a welcoming and sustainable community where Pulsar and you can thrive together.</p><p><img src="/img/cooperation.png"/></p><p>P.S. want to be a Pulsar contributor? </p><p>Get started today by <a href="http://pulsar.apache.org/en/contributing/">reading contribution guidelines</a> and <a href="https://github.com/apache/pulsar">submitting a PR</a>, any contribution on codes, docs or other is highly appreciated. Thank you.</p>]]></content>
        <author>
            <name>Yu Liu</name>
            <uri>https://twitter.com/Anonymitaet1</uri>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Pulsar Summit San Francisco 2020 CFP is now open]]></title>
        <id>/2019/12/18/Pulsar-summit-cfp</id>
        <link href="https://pulsar.apache.com/blog/2019/12/18/Pulsar-summit-cfp"/>
        <updated>2019-12-18T00:00:00.000Z</updated>
        <summary type="html"><![CDATA[Pulsar Summit is an annual conference dedicated to Apache Pulsar community, bringing together an international audience of CTOs/CIOs, developers, data architects, data scientists, Apache Pulsar committers/contributors, and the messaging and streaming community, to share experiences, exchange ideas and knowledge about Pulsar and its growing community, and receive hands-on training sessions led by Pulsar experts.]]></summary>
        <content type="html"><![CDATA[<p>Pulsar Summit is an annual conference dedicated to Apache Pulsar community, bringing together an international audience of CTOs/CIOs, developers, data architects, data scientists, Apache Pulsar committers/contributors, and the messaging and streaming community, to share experiences, exchange ideas and knowledge about Pulsar and its growing community, and receive hands-on training sessions led by Pulsar experts.</p><p>We are excited to announce that the first Pulsar Summit will be held in San Francisco in April, 2020. Talk submissions, pre-registration, and sponsorship opportunities are now open for the conference!</p><h2>Speak at Pulsar Summit</h2><p>Presentations and lightning talks are accepted for speaking proposals. Suggested topics cover Pulsar use cases, operations, technology deep dive, and ecosystem. Submissions are open until <strong>January 31, 2020</strong>.</p><p>If you are unsure about your proposal, or want some feedback or advice in general, please do not hesitate to reach out to <a href="mailto:sf-2020@pulsar-summit.org">sf-2020@pulsar-summit.org</a>. We are happy to help out! Further details are available on the <a href="https://pulsar-summit.org/call-for-presentations/">CFP website</a>.</p><h2>Dates to remember</h2><ul><li>CFP opens: December 15, 2019</li><li>CFP closes: January 31, 2020 - 23:59 PST</li><li>CFP notification: February 21, 2020</li><li>Schedule announcement: February 24, 2020</li></ul><h2>Speaker benefits</h2><p>When your speaking proposal is approved, you will enjoy the following benefits:</p><ul><li>Full conference pass.</li><li>Exclusive swag only available to speakers.</li><li>Expand your network and raise your profile in the Pulsar community.</li><li>A professionally produced video of your presentation.</li><li>Your name, title, company, and bio will be featured on the Pulsar Summit San Francisco 2020 website.</li><li>Your session will be added to the Pulsar Summit YouTube Channel and promoted on Twitter and LinkedIn.</li></ul><h2>Pre-registration</h2><p>If you are interested in attending Pulsar Summit San Francisco 2020, we’d like to hear from you with your <a href="https://pulsar-summit.org/pre-registration/">pre-registration</a>. Your ideas are very important to us, and we will prepare the content accordingly. </p><p>After you submit the pre-registration form, you will be added to the waitlist of Pulsar Summit San Francisco 2020. Once the registration is open, you will be notified with an email.</p><h2>Sponsor Pulsar Summit</h2><p>Pulsar Summit is a community run conference and your support is needed. Sponsoring this event will provide a great opportunity for your organization to further engage with the Apache Pulsar community. <a href="mailto:partners@pulsar-summit.org">Contact us</a> to learn more.</p><p>Help us make #PulsarSummit 2020 a big success by spreading the word and submitting your proposal! Follow us on Twitter (<a href="https://twitter.com/PulsarSummit">@pulsarsummit</a>) to receive the latest updates of the conference!</p><p>Hope to see you at Pulsar Summit San Francisco 2020!</p>]]></content>
        <author>
            <name>Jennifer Huang</name>
            <uri>https://twitter.com/Jennife06125739</uri>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Apache Pulsar 2.4.2]]></title>
        <id>/2019/12/04/Apache-Pulsar-2-4-2</id>
        <link href="https://pulsar.apache.com/blog/2019/12/04/Apache-Pulsar-2-4-2"/>
        <updated>2019-12-04T00:00:00.000Z</updated>
        <summary type="html"><![CDATA[We are proud to publish Apache Pulsar 2.4.2. Thank the great efforts from Apache Pulsar community with over 110 commits, covering improvements and bug fixes.]]></summary>
        <content type="html"><![CDATA[<p>We are proud to publish Apache Pulsar 2.4.2. Thank the great efforts from Apache Pulsar community with over 110 commits, covering improvements and bug fixes.</p><p>For detailed changes related to 2.4.2 release, refer to <b><a href="/release-notes/#2.4.2">release notes</a></b>.</p><p>I will highlight some improvements and bug fixes in this blog.</p><h2>Use classLoaders to load Java functions</h2><p>In Pulsar 2.4.2, windowed functions can work well whether Java Functions instances use shaded JAR or classLoaders, and functionClassLoader is set correctly when the <code>--output-serde-classname</code> option is enabled.</p><p>Before Pulsar 2.4.2, Java Functions instances are started with a shaded JAR, and different classLoaders are used to load the internal Pulsar code, user code, and the interfaces that the two interacts with each other. This change results in two issues:</p><ul><li>The windowed functions do not work well if Java Functions instances use classLoaders. </li><li>When using the <code>--output-serde-classname</code> option, functionClassLoader is not set correctly.  </li></ul><h2>Start Broker with Functions worker</h2><p>In Pulsar 2.4.2, we can start Broker with Functions worker when broker client is enabled with TLS. Before Pulsar 2.4.2, when we run Functions worker with the broker, it checks whether TLS is enabled in the <code>function_worker.yml</code> file. If TLS is enabled, it uses TLS port. However, when TLS is enabled on Functions worker, it checks the <code>broker.conf</code>. Since Functions worker runs with the broker, it makes sense to check the <code>broker.conf</code> as the single source of truth about whether or not to use TLS. </p><h2>Add error code and error message when a key does not exist</h2><p>In Pulsar Functions, BookKeeper is supported to store the state of Functions. When users attempt to fetch a key that does not exist from function state, an NPE(NullPointerException) error occurs. In Pulsar 2.4.2, we add error code and error message for the case when a key does not exist.</p><h2>Deduplication</h2><p>Deduplication removes messages based on the the largest sequence ID that pre-persisted. If an error is persisted to BookKeeper, a retry attempt is “deduplicated” with no message ever getting persisted. In version 2.4.2, we fix the issue from the following two aspects:                                                                                              </p><ul><li>Double check the pending messages and return error to the producer when the duplication status is uncertain. For example, when a message is still pending.</li><li>Sync back the lastPushed map with the lastStored map after failures.</li></ul><h2>Consume data from the earliest location</h2><p>In Pulsar 2.4.2, we add <code>--subs-position</code> for Pulsar Sinks, so users can consume data from the latest and earliest locations. Before 2.4.2 release, data in topics is consumed from the latest location in Pulsar Sinks by default, and users can not consume the earliest data in sink topic. </p><h2>Close previous dispatcher when the subscription type changes</h2><p>In Pulsar 2.4.2, when the type of a subscription changes, a new dispatcher is created, and the old dispatcher is closed, thus avoiding memory leaks. Before 2.4.2, when the subscription type of a topic changes, a new dispatcher is created and the old one is discarded, yet not closed, which causes memory leaks. If the cursor is not durable, the subscription is closed and removed from the topic when all consumers are removed. The dispatcher should be closed at this time. Otherwise, RateLimiter instances are not garbage collected, which results in a memory leak. </p><h2>Select an active consumer based on the subscription order</h2><p>In Pulsar 2.4.2, the active consumer is selected based on the subscription order. The first consumer in the consumer list is selected as an active consumer without sorting. Before 2.4.2, the active consumer is selected based on the priority level and consumer name. In this case, the active consumer joins and leaves, and no consumer is actually elected as &quot;active&quot; or consumes messages. </p><h2>Remove failed stale producer from the connection</h2><p>In Pulsar 2.4.2, failed producer is removed correctly from the connection. Before Pulsar 2.4.2, broker cannot clean up the old failed producer correctly from the connection. When broker tries to clean up <code>producer-future</code> in the failed producer, it removes the newly created <code>producer-future</code> rather than the old failed producer, and the following error occurs in broker.</p><pre><code class="language-text">
17:22:00.700 [pulsar-io-21-26] WARN  org.apache.pulsar.broker.service.ServerCnx - [/1.1.1.1:1111][453] Producer with id persistent://prop/cluster/ns/topic is already present on the connection

</code></pre><h2>Add new APIs for schema</h2><p>In Pulsar 2.4.2, we add the following APIs for schema:</p><ul><li><code>getAllVersions</code>: return the list of schema versions for a given topic.</li><li><code>testCompatibility</code>: be able to test the compatibility for a schema without registering it.</li><li><code>getVersionBySchema</code>: provide a schema definition and provide the schema version for it.</li></ul><h2>Expose <code>getLastMessageId()</code> method in consumerImpl</h2><p>In Pulsar 2.4.2, we expose <code>getLastMessageId()</code> method in consumerImpl. It benefits users when they want to know the lag messages, or only consume messages before the current time.                                                     </p><h2>Add new <code>send()</code> interface in C++/Go</h2><p>In Pulsar 2.4.2, we add new <code>send()</code> interface in C++/Go, so the <code>MessageID</code> will be returned to users. The logic is consistent with that in Java. In Java client, the <code>MessageId send(byte[] message)</code> returns <code>MessageId</code> for users.</p><h2>Consumer background tasks are cancelled after subscription failures</h2><p>In Pulsar 2.4.2, we ensure that consumer background tasks are cancelled after subscription failures. Before 2.4.2, some background consumer tasks are started in the ConsumerImpl constructor though these tasks are not cancelled if the consumer creation fails, leaving active references to these objects. </p><h2>Delete topics attached with regex consumers</h2><p>In Pulsar 2.4.2, we can delete topics attached with a regex consumer. The followings are detailed methods.</p><ul><li>Add a flag in CommandSubscribe so that a regex consumer will never trigger the creation of a topic.</li><li>Subscribe to a non-existing topic. When a specific error occurs, the consumer is interpreted as a permanent failure and thus stopping retrying.</li></ul><p>Before 2.4.2, it&#x27;s not possible to delete topics when there is a regex consumer attached to them. The reason is that the regex consumer will immediately reconnect and re-create the topic. </p><h2>Reference</h2><p>Download Pulsar 2.4.2 <a href="https://pulsar.apache.org/en/download/">here</a>. </p><p>If you have any questions or suggestions, contact us with mailing lists or slack. </p><ul><li><a href="mailto:users@pulsar.apache.org">users@pulsar.apache.org</a> </li><li><a href="mailto:dev@pulsar.apache.org">dev@pulsar.apache.org</a> </li><li>Pulsar slack channel: <a href="https://apache-pulsar.slack.com/">https://apache-pulsar.slack.com/</a></li><li>You can self-register at <a href="https://apache-pulsar.herokuapp.com/">https://apache-pulsar.herokuapp.com/</a></li></ul><p>Looking forward to your contributions to <a href="https://github.com/apache/pulsar">Pulsar</a>.</p>]]></content>
        <author>
            <name>Xiaolong Ran</name>
            <uri>https://twitter.com/wolf4j1</uri>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Apache Pulsar 2.4.0]]></title>
        <id>/2019/07/05/Apache-Pulsar-2-4-0</id>
        <link href="https://pulsar.apache.com/blog/2019/07/05/Apache-Pulsar-2-4-0"/>
        <updated>2019-07-05T00:00:00.000Z</updated>
        <summary type="html"><![CDATA[We are glad to publish Apache Pulsar 2.4.0. This is the result of a huge]]></summary>
        <content type="html"><![CDATA[<p>We are glad to publish Apache Pulsar 2.4.0. This is the result of a huge
effort from the community, with over 460 commits and a long list of new features,
general improvements and bug fixes.</p><p>Check out the <b><a href="/release-notes/#2.4.0">release notes</a></b> for a detailed list of
the changes, with links to the relevant pull requests, discussions and documentation.</p><p>Regarding new features introduced, I just want to highlight here a tiny subset of them:</p><h3>Delayed message delivery</h3><p>It&#x27;s now possible to send a delayed message by Pulsar producer, and a delayed message will be
available after a delay time.</p><p>The Java code for a client using delayed messages delivery looks as follows:</p><pre><code class="language-java">
producer.newMessage().value(&quot;delayed message&quot;).deliverAfter(10, TimeUnit.SECONDS).send()

</code></pre><p>:::note</p><ol><li>Messages are only delayed on shared subscriptions, other subscriptions will deliver immediately.</li><li>Delayed messages are sent individually even if you enable message batching on producer.</li></ol><p>:::</p><h3>Go Functions</h3><p>Before 2.4.0 release, Java and Python are supported to write Pulsar Functions. Now, you can
use Go to write Pulsar Functions, the following is an example of
a Pulsar Function written in Go.</p><pre><code class="language-go">
import (
    &quot;fmt&quot;
    &quot;context&quot;

    &quot;github.com/apache/pulsar/pulsar-function-go/pf&quot;
)

func HandleRequest(ctx context.Context, in []byte) error {
    fmt.Println(string(in) + &quot;!&quot;)
    return nil
}

func main() {
    pf.Start(HandleRequest)
}

</code></pre><h3>Key_Shared subscription</h3><p>A new subscription mode <code>Key_shared</code> is introduced in 2.4.0. In <code>Key_shared</code> subscription mode,
one partition could have several consumers to consume messages in parallelism and ensure messages
with the same key are distributed to a consumer in order.
Here is <a href="http://pulsar.apache.org/docs/en/concepts-messaging/#key_shared">architecture</a>
for Key_Shared.</p><p>The following is an example to use <code>Key_shared</code> subscription:</p><pre><code class="language-java">
client.newConsumer()
        .topic(&quot;topic&quot;)
        .subscriptionType(SubscriptionType.Key_Shared)
        .subscriptionName(&quot;sub-1&quot;)
        .subscribe();

</code></pre><h3>Schema versioning</h3><p>Before 2.4.0 release, Avro schema used one schema for both writer schema and reader schema.
Multiple schemas version is supported now.</p><p>With multiple schemas, a producer can send messages with different schema versions and a consumer
can read messages with different schemas.</p><p>In 2.4.0 release, <code>FORWARD_TRANSITIVE</code>, <code>BACKWARD_TRANSITIVE</code> and <code>FULL_TRANSITIVE</code> compatibility
strategies are added to check the compatibility with all existing schema version.</p><h3>Replicated subscription</h3><p>In 2.4.0 release, a mechanism is added to keep subscription state in sync, within a sub-second timeframe,
in the context of a topic that is being asynchronously replicated across multiple geographical
regions. Here is <a href="https://github.com/apache/pulsar/wiki/PIP-33%3A-Replicated-subscriptions">architecture</a>
for replicated subscription.</p><p>The following is an example to use replicated subscription:</p><pre><code class="language-java">
Consumer&lt;String&gt; consumer = client.newConsumer(Schema.STRING)
            .topic(&quot;my-topic&quot;)
            .subscriptionName(&quot;my-subscription&quot;)
            .replicateSubscriptionState(true)
            .subscribe();

</code></pre><h3>New IO connectors</h3><p>A new batch of connectors is added, including Flume, Redis sink, Solr sink, RabbitMQ sink.
The following lists builtin <a href="http://pulsar.apache.org/docs/en/io-connectors/">connectors</a>
that Pulsar supports.</p><h3>Security</h3><p>In 2.4.0 release, Kerberos is supported in Apache Pulsar broker and client.
To enable Kerberos authentication, refer to the <a href="http://pulsar.apache.org/docs/en/security-kerberos/">document</a>.</p><p>Also added role based Pulsar Function authentication and authorization.</p><h2>Conclusion</h2><p>If you want to download Pulsar 2.4.0, click <a href="/download">here</a>. You can send any questions or suggestions
to our mailing lists, contribute to Pulsar on <a href="https://github.com/apache/pulsar">GitHub</a> or join
the Apache Pulsar community on <a href="https://apache-pulsar.herokuapp.com/">Slack</a>.</p>]]></content>
        <author>
            <name>Penghui Li</name>
            <uri>https://twitter.com/lipenghui6</uri>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Apache Pulsar 2.3.0]]></title>
        <id>/2019/02/20/Apache-Pulsar-2-3-0</id>
        <link href="https://pulsar.apache.com/blog/2019/02/20/Apache-Pulsar-2-3-0"/>
        <updated>2019-02-20T00:00:00.000Z</updated>
        <summary type="html"><![CDATA[The Apache Pulsar PMC is happy to announce the release of Pulsar 2.3.0. This]]></summary>
        <content type="html"><![CDATA[<p>The Apache Pulsar PMC is happy to announce the release of Pulsar 2.3.0. This
is the result of huge effort from the community, with over 480 commits and
a long list of new features, general improvements and bug fixes.</p><p>These improvements have been across the board in all of Pulsar components,
from new messaging features, to improved usability for Pulsar Functions
and Pulsar IO.</p><p>Check out the official <b><a href="/release-notes/#2.3.0">release notes</a></b> for a
detailed list of the changes, with links to the relevant pull-requests,
discussions and documentation.</p><p>Regarding new features introduced, I just want to highlight here a tiny
subset of them:</p><h3>Pulsar functions in Kubernetes</h3><p>It&#x27;s now possible to use Kubernetes as the scheduler for Pulsar Functions.</p><p>When a Pulsar cluster is configured to use Kubernetes, submitting a
function, using CLI tools or REST API, will cause the function instances
to be submitted as Kubernetes pods rather than running as processes
or threads within the Pulsar functions worker.</p><p>With this runtime manager, it&#x27;s possible to set quota on CPU/Mem and
have Kubernetes assign the required resources and enforce isolation
between different instances and functions.</p><h3>New Pulsar IO connectors:</h3><p>A new batch of connectors was added, including MongoDB, Elastic Search,
HBase and local files source and sink.</p><p>We introduce support for doing <a href="https://en.wikipedia.org/wiki/Change_data_capture">Change-Data-Capture</a>
with <a href="https://debezium.io/">Debezium</a>. This allows to record all
the update from a database into a Pulsar topic and use it for replication,
streaming jobs, cache updating, etc..</p><p>With Pulsar IO, Debezium will run as a regular Pulsar IO source,
completely managed by Pulsar. Users can easily submit a Debezium
builtin connector to a Pulsar cluster and start feeding data
from a long list of supported databases like MySQL, MongoDB,
PostgreSQL, Oracle and SQL Server.</p><p>Check out the <a href="/docs/io-cdc">Debezium connector</a> documentation for how
to get started in capturing database changes.</p><h3>Token Authentication</h3><p>Token Authentication provides a very simple and secure method of authentication for Pulsar.
This is based on <a href="https://jwt.io/">JSON Web Tokens</a>.</p><p>With tokens authentication, a client only needs to provide a single credential, or &quot;token&quot;, in the
form of an opaque string provided by either the system administrator or some automated service.</p><p>The Java code for a client using token authentication will look like:</p><pre><code class="language-java">
PulsarClient client = PulsarClient.builder()
    .serviceUrl(&quot;pulsar://broker.example.com:6650/&quot;)
    .authentication(
        AuthenticationFactory.token(&quot;eyJhbGciOiJIUzI1NiJ9.eyJzdWIiOiJKb2UifQ.ipevRNuRP6HflG8cFKnmUPtypruRC4fb1DWtoLL62SY&quot;)
    .build();

</code></pre><p>See <a href="/docs/security-token-client">Client Authentication using tokens</a> for a complete walk through
and instructions on how to set it up and manage it.</p><h3>Schema support in Python client library</h3><p>This feature adds a Python idiomatic way to declare the schema
of a producer or consumer and integrates directly with the Pulsar
schema registry.</p><pre><code class="language-python">
import pulsar
from pulsar.schema import *

class Example(Record):
    a = String()
    b = Integer()
    c = Boolean()

producer = client.create_producer(
                    topic=&#x27;my-topic&#x27;,
                    schema=AvroSchema(Example) )

producer.send(Example(a=&#x27;Hello&#x27;, b=1))

</code></pre><p>The above example will make the producer <code>Example</code> schema to be
validated by broker when we try to publish on <code>my-topic</code>. If the
topic has a schema that is incompatible, the producer creation will
fail.</p><p>Currently, the Python schema support Avro and JSON, in addition to
regular types like <code>str</code> and <code>bytes</code>.</p><p>The complete documentation is available at <a href="/docs/client-libraries-python/#schema">Python schema</a>.</p><h3>Function state API in Python</h3><p>From 2.3.0, Python function can access the state in as similar
way as Java functions, through the context object.</p><pre><code class="language-python">
import pulsar

# The classic ExclamationFunction that appends an
# exclamation at the end of the input
class WordCountFunction(pulsar.Function):
    def process(self, input, context):
        for word in input.split():
            context.incr_counter(word, 1)
        return input + &quot;!&quot;

</code></pre><p>Available methods for state management in the context object are:</p><pre><code class="language-python">
def incr_counter(self, key, amount):
  &quot;&quot;incr the counter of a given key in the managed state&quot;&quot;

def get_counter(self, key):
  &quot;&quot;&quot;get the counter of a given key in the managed state&quot;&quot;&quot;

def put_state(self, key, value):
  &quot;&quot;&quot;update the value of a given key in the managed state&quot;&quot;&quot;

def get_state(self, key):
  &quot;&quot;&quot;get the value of a given key in the managed state&quot;&quot;&quot;

</code></pre><h2>Conclusion</h2><p>Please <a href="/download">download</a> Pulsar 2.3.0 and report feedback, issues or any comment into our mailing lists,
slack channel or Github page. (<a href="/contact">Contact page</a>)</p>]]></content>
        <author>
            <name>Matteo Merli</name>
            <uri>https://twitter.com/merlimat</uri>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Apache Pulsar 2.1.0-incubating]]></title>
        <id>/2018/08/06/Apache-Pulsar-2-1-0</id>
        <link href="https://pulsar.apache.com/blog/2018/08/06/Apache-Pulsar-2-1-0"/>
        <updated>2018-08-06T00:00:00.000Z</updated>
        <summary type="html"><![CDATA[We are glad to present the new 2.1.0-incubating release of Pulsar.]]></summary>
        <content type="html"><![CDATA[<p>We are glad to present the new 2.1.0-incubating release of Pulsar.
This release is the culmination of 2 months of work that have
brought multiple new features and improvements to Pulsar. </p><p>In Pulsar 2.1 you&#x27;ll see:</p><ul><li><a href="/docs/io-overview">Pulsar IO</a> connector framework and a list of <a href="/docs/io-connectors">builtin connectors</a></li><li><a href="https://github.com/apache/incubator-pulsar/wiki/PIP-17:-Tiered-storage-for-Pulsar-topics">PIP-17</a>: <a href="/docs/concepts-tiered-storage">Tiered Storage</a></li><li>Pulsar <a href="/docs/functions-state">Stateful Functions</a></li><li><a href="/docs/client-libraries-go">Go Client</a></li><li><a href="https://github.com/apache/incubator-pulsar/blob/v2.1.0-incubating/pulsar-client-schema/src/main/java/org/apache/pulsar/client/impl/schema/AvroSchema.java">Avro</a>
and <a href="https://github.com/apache/incubator-pulsar/blob/v2.1.0-incubating/pulsar-client-schema/src/main/java/org/apache/pulsar/client/impl/schema/ProtobufSchema.java">Protobuf</a> Schemas</li></ul><p>For details information please check the detailed <a href="/release-notes/#2.1.0-incubating">release notes</a> and <a href="/versions">2.1.0 documentation</a>.</p><p>We&#x27;ll provide a brief summary of these features in the section below.</p><h2>Pulsar IO</h2><p>Since Pulsar 2.0, we introduced a serverless inspired lightweight computing framework <a href="/docs/functions-overview">Pulsar Functions</a>,
providing the easiest possible way to implement application-specific in-stream processing logic of any complexity. A lot of developers
love Pulsar Functions because they require minimal boilerplate and are easy to reason about.</p><p>In Pulsar 2.1, we continued following this &quot;simplicity first&quot; principle on developing Pulsar. We developed this IO (input/output) connector
framework on top of Pulsar Functions, to simplify getting data in and out of Apache Pulsar. You don&#x27;t need to write any single line of code.
All you need is prepare a configuration file of the system your want to connect to, and use Pulsar admin
CLI to submit a connector to Pulsar. Pulsar will take care of all the other stuffs, such as fault-tolerance, rebalancing and etc.</p><p>There are 6 built-in connectors released in 2.1 release. They are:</p><ul><li><a href="/docs/io-aerospike/">Aerospike Connector</a></li><li><a href="/docs/io-cassandra/">Cassandra Connector</a></li><li><a href="/docs/io-kafka/">Kafka Connector</a></li><li><a href="/docs/io-kinesis/">Kinesis Connector</a></li><li><a href="/docs/io-rabbitmq/">RabbitMQ Connector</a></li><li><a href="/docs/io-twitter/">Twitter Firehose Connector</a> </li></ul><p>You can follow <a href="/docs/io-quickstart">the tutorial</a> to try out Pulsar IO on connecting Pulsar with <a href="http://cassandra.apache.org/">Apache Cassandra</a>.</p><p>More connectors will be coming in future releases. If you are interested in contributing a connector to Pulsar, checkout the guide on <a href="/docs/io-develop">Developing Connectors</a>.
It is as simple as writing a Pulsar function.</p><h2>Tiered Storage</h2><p>One of the advantages of Apache Pulsar is <a href="https://streaml.io/blog/pulsar-segment-based-architecture">its segment storage</a> using <a href="https://bookkeeper.apache.org/">Apache BookKeeper</a>. You can store a topic backlog as large as you want.
When the cluster starts to run out of space, you just add another storage node, and the system will automatically
pickup the new storage nodes and start using them without rebalancing partitions. However, this can start to get expensive after a while.</p><p>Pulsar mitigates this cost/size trade-off by providing Tiered Storage. Tiered Storage turns your Pulsar topics into real <em>infinite</em> streams,
by offloading older segments into a long term storage, such as AWS S3, GCS and HDFS, which is designed for storing cold data. To the end user,
there is no perceivable difference between consuming streams whose data is stored in BookKeeper or in long term storage. All the underlying
offloading mechanisms and metadata management are transparent to applications.</p><p>Currently <a href="https://aws.amazon.com/s3/">S3</a> is supported in 2.1. More offloaders (such as Google GCS, Azure Blobstore, and HDFS) are coming
in future releases.</p><p>If you are interested in this feature, you can checkout more details <a href="/docs/cookbooks-tiered-storage">here</a>.</p><h2>Stateful Function</h2><p>The greatest challenge that stream processing engines face is managing <em>state</em>. So does Pulsar Functions. As the goal for Pulsar Functions
is to simplify developing stream native processing logic, we also want to provide an easier way for Pulsar Functions to manage their state.
We introduced a set of <a href="/docs/functions-state/#api">State API</a> for Pulsar Functions to store their state. It integrates with the table service
in Apache BookKeeper for storing the state.</p><p>It is released as a developer preview feature in Pulsar Functions Java SDK. We would like to collect feedback to improve it in future releases.</p><h2>Schemas</h2><p>Pulsar 2.0 introduces native support for schemas in Pulsar. It means you can declare how message data looks and have Pulsar enforce that
producers can only publish valid data on the topics. In 2.0, Pulsar only supports <code>String</code>, <code>bytes</code> and <code>JSON</code> schemas. We introduced the
support for <a href="https://avro.apache.org/">Avro</a> and <a href="https://developers.google.com/protocol-buffers/">Protobuf</a> in this release. </p><h2>Clients</h2><p>We have introduced a new <a href="/docs/client-libraries-go">Go</a> client in 2.1 release. The Pulsar Go client library is based on the <a href="/docs/client-libraries-cpp/">C++</a> client library.</p><p>Follow <a href="/docs/client-libraries-go/#installing-go-package">the instructions</a> to try it out in your Go applications!</p>]]></content>
        <author>
            <name>Sijie Guo</name>
            <uri>https://twitter.com/sijieg</uri>
        </author>
    </entry>
</feed>